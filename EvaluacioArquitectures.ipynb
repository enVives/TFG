{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enVives/TFG/blob/main/EvaluacioArquitectures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4v7z1Tb8sOhk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import wandb\n",
        "import pylab as pl\n",
        "\n",
        "\n",
        "from glob import glob\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output,display\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "\n",
        "WEIGHTSANDBIASES = False\n",
        "DOWNLOAD = False\n",
        "\n",
        "if DOWNLOAD:\n",
        "  !rm -rf /content/sample_data/*\n",
        "\n",
        "  !kaggle datasets download -d \"kmader/skin-cancer-mnist-ham10000\"\n",
        "\n",
        "  !unzip -o skin-cancer-mnist-ham10000.zip -d /content/sample_data/\n",
        "\n",
        "#471be466c8949671a46c67e7aad0d5a0ac8c9dad\n",
        "\n",
        "if WEIGHTSANDBIASES:\n",
        "  wandb.login()\n",
        "\n",
        "#torch.cuda.default_stream(torch.device('cuda'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "!rm -rf /content/sample_data/*\n",
        "\n",
        "!kaggle datasets download -d \"kmader/skin-cancer-mnist-ham10000\"\n",
        "\n",
        "!unzip -o skin-cancer-mnist-ham10000.zip -d /content/sample_data/"
      ],
      "metadata": {
        "id": "BcO_-eS1dYxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadates = pd.read_csv('/content/sample_data/HAM10000_metadata.csv')\n",
        "metadates = metadates.sort_values(by='image_id')\n",
        "metadates.head()\n",
        "print(metadates['dx'].value_counts())\n",
        "print()\n",
        "print(metadates['dx'].value_counts() / sum(metadates['dx'].value_counts()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugqDHdvBtZRA",
        "outputId": "46e0f37c-dc44-4de3-d413-cb7108a7a701"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dx\n",
            "nv       6705\n",
            "mel      1113\n",
            "bkl      1099\n",
            "bcc       514\n",
            "akiec     327\n",
            "vasc      142\n",
            "df        115\n",
            "Name: count, dtype: int64\n",
            "\n",
            "dx\n",
            "nv       0.669496\n",
            "mel      0.111133\n",
            "bkl      0.109735\n",
            "bcc      0.051323\n",
            "akiec    0.032651\n",
            "vasc     0.014179\n",
            "df       0.011483\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nv: melanocytic nevi\n",
        "\n",
        "vasc: vascular lesions\n",
        "\n",
        "mel:melanoma\n",
        "\n",
        "df: dermatofibroma\n",
        "\n",
        "bkl: benign keratosis-like lesions\n",
        "\n",
        "bcc: basal cell carcinoma\n",
        "\n",
        "akiec: Actinic keratoses and intraepithelial carcinoma / Bowen's disease"
      ],
      "metadata": {
        "id": "QcJc98DVvHTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Formes(Dataset):\n",
        "  #Classe on gestionarem les imatges dels fitxers\n",
        "  dict_illnesses = {0 : 'nv', 1 : 'mel', 2 : 'bkl', 3 : 'bcc', 4 : 'akiec', 5 : 'vasc', 6 : 'df'}\n",
        "\n",
        "  def __init__(self, images, labels, transform):\n",
        "        super().__init__()\n",
        "        self.paths = images\n",
        "        self.labels = labels\n",
        "        self.len = len(self.paths)\n",
        "        self.transform = transform\n",
        "        #Per defecte pens que el color pot extreure característiques importants, per tant en primer lloc\n",
        "        #entrenarem les imatges de color\n",
        "        self.greyscale = False\n",
        "\n",
        "  def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "  def __addlabel__(self,label):\n",
        "    self.labels = np.append(self.labels,label)\n",
        "\n",
        "  def __addPath__(self,path):\n",
        "    self.paths = np.append(self.paths,path)\n",
        "\n",
        "  def __getdist__(self):\n",
        "    return pd.Series(self.labels).value_counts()\n",
        "\n",
        "  def __getlabels__(self):\n",
        "    classes = [[],[],[],[],[],[],[]]\n",
        "    for i in range(len(self.labels)):\n",
        "      classes[self.labels[i]].append(i) #afegim l'index\n",
        "    return classes\n",
        "\n",
        "  def __redistribute__(self,percentages):\n",
        "    #percentages: [15,15,10,10,5,5] percentatges que volem pujar de la resta de classes llevat de nv\n",
        "    threshold = 0.005  #percentatge de marge que deixam a la redistribució\n",
        "    Ntarget = self.len\n",
        "    classes = self.__getlabels__() #indexos de cada clase\n",
        "    afegir = np.array([0,0,0,0,0,0],dtype=np.int64) # de nv mai haurem d'afegir\n",
        "\n",
        "    nmel = len(classes[1]) #nombre inicial de cada clase\n",
        "    nbkl = len(classes[2])\n",
        "    nbcc = len(classes[3])\n",
        "    nakiec = len(classes[4])\n",
        "    nvasc = len(classes[5])\n",
        "    ndf = len(classes[6])\n",
        "\n",
        "    while True:\n",
        "\n",
        "      suma_actual = afegir.sum()\n",
        "\n",
        "      operacio = percentages[0]*Ntarget - nmel\n",
        "      afegir[0] +=  operacio if operacio > 0 else 0\n",
        "      nmel += operacio if operacio > 0 else 0\n",
        "\n",
        "      operacio = percentages[1]*Ntarget - nbkl\n",
        "      afegir[1] += operacio if operacio > 0 else 0\n",
        "      nbkl += operacio if operacio > 0 else 0\n",
        "\n",
        "      operacio = percentages[2]*Ntarget - nbcc\n",
        "      afegir[2] += operacio if operacio > 0 else 0\n",
        "      nbcc += operacio if operacio > 0 else 0\n",
        "\n",
        "      operacio = percentages[3]*Ntarget - nakiec\n",
        "      afegir[3] += operacio if operacio > 0 else 0\n",
        "      nakiec += operacio if operacio > 0 else 0\n",
        "\n",
        "      operacio = percentages[4]*Ntarget - nvasc\n",
        "      afegir[4] += operacio if operacio > 0 else 0\n",
        "      nvasc += operacio if operacio > 0 else 0\n",
        "\n",
        "      operacio = percentages[5]*Ntarget - ndf\n",
        "      afegir[5] += operacio if operacio > 0 else 0\n",
        "      ndf += operacio if operacio > 0 else 0\n",
        "\n",
        "      if (afegir.sum()-suma_actual) < Ntarget*threshold:\n",
        "        break\n",
        "\n",
        "      Ntarget += (afegir.sum()-suma_actual)\n",
        "\n",
        "    #Quedaria afegir a les imatges les còpies\n",
        "    for i in range(len(afegir)):\n",
        "      for j in range(afegir[i]):\n",
        "\n",
        "          self.__addPath__(self.paths[classes[i+1][random.randint(0, len(classes[i+1]) - 1)]])\n",
        "          self.__addlabel__(i+1)\n",
        "\n",
        "    self.len = len(self.labels)\n",
        "\n",
        "  def __setgreyscale__(self,mode):\n",
        "    self.greyscale = mode\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      path = self.paths[index]\n",
        "      label = self.labels[index]\n",
        "\n",
        "      image = cv2.imread(path, cv2.IMREAD_GRAYSCALE if self.greyscale else cv2.IMREAD_COLOR)\n",
        "\n",
        "      if self.greyscale:\n",
        "        image = Image.fromarray(image, mode=\"L\")\n",
        "      else:\n",
        "        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "      image = self.transform(image)\n",
        "\n",
        "      return image, label"
      ],
      "metadata": {
        "id": "6PHW-EVhnT3p"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calcula_mitjana_desviacio(img_files_path):\n",
        "  mitjana = np.array([0.0, 0.0, 0.0], dtype=np.float64)\n",
        "  desviacio = np.array([0.0, 0.0, 0.0], dtype=np.float64)\n",
        "\n",
        "  x,y = 256,256\n",
        "  pixels_totals_canal = len(img_files_path) * x * y\n",
        "\n",
        "  for i in range(len(img_files_path)):\n",
        "    imatge = cv2.imread(img_files_path[i])\n",
        "    imatge = cv2.resize(imatge,(x,y))\n",
        "\n",
        "    canal_b, canal_g, canal_r = cv2.split(imatge)\n",
        "\n",
        "    mitjana += np.array([canal_r.sum(), canal_g.sum(), canal_b.sum()])\n",
        "    #desviacio += np.array([(canal_r**2).sum(), (canal_g**2).sum(), (canal_b**2).sum()])\n",
        "\n",
        "  mitjana = mitjana / pixels_totals_canal\n",
        "\n",
        "  for i in range(len(img_files_path)):\n",
        "    imatge = cv2.imread(img_files_path[i])\n",
        "    imatge = cv2.resize(imatge,(x,y))\n",
        "\n",
        "    canal_b, canal_g, canal_r = cv2.split(imatge)\n",
        "    desviacio += np.array([((canal_r-mitjana[0])**2).sum(), ((canal_g-mitjana[1])**2).sum(), ((canal_b-mitjana[2])**2).sum()])\n",
        "\n",
        "\n",
        "  desviacio = np.sqrt(desviacio / pixels_totals_canal)\n",
        "\n",
        "  return mitjana,desviacio"
      ],
      "metadata": {
        "id": "-lKr3HM2VvhY"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_sets(transformation_training,transformation_default,training_dist,valitation_dist,testing_dist,distribution):\n",
        "\n",
        "  illnes_dictionary = {\n",
        "      'nv': 'Melanocytic nevi',\n",
        "      'mel': 'Melanoma',\n",
        "      'bkl': 'Benign keratosis-like lesions ',\n",
        "      'bcc': 'Basal cell carcinoma',\n",
        "      'akiec': 'Actinic keratoses and intraepithelial carcinoma / Bowens disease',\n",
        "      'vasc': 'Vascular lesions',\n",
        "      'df': 'Dermatofibroma'\n",
        "  }\n",
        "\n",
        "  img_files_1 = sorted(glob('/content/sample_data/HAM10000_images_part_1/*'))\n",
        "  img_files_2 = sorted(glob('/content/sample_data/HAM10000_images_part_2/*'))\n",
        "  img_files = img_files_1 + img_files_2\n",
        "\n",
        "  img_files = np.array(img_files)\n",
        "\n",
        "\n",
        "  imgid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in img_files}\n",
        "\n",
        "  metadates['path'] = metadates['image_id'].map(imgid_path_dict.get)\n",
        "  metadates['illness'] = metadates['dx'].map(illnes_dictionary.get)\n",
        "  metadates['illness_code'] = metadates['dx'].map({'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3, 'akiec': 4, 'vasc': 5, 'df': 6})\n",
        "\n",
        "  #Aquest illness_code s'utilitzarà com a label de la enfermetat\n",
        "\n",
        "  img_number = len(img_files)\n",
        "\n",
        "  X = metadates.drop('illness_code',axis= 1)\n",
        "  y = metadates['illness_code']\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testing_dist, random_state=42, stratify=y)\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=valitation_dist/(training_dist+valitation_dist), random_state=42, stratify=y_train)\n",
        "\n",
        "  #Una bona idea seria aplicar data augmentation al conjunt d'entrenament ja que les classes estan molt desbalancejades\n",
        "  #Una altra bona idea seria emplear una funció de pèrdua que tengui en compte les classes desbalancejades.\n",
        "\n",
        "  #Antes de guardar els datasets en classes Formes, hauriem de caluclar la mitjana i desviació típica de les imatges\n",
        "  train_data = Formes(X_train['path'].to_numpy(),y_train.to_numpy(),transform_training)\n",
        "  test_data = Formes(X_test['path'].to_numpy(),y_test.to_numpy(),transform)\n",
        "  validation_data = Formes(X_val['path'].to_numpy(),y_val.to_numpy(),transform)\n",
        "\n",
        "\n",
        "  #prova1: [0.12,0.12,0.06,0.04,0.02,0.02]\n",
        "  #prova2: [0.12,0.12,0.06,0.04,0.02,0.015]\n",
        "  #prova3: [0.13,0.13,0.07,0.05,0.02,0.015]\n",
        "\n",
        "  if distribution != None:\n",
        "    train_data.__redistribute__(distribution)\n",
        "\n",
        "  print(train_data.__getdist__())\n",
        "  print(train_data.len)\n",
        "\n",
        "  return train_data, test_data,validation_data\n"
      ],
      "metadata": {
        "id": "LxaJdwKTtsfD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# illnes_dictionary = {\n",
        "#     'nv': 'Melanocytic nevi',\n",
        "#     'mel': 'Melanoma',\n",
        "#     'bkl': 'Benign keratosis-like lesions ',\n",
        "#     'bcc': 'Basal cell carcinoma',\n",
        "#     'akiec': 'Actinic keratoses and intraepithelial carcinoma / Bowens disease',\n",
        "#     'vasc': 'Vascular lesions',\n",
        "#     'df': 'Dermatofibroma'\n",
        "# }\n",
        "\n",
        "# img_files_1 = sorted(glob('/content/sample_data/HAM10000_images_part_1/*'))\n",
        "# img_files_2 = sorted(glob('/content/sample_data/HAM10000_images_part_2/*'))\n",
        "# img_files = img_files_1 + img_files_2\n",
        "\n",
        "# img_files = np.array(img_files)\n",
        "\n",
        "# #mitjana,desviacio = calcula_mitjana_desviacio(img_files)\n",
        "# #S'ha descobert amb aquesta funció que la mitjana = [194.57463374 139.13953272 145.36132088]\n",
        "# #I desviació= [35.92275236 38.90347617 43.33101831]\n",
        "# mean = torch.tensor([194.57463374, 139.13953272, 145.36132088]) /255 #rgb\n",
        "# std = torch.tensor([35.92275236, 38.90347617, 43.33101831]) / 255\n",
        "\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((SIZE,SIZE)),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean = mean, std=std)\n",
        "\n",
        "# ])\n",
        "\n",
        "# transform_training = transforms.Compose([\n",
        "#     transforms.Resize((SIZE,SIZE)),\n",
        "#     transforms.RandomHorizontalFlip(p=0.5),\n",
        "#     transforms.RandomVerticalFlip(p=0.5),\n",
        "#     transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
        "#     transforms.RandomRotation(degrees=20),\n",
        "#     #transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
        "#     transforms.RandomGrayscale(p=0.1),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean = mean, std=std),\n",
        "# ])\n",
        "\n",
        "# imgid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in img_files}\n",
        "\n",
        "# metadates['path'] = metadates['image_id'].map(imgid_path_dict.get)\n",
        "# metadates['illness'] = metadates['dx'].map(illnes_dictionary.get)\n",
        "# metadates['illness_code'] = metadates['dx'].map({'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3, 'akiec': 4, 'vasc': 5, 'df': 6})\n",
        "\n",
        "# #Aquest illness_code s'utilitzarà com a label de la enfermetat\n",
        "\n",
        "# img_number = len(img_files)\n",
        "\n",
        "\n",
        "# X = metadates.drop('illness_code',axis= 1)\n",
        "# y = metadates['illness_code']\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TESTING, random_state=42, stratify=y)\n",
        "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=VALIDATION/(TRAINING+VALIDATION), random_state=42, stratify=y_train)\n",
        "\n",
        "# #Una bona idea seria aplicar data augmentation al conjunt d'entrenament ja que les classes estan molt desbalancejades\n",
        "# #Una altra bona idea seria emplear una funció de pèrdua que tengui en compte les classes desbalancejades.\n",
        "\n",
        "# #Antes de guardar els datasets en classes Formes, hauriem de caluclar la mitjana i desviació típica de les imatges\n",
        "# train_data = Formes(X_train['path'].to_numpy(),y_train.to_numpy(),transform)\n",
        "# test_data = Formes(X_test['path'].to_numpy(),y_test.to_numpy(),transform)\n",
        "# validation_data = Formes(X_val['path'].to_numpy(),y_val.to_numpy(),transform_training)\n",
        "\n",
        "\n",
        "# #prova1: [0.12,0.12,0.06,0.04,0.02,0.02]\n",
        "# #prova2: [0.12,0.12,0.06,0.04,0.02,0.015]\n",
        "# #prova3: [0.13,0.13,0.07,0.05,0.02,0.015]\n",
        "\n",
        "# print(train_data.__getdist__())\n",
        "# train_data.__redistribute__([0.15,0.12,0.09,0.07,0.02,0.015])\n",
        "# print(train_data.__getdist__())\n",
        "# print(train_data.len)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cZlOgbNubsoS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def veure_imatges(train_data,std,mean):\n",
        "  for i in range(len(train_data)):\n",
        "    imatge,label = train_data.__getitem__(i)\n",
        "\n",
        "    imatge = imatge * (std[:, None, None]*255) + (mean[:, None, None]*255)\n",
        "\n",
        "    # Convert the tensor back to a NumPy array\n",
        "    img_numpy = imatge.permute(1, 2, 0).numpy()  # Change from (C, H, W) to (H, W, C)\n",
        "    cv2_imshow(img_numpy)\n",
        "    time.sleep(5)\n",
        "    clear_output(wait=True)"
      ],
      "metadata": {
        "id": "1YnLcPMeI356"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#veure_imatges(train_data,std,mean)"
      ],
      "metadata": {
        "id": "qvLR-CQR_OLU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ara ja tenim el training preparat. El provarem amb el validation a continuació"
      ],
      "metadata": {
        "id": "s6iyMBCr_33C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ENTRENAMENT"
      ],
      "metadata": {
        "id": "gvPO4Jzmvoal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tria_model(numero_model,weights):\n",
        "  if numero_model == 0:\n",
        "    alexnetbinary = models.alexnet(weights=weights)\n",
        "\n",
        "    alexnetbinary.classifier = nn.Sequential(\n",
        "    torch.nn.Linear(9216, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 512),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(512, 1)\n",
        "    )\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    return alexnetbinary,loss_fn\n",
        "\n",
        "  elif numero_model == 1:\n",
        "    vggbinary = models.vgg19(weights=weights)\n",
        "    vggbinary.classifier[6] = nn.Linear(in_features=4096, out_features=1)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    return vggbinary,\n",
        "\n",
        "  elif numero_model == 2:\n",
        "    # alexnetmulticlass = models.alexnet(weights=None)\n",
        "\n",
        "    # alexnetmulticlass.classifier = nn.Sequential(\n",
        "    # torch.nn.Linear(9216, 1024),\n",
        "    # nn.ReLU(),\n",
        "    # torch.nn.Linear(1024, 1024),\n",
        "    # nn.ReLU(),\n",
        "    # torch.nn.Linear(1024, 512),\n",
        "    # nn.ReLU(),\n",
        "    # torch.nn.Linear(512, 7),  # Ja que tenim 7 classes.\n",
        "    # nn.Softmax(dim=1)\n",
        "    # )\n",
        "    # loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # return alexnetmulticlass,loss_fn\n",
        "    return\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n1UDZMclAYj5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BATCH_SIZE = 64\n",
        "# EPOCHS = 10\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "# val_loader = torch.utils.data.DataLoader(validation_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "6Vn_HzyDI-2J"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model,loss_fn = tria_model(MODEL)\n",
        "\n",
        "# projectes = ['Ham10000-AlexnetBinary','Ham1000-Vgg','Ham1000-ResNet']\n",
        "\n",
        "# architecrures_inv = {0: 'alexnet',1:'vgg',2:'resnet'}\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model.to(device)\n",
        "# learning_rate = 1e-3\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# if WEIGHTSANDBIASES:\n",
        "#     wandb.init(\n",
        "#             project=projectes[MODEL],\n",
        "#             config={\n",
        "#                 \"epochs\": EPOCHS,\n",
        "#                 \"batch_size\": BATCH_SIZE,\n",
        "#                 \"lr\": learning_rate,\n",
        "#                 \"trsize\":len(train_loader),\n",
        "#                 \"trdist\":TRAINING,\n",
        "#                 \"vsize\":len(val_loader),\n",
        "#                 \"vdist\":VALIDATION,\n",
        "#                 })\n",
        "\n"
      ],
      "metadata": {
        "id": "0XpU9dCgvsaf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def converteix_a_binari(target):\n",
        "  #{'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3, 'akiec': 4, 'vasc': 5, 'df': 6}\n",
        "  diseases = {'0': 0,'1':1,'2': 0,'3': 1,'4':1,'5':0,'6':0}\n",
        "  target = ([[str(num.item())] for num in target])\n",
        "\n",
        "  mapped_tensor = torch.tensor([[diseases[num[0]]] for num in target])\n",
        "  return mapped_tensor"
      ],
      "metadata": {
        "id": "PsfeV3Yyek6F"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,loss_fn,dataloader,optimizer,epoch):\n",
        "\n",
        "  train_acc = 0\n",
        "  train_f1 = 0\n",
        "  train_recall = 0\n",
        "  train_precision = 0\n",
        "  train_loss = 0\n",
        "\n",
        "  for batch_num, (input_img, target) in tqdm(enumerate(dataloader), desc=f\"Batches (Època {epoch + 1})\"):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        target = torch.unsqueeze(target, 1) #separa [1,2,3,4] en [[1],[2],[3]]\n",
        "        target = converteix_a_binari(target) #només si volem saber si la enfermetat es benigna o no\n",
        "        target = target.to(device)\n",
        "\n",
        "\n",
        "        input_img = input_img.to(device)\n",
        "        output = model(input_img.to(device))\n",
        "\n",
        "        loss = loss_fn(output, target.float())\n",
        "\n",
        "        output = torch.sigmoid(output)\n",
        "\n",
        "        output = (output.cpu().detach().numpy() > 0.5).astype(int)\n",
        "\n",
        "        target = target.cpu().detach().numpy()\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            optimizer.step()\n",
        "\n",
        "        #print(f\"Pèrdua entrenament batch: {batch_num} epoch: {epoch+1}  train_loss: {loss.item()}\")\n",
        "        train_acc += accuracy_score(target,output)\n",
        "        train_f1 += f1_score(target,output,zero_division=1)\n",
        "        train_recall += recall_score(target,output,zero_division=1)\n",
        "        train_precision += precision_score(target,output,zero_division=1)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "  return train_acc,train_f1,train_recall,train_precision,train_loss\n"
      ],
      "metadata": {
        "id": "vjQynJrPzlxX"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model,data_loader,loss_fn):\n",
        "  val_acc = 0\n",
        "  val_f1 = 0\n",
        "  val_recall = 0\n",
        "  val_precision = 0\n",
        "  val_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for batch_num, (input_img, target) in enumerate(val_loader):\n",
        "            input_img = input_img.to(device)\n",
        "\n",
        "\n",
        "            target = torch.unsqueeze(target, 1)\n",
        "            target = converteix_a_binari(target) #només si volem saber si la enfermetat es benigna o no\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = model(input_img)\n",
        "            loss = loss_fn(output, target.float())\n",
        "\n",
        "            output = torch.sigmoid(output)\n",
        "            output = (output.cpu().detach().numpy() > 0.5).astype(int)\n",
        "            target = target.cpu().detach().numpy()\n",
        "\n",
        "            val_acc  += accuracy_score(target,output)\n",
        "            val_f1 += f1_score(target,output,zero_division=1)\n",
        "            val_recall += recall_score(target,output,zero_division=1)\n",
        "            val_precision += precision_score(target,output,zero_division=1)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "  return val_acc,val_f1,val_recall,val_precision,val_loss"
      ],
      "metadata": {
        "id": "6EO8TgQl304Z"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute(model,loss_fn,train_loader,val_loader,test_loader,optimizer,epochs):\n",
        "\n",
        "  t_loss = np.zeros(epochs)\n",
        "  v_loss = np.zeros(epochs)\n",
        "  acc_t = np.zeros(epochs)\n",
        "  acc_v = np.zeros(epochs)\n",
        "  f1_t = np.zeros(epochs)\n",
        "  f1_v = np.zeros(epochs)\n",
        "  recall_t = np.zeros(epochs)\n",
        "  recall_v = np.zeros(epochs)\n",
        "\n",
        "  pbar = tqdm(range(1, epochs + 1))  # tdqm permet tenir text dinàmic\n",
        "\n",
        "  for epoch in pbar:\n",
        "\n",
        "      train_loss = 0\n",
        "      train_acc = 0\n",
        "      train_precision = 0\n",
        "      train_f1 = 0\n",
        "      train_recall = 0\n",
        "      val_acc = 0\n",
        "      val_recall = 0\n",
        "      val_f1 = 0\n",
        "      val_loss = 0\n",
        "      val_precision = 0\n",
        "\n",
        "      batch_num = 1\n",
        "\n",
        "      train_acc,train_f1,train_recall,train_precision,train_loss = train(model,loss_fn,train_loader,optimizer,epoch)\n",
        "\n",
        "      val_acc,val_f1,val_recall,val_precision,val_loss  = validate(model,loss_fn,val_loader,optimizer,epoch)\n",
        "\n",
        "      # RESULTATS\n",
        "      train_loss /= len(train_loader)\n",
        "      train_acc /= len(train_loader)\n",
        "      train_f1 /= len(train_loader)\n",
        "      train_recall /= len(train_loader)\n",
        "      train_precision /= len(train_loader)\n",
        "\n",
        "      print(f\"Pèrdua entrenament epoch: {epoch+1}  train_loss: {train_loss}\")\n",
        "      print(f\"Accuracy train epoch: {epoch+1}  train_acc: {train_acc}\")\n",
        "      print(f\"F1 train epoch: {epoch+1}  train_f1: {train_f1}\")\n",
        "      print(f\"Recall train epoch: {epoch+1}  train_recall: {train_recall}\")\n",
        "\n",
        "      val_loss /= len(val_loader)\n",
        "      val_acc /= len(val_loader)\n",
        "      val_f1 /= len(val_loader)\n",
        "      val_recall /= len(val_loader)\n",
        "\n",
        "      print()\n",
        "      print()\n",
        "      print(f\"Pèrdua validació epoch: {epoch+1}  val_loss: {val_loss}\")\n",
        "      print(f\"Accuracy val epoch: {epoch+1}  val_acc: {val_acc}\")\n",
        "      print(f\"F1 val epoch: {epoch+1}  val_f1: {val_f1}\")\n",
        "      print(f\"Recall val epoch: {epoch+1}  val_reall: {val_recall}\")"
      ],
      "metadata": {
        "id": "-jUBGQHk5QwK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BINARY = True #Si volem que el resultat de la classificació sigui 0 i 1\n",
        "\n",
        "architectures = {'alexnet': 0,'vgg': 1,'resnet': 2}\n",
        "MODEL = architectures['alexnet']\n",
        "\n",
        "TRAINING = 0.64\n",
        "VALIDATION = 0.16\n",
        "TESTING = 0.20\n",
        "SIZE = 224\n",
        "\n",
        "\n",
        "mean = torch.tensor([194.57463374, 139.13953272, 145.36132088]) /255 #rgb\n",
        "std = torch.tensor([35.92275236, 38.90347617, 43.33101831]) / 255\n",
        "\n",
        "TRANSFORMATIONS = []\n",
        "DISTRIBUTIONS = None\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((SIZE,SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = mean, std=std)\n",
        "])\n",
        "\n",
        "transform_training = transforms.Compose([\n",
        "    transforms.Resize((SIZE,SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomRotation(degrees=20),\n",
        "    #transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
        "    transforms.RandomGrayscale(p=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = mean, std=std),\n",
        "])\n",
        "\n",
        "#load_sets(transformation_training,transformation_default,training_dist,valitation_dist,testing_dist,distribution):\n",
        "\n",
        "train_data,validation_data,test_data = load_sets(transform_training,transform,TRAINING,VALIDATION,TESTING,DISTRIBUTIONS)\n",
        "\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(validation_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "weights = None\n",
        "model,loss_fn = tria_model(MODEL,weights)\n",
        "\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "projectes = ['Ham10000-AlexnetBinary','Ham1000-Vgg','Ham1000-ResNet']\n",
        "architecrures_inv = {0: 'alexnet',1:'vgg',2:'resnet'}\n",
        "\n",
        "# if WEIGHTSANDBIASES:\n",
        "#     wandb.init(\n",
        "#             project=projectes[MODEL],\n",
        "#             config={\n",
        "#                 \"epochs\": EPOCHS,\n",
        "#                 \"batch_size\": BATCH_SIZE,\n",
        "#                 \"lr\": learning_rate,\n",
        "#                 \"trsize\":len(train_loader),\n",
        "#                 \"trdist\":TRAINING,\n",
        "#                 \"vsize\":len(val_loader),\n",
        "#                 \"vdist\":VALIDATION,\n",
        "#                 })\n",
        "\n",
        "\n",
        "execute(model,loss_fn,train_loader,val_loader,test_loader,optimizer,EPOCHS)"
      ],
      "metadata": {
        "id": "9_VHfhYy6uO7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541,
          "referenced_widgets": [
            "6f20d045a8e64553a91cb273f6158b24",
            "ca39d98b6b2f45689fcb1072be691e9f",
            "fe40120f2a544b319b7b52e13e47c80a",
            "567e9e83442a4166a1eb457e5f23e503",
            "94ba36011e084373be7adb382da6cd5e",
            "b4f5f222cd684303abf2035d9c47f316",
            "69000e982c254187af0de12b9fff6397",
            "7b100c61c5b1405c98e1bcb1119c6ff7",
            "b5150ad81db144108719df651678ad3f",
            "cd589685fa8048b9a77afd59b51ef2e2",
            "8d0be79422874ae0b23534cc59c90dd4",
            "14833dc26c834388a517851f870c0afa",
            "eac1a5657156405eaf9052ea014340e8",
            "63066b8a41c44f4aa0e6d22d90bedba2",
            "65a7fb641ed54ee5a6476a4dac33a497",
            "47a66c1582df4566adadb9df927f042b",
            "3fe1fca3915b484cbabe4d584e2638e4",
            "915cb290fca04ea8bcf3187fdffabb8c",
            "5fcc15d8c028413babe4eade8d91b019",
            "c06ccd530d504f099f9520c0c24cb5b7",
            "eb83fd1f977e436fa374b34e2d4e6edf",
            "8bd9d8c01734406babe27f4165168753"
          ]
        },
        "outputId": "232f2c0c-9e24-4e13-9c2b-2e7e88659d29"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    4291\n",
            "1     712\n",
            "2     703\n",
            "3     329\n",
            "4     209\n",
            "5      91\n",
            "6      74\n",
            "Name: count, dtype: int64\n",
            "6409\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f20d045a8e64553a91cb273f6158b24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches (Època 2): 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14833dc26c834388a517851f870c0afa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-40bd6dac9e27>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-8648ce4758de>\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(model, loss_fn, train_loader, val_loader, test_loader, optimizer, epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mbatch_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_f1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_recall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_precision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_f1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_recall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_precision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loss\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-25128573853a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, dataloader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Batches (Època {epoch + 1})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-d561a311a676>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(img, angle, interpolation, expand, center, fill)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0mcenter_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(img, angle, interpolation, expand, center, fill)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(self, angle, resample, expand, center, translate, fillcolor)\u001b[0m\n\u001b[1;32m   2503\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2505\u001b[0;31m         return self.transform(\n\u001b[0m\u001b[1;32m   2506\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAFFINE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfillcolor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2507\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, size, method, data, resample, fill, fillcolor)\u001b[0m\n\u001b[1;32m   2873\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2875\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2876\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m             \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   3130\u001b[0m             \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImagePalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImagePalette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3131\u001b[0m             \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_ints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3132\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "# from tqdm.auto import tqdm\n",
        "# import pylab as pl\n",
        "\n",
        "# t_loss = np.zeros(EPOCHS)\n",
        "# v_loss = np.zeros(EPOCHS)\n",
        "# acc_t = np.zeros(EPOCHS)\n",
        "# acc_v = np.zeros(EPOCHS)\n",
        "# f1_t = np.zeros(EPOCHS)\n",
        "# f1_v = np.zeros(EPOCHS)\n",
        "# recall_t = np.zeros(EPOCHS)\n",
        "# recall_v = np.zeros(EPOCHS)\n",
        "\n",
        "# pbar = tqdm(range(1, EPOCHS + 1))  # tdqm permet tenir text dinàmic\n",
        "\n",
        "# for epoch in pbar:\n",
        "\n",
        "#     train_loss = 0\n",
        "#     train_acc = 0\n",
        "#     train_f1 = 0\n",
        "#     train_recall = 0\n",
        "#     val_acc = 0\n",
        "#     val_recall = 0\n",
        "#     val_f1 = 0\n",
        "#     val_loss = 0\n",
        "\n",
        "#     batch_num = 1\n",
        "\n",
        "\n",
        "#     for batch_num, (input_img, target) in tqdm(enumerate(train_loader), desc=f\"Batches (Època {epoch + 1})\"):\n",
        "#         model.train()\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         target = torch.unsqueeze(target, 1) #separa [1,2,3,4] en [[1],[2],[3]]\n",
        "#         target = converteix_a_binari(target) #només si volem saber si la enfermetat es benigna o no\n",
        "#         target = target.to(device)\n",
        "\n",
        "\n",
        "#         input_img = input_img.to(device)\n",
        "#         output = model(input_img.to(device))\n",
        "\n",
        "#         loss = loss_fn(output, target.float())\n",
        "\n",
        "#         output = torch.sigmoid(output)\n",
        "\n",
        "#         output = (output.cpu().detach().numpy() > 0.5).astype(int)\n",
        "\n",
        "#         target = target.cpu().detach().numpy()\n",
        "#         train_acc += accuracy_score(target,output)\n",
        "#         train_f1 += f1_score(target,output,zero_division=1)\n",
        "#         train_recall += recall_score(target,output,zero_division=1)\n",
        "\n",
        "#         model.zero_grad()\n",
        "#         loss.backward()\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             optimizer.step()\n",
        "\n",
        "#         #print(f\"Pèrdua entrenament batch: {batch_num} epoch: {epoch+1}  train_loss: {loss.item()}\")\n",
        "#         train_loss += loss.item()\n",
        "\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         for batch_num, (input_img, target) in enumerate(val_loader):\n",
        "#             input_img = input_img.to(device)\n",
        "\n",
        "\n",
        "#             target = torch.unsqueeze(target, 1)\n",
        "#             target = converteix_a_binari(target) #només si volem saber si la enfermetat es benigna o no\n",
        "#             target = target.to(device)\n",
        "\n",
        "#             output = model(input_img)\n",
        "#             loss = loss_fn(output, target.float())\n",
        "\n",
        "#             output = torch.sigmoid(output)\n",
        "#             output = (output.cpu().detach().numpy() > 0.5).astype(int)\n",
        "#             target = target.cpu().detach().numpy()\n",
        "\n",
        "#             val_acc  += accuracy_score(target,output)\n",
        "#             val_f1 += f1_score(target,output,zero_division=1)\n",
        "#             val_recall += recall_score(target,output,zero_division=1)\n",
        "\n",
        "#             val_loss += loss.item()\n",
        "\n",
        "#             #print(f\"Pèrdua entrenament batch validacio: {batch_num} epoch: {epoch+1}  val_loss: {val_loss.item()}\")\n",
        "\n",
        "#             # RESULTATS\n",
        "#     train_loss /= len(train_loader)\n",
        "#     t_loss[epoch - 1] = train_loss\n",
        "\n",
        "#     train_acc /= len(train_loader)\n",
        "#     acc_t[epoch - 1] = train_acc\n",
        "\n",
        "#     train_f1 /= len(train_loader)\n",
        "#     f1_t[epoch - 1] = train_f1\n",
        "\n",
        "#     train_recall /= len(train_loader)\n",
        "#     recall_t[epoch - 1] = train_recall\n",
        "#     print(f\"Pèrdua entrenament epoch: {epoch+1}  train_loss: {train_loss}\")\n",
        "#     print(f\"Accuracy train epoch: {epoch+1}  train_acc: {train_acc}\")\n",
        "#     print(f\"F1 train epoch: {epoch+1}  train_f1: {train_f1}\")\n",
        "#     print(f\"Recall train epoch: {epoch+1}  train_recall: {train_recall}\")\n",
        "\n",
        "#     val_loss /= len(val_loader)\n",
        "#     v_loss[epoch - 1] = val_loss\n",
        "\n",
        "#     val_acc /= len(val_loader)\n",
        "#     acc_v[epoch - 1] = val_acc\n",
        "\n",
        "#     val_f1 /= len(val_loader)\n",
        "#     f1_v[epoch - 1] = val_f1\n",
        "\n",
        "#     val_recall /= len(val_loader)\n",
        "#     recall_v[epoch - 1] = val_recall\n",
        "\n",
        "#     print()\n",
        "#     print()\n",
        "#     print(f\"Pèrdua validació epoch: {epoch+1}  val_loss: {val_loss}\")\n",
        "#     print(f\"Accuracy val epoch: {epoch+1}  val_acc: {val_acc}\")\n",
        "#     print(f\"F1 val epoch: {epoch+1}  val_f1: {val_f1}\")\n",
        "#     print(f\"Recall val epoch: {epoch+1}  val_reall: {val_recall}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "uQSCid8zGduq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "AlexNet.ipynb",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6f20d045a8e64553a91cb273f6158b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca39d98b6b2f45689fcb1072be691e9f",
              "IPY_MODEL_fe40120f2a544b319b7b52e13e47c80a",
              "IPY_MODEL_567e9e83442a4166a1eb457e5f23e503"
            ],
            "layout": "IPY_MODEL_94ba36011e084373be7adb382da6cd5e"
          }
        },
        "ca39d98b6b2f45689fcb1072be691e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4f5f222cd684303abf2035d9c47f316",
            "placeholder": "​",
            "style": "IPY_MODEL_69000e982c254187af0de12b9fff6397",
            "value": "  0%"
          }
        },
        "fe40120f2a544b319b7b52e13e47c80a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b100c61c5b1405c98e1bcb1119c6ff7",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5150ad81db144108719df651678ad3f",
            "value": 0
          }
        },
        "567e9e83442a4166a1eb457e5f23e503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd589685fa8048b9a77afd59b51ef2e2",
            "placeholder": "​",
            "style": "IPY_MODEL_8d0be79422874ae0b23534cc59c90dd4",
            "value": " 0/5 [00:00&lt;?, ?it/s]"
          }
        },
        "94ba36011e084373be7adb382da6cd5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f5f222cd684303abf2035d9c47f316": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69000e982c254187af0de12b9fff6397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b100c61c5b1405c98e1bcb1119c6ff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5150ad81db144108719df651678ad3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd589685fa8048b9a77afd59b51ef2e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d0be79422874ae0b23534cc59c90dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14833dc26c834388a517851f870c0afa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eac1a5657156405eaf9052ea014340e8",
              "IPY_MODEL_63066b8a41c44f4aa0e6d22d90bedba2",
              "IPY_MODEL_65a7fb641ed54ee5a6476a4dac33a497"
            ],
            "layout": "IPY_MODEL_47a66c1582df4566adadb9df927f042b"
          }
        },
        "eac1a5657156405eaf9052ea014340e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fe1fca3915b484cbabe4d584e2638e4",
            "placeholder": "​",
            "style": "IPY_MODEL_915cb290fca04ea8bcf3187fdffabb8c",
            "value": "Batches (Època 2): "
          }
        },
        "63066b8a41c44f4aa0e6d22d90bedba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fcc15d8c028413babe4eade8d91b019",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c06ccd530d504f099f9520c0c24cb5b7",
            "value": 0
          }
        },
        "65a7fb641ed54ee5a6476a4dac33a497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb83fd1f977e436fa374b34e2d4e6edf",
            "placeholder": "​",
            "style": "IPY_MODEL_8bd9d8c01734406babe27f4165168753",
            "value": " 0/? [00:00&lt;?, ?it/s]"
          }
        },
        "47a66c1582df4566adadb9df927f042b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fe1fca3915b484cbabe4d584e2638e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "915cb290fca04ea8bcf3187fdffabb8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fcc15d8c028413babe4eade8d91b019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c06ccd530d504f099f9520c0c24cb5b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb83fd1f977e436fa374b34e2d4e6edf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bd9d8c01734406babe27f4165168753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}