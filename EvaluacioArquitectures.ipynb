{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enVives/TFG/blob/main/EvaluacioArquitectures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluació d'Arquitectures\n",
        "\n",
        "Aquest fitxer s'ha desenvolupat amb els següents objectius:\n",
        "\n",
        "1.   Entrenar els models _AlexNet_, _ResNet-152_, _InceptionV3_ i _EfficientNetB1_ per a classificació binària i multiclasse.\n",
        "2.   Generar carpetes al drive per a cada model. De cada entrenament crearem una carpeta numerada i hi guardarem el següent:\n",
        "\n",
        "  *   Pesos del model entrenat\n",
        "  *   Paràmetres utilitzats en l'entrenament, guardats a un fitxer txt.\n",
        "  *   Sortida obtinguda del test amb el conjunt de test.\n",
        "\n",
        "3. Utilitzar l'eina _Weights and Biases_ per a tenir un seguiment dels entrenaments\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BHUgQdneFJkL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v7z1Tb8sOhk",
        "outputId": "1484a15a-0d25-451b-cab5-bc9c33b9d8fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import wandb\n",
        "import pylab as pl\n",
        "import json\n",
        "\n",
        "from glob import glob\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output,display\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "WEIGHTSANDBIASES = True\n",
        "DOWNLOAD = False\n",
        "CROPPING = False\n",
        "SEGMENTATION = True\n",
        "\n",
        "# ORIGEN = '/content/drive/MyDrive/HAM10000/skin-cancer-mnist-ham10000/'\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#descarregam les imatges i les màscares de segmentació\n",
        "\n",
        "if DOWNLOAD:\n",
        "  !rm -rf /content/sample_data/*\n",
        "\n",
        "  !kaggle datasets download -d \"kmader/skin-cancer-mnist-ham10000\"\n",
        "\n",
        "  !unzip -o skin-cancer-mnist-ham10000.zip -d /content/sample_data/\n",
        "\n",
        "  !kaggle datasets download -d \"tschandl/ham10000-lesion-segmentations\"\n",
        "\n",
        "  !unzip -o ham10000-lesion-segmentations.zip -d /content/sample_data/\n",
        "\n",
        "#471be466c8949671a46c67e7aad0d5a0ac8c9dad\n",
        "\n",
        "#iniciam sessió a weights and biases\n",
        "if WEIGHTSANDBIASES:\n",
        "  wandb.login()\n",
        "\n",
        "#per defecte volem utilitzar la GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZDX7scfqUSy_"
      },
      "outputs": [],
      "source": [
        "# !mkdir -p ~/.kaggle\n",
        "# !mv /content/kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El fitxer csv de metadates conté informació adicional de cada imatge. En aquest projecte hem utilitzat els següents camps:\n",
        "\n",
        "*   _image_id_ : identificador associat a cada imatge. Aquest té el prefixe ISIC_00 seguit d'un nombre de 5 dígits únic per a cada imatge.\n",
        "*   _dx_ : acrònim associat a cada malaltia dermatològica."
      ],
      "metadata": {
        "id": "Hev2uxLnHeo3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ugqDHdvBtZRA"
      },
      "outputs": [],
      "source": [
        "metadates = pd.read_csv('/content/sample_data/HAM10000_metadata.csv')\n",
        "metadates = metadates.sort_values(by='image_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La següent classe, hereditària de la classe Dataset, s'utilitzarà per a gestionar els subconjunts creats a partir de la base de dades original. És amb aquesta classe que crearem els subconjunts d'entrenament, de test i de validació. De cada subconjunt guarda el següent:\n",
        "\n",
        "*   Direcció URL (_paths_): localitzacions de cada imatge.\n",
        "*   Classes (_labels_) : Malaltia a la que pertany cada imatge. Aquestes malalties es codifiquen de la següent manera:\n",
        "\n",
        "  *   nv: 0\n",
        "  *   mel: 1\n",
        "  *   bkl: 2\n",
        "  *   bcc : 3\n",
        "  *   akiec: 4\n",
        "  *   vasc: 5\n",
        "  *   df: 6\n",
        "* Transformacions (_transform_): Guarda els pre processaments que s'aplicaran a totes les imatges del subconjunt: augmentació de dades, normalització etc.\n",
        "\n",
        "* Greyscale: en el cas de voler entrenar amb imatges en escala de grisos.\n",
        "\n",
        "*Masks: màscares de segmentació de cada imatge.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AZ1f76hoI2-V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6PHW-EVhnT3p"
      },
      "outputs": [],
      "source": [
        "class Formes(Dataset):\n",
        "  dict_illnesses = {0 : 'nv', 1 : 'mel', 2 : 'bkl', 3 : 'bcc', 4 : 'akiec', 5 : 'vasc', 6 : 'df'}\n",
        "\n",
        "  def __init__(self, images, labels, transform):\n",
        "        super().__init__()\n",
        "        self.paths = images\n",
        "        self.labels = labels\n",
        "        self.len = len(self.paths)\n",
        "        self.transform = transform\n",
        "        self.greyscale = False\n",
        "\n",
        "  def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "  def __setmasks__(self,masks):\n",
        "      self.masks = masks\n",
        "\n",
        "  def __getmask__(self,i):\n",
        "      return self.masks[i]\n",
        "\n",
        "  def __lenmasks__(self):\n",
        "    return len(self.masks)\n",
        "\n",
        "  def __addlabel__(self,label):\n",
        "    self.labels = np.append(self.labels,label)\n",
        "\n",
        "  def __addPath__(self,path):\n",
        "    self.paths = np.append(self.paths,path)\n",
        "\n",
        "  def __getdist__(self):\n",
        "    return pd.Series(self.labels).value_counts()\n",
        "\n",
        "  def __getlabels__(self):\n",
        "    classes = [[],[],[],[],[],[],[]]\n",
        "    for i in range(len(self.labels)):\n",
        "      classes[self.labels[i]].append(i) #afegim l'index\n",
        "    return classes\n",
        "\n",
        "  def __setgreyscale__(self,mode):\n",
        "    self.greyscale = mode\n",
        "\n",
        "  def __getpath__(self,index):\n",
        "    return self.paths[index]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      path = self.paths[index]\n",
        "      label = self.labels[index]\n",
        "\n",
        "      image = cv2.imread(path, cv2.IMREAD_GRAYSCALE if self.greyscale else cv2.IMREAD_COLOR)\n",
        "\n",
        "      #Si hem decidit al principi que volem aplicar les màsqueres de segmentació\n",
        "      if SEGMENTATION:\n",
        "        mask = cv2.imread(self.masks[index], cv2.IMREAD_GRAYSCALE)\n",
        "        _, mask_binaria = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "        image = cv2.bitwise_and(image, image, mask=mask_binaria)\n",
        "\n",
        "        non_black_pixels = np.where(image > 0)\n",
        "\n",
        "        x_min, x_max = np.min(non_black_pixels[1]), np.max(non_black_pixels[1])\n",
        "        y_min, y_max = np.min(non_black_pixels[0]), np.max(non_black_pixels[0])\n",
        "\n",
        "        marge = 10\n",
        "        if ((x_min - marge) >= 0):\n",
        "            x_min = x_min - marge\n",
        "        if ((x_max + marge) <= 224):\n",
        "            x_max = x_max + marge\n",
        "\n",
        "        #Si hem decidit al principi que volem aplicar el reescalat a les imatges segmentades\n",
        "        if CROPPING:\n",
        "          image = image[y_min:y_max, x_min:x_max]\n",
        "\n",
        "        image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "\n",
        "      if self.greyscale:\n",
        "        image = Image.fromarray(image, mode=\"L\")\n",
        "      else:\n",
        "        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "      image = self.transform(image)\n",
        "\n",
        "      return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El següent mètode es va utilitzar per obtenir la mitjana i la desviació tipica dels canals de les imatges dels subconjunts."
      ],
      "metadata": {
        "id": "hwcZsvk2Lvwr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-lKr3HM2VvhY"
      },
      "outputs": [],
      "source": [
        "def calcula_mitjana_desviacio(img_files_path):\n",
        "  mitjana = np.array([0.0, 0.0, 0.0], dtype=np.float64)\n",
        "  desviacio = np.array([0.0, 0.0, 0.0], dtype=np.float64)\n",
        "\n",
        "  x,y = 256,256\n",
        "  pixels_totals_canal = len(img_files_path) * x * y\n",
        "\n",
        "  for i in range(len(img_files_path)):\n",
        "    imatge = cv2.imread(img_files_path[i])\n",
        "    imatge = cv2.resize(imatge,(x,y))\n",
        "\n",
        "    canal_b, canal_g, canal_r = cv2.split(imatge)\n",
        "\n",
        "    mitjana += np.array([canal_r.sum(), canal_g.sum(), canal_b.sum()])\n",
        "\n",
        "  mitjana = mitjana / pixels_totals_canal\n",
        "\n",
        "  for i in range(len(img_files_path)):\n",
        "    imatge = cv2.imread(img_files_path[i])\n",
        "    imatge = cv2.resize(imatge,(x,y))\n",
        "\n",
        "    canal_b, canal_g, canal_r = cv2.split(imatge)\n",
        "    desviacio += np.array([((canal_r-mitjana[0])**2).sum(), ((canal_g-mitjana[1])**2).sum(), ((canal_b-mitjana[2])**2).sum()])\n",
        "\n",
        "\n",
        "  desviacio = np.sqrt(desviacio / pixels_totals_canal)\n",
        "\n",
        "  return mitjana,desviacio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amb load_sets construim els subconjunts de entrenament, validació i testing."
      ],
      "metadata": {
        "id": "tJwahTFtL7lt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LxaJdwKTtsfD"
      },
      "outputs": [],
      "source": [
        "def load_sets(transformation_training,transformation_default,training_dist,valitation_dist,testing_dist):\n",
        "\n",
        "  illnes_dictionary = {\n",
        "      'nv': 'Melanocytic nevi',\n",
        "      'mel': 'Melanoma',\n",
        "      'bkl': 'Benign keratosis-like lesions ',\n",
        "      'bcc': 'Basal cell carcinoma',\n",
        "      'akiec': 'Actinic keratoses and intraepithelial carcinoma / Bowens disease',\n",
        "      'vasc': 'Vascular lesions',\n",
        "      'df': 'Dermatofibroma'\n",
        "  }\n",
        "\n",
        "  img_files_1 = sorted(glob('/content/sample_data/HAM10000_images_part_1/*'))\n",
        "  img_files_2 = sorted(glob('/content/sample_data/HAM10000_images_part_2/*'))\n",
        "  img_files = img_files_1 + img_files_2\n",
        "\n",
        "  img_files = np.array(img_files)\n",
        "\n",
        "  mask_files = sorted(glob('/content/sample_data/HAM10000_segmentations_lesion_tschandl/*'))\n",
        "\n",
        "  imgid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in img_files}\n",
        "\n",
        "  mask_path_dict = {os.path.splitext(os.path.basename(x))[0].replace('_segmentation', ''): x for x in mask_files}\n",
        "\n",
        "\n",
        "  metadates['path'] = metadates['image_id'].map(imgid_path_dict.get)\n",
        "  metadates['mask_path'] = metadates['image_id'].map(mask_path_dict.get)\n",
        "\n",
        "  metadates['illness'] = metadates['dx'].map(illnes_dictionary.get)\n",
        "  metadates['illness_code'] = metadates['dx'].map({'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3, 'akiec': 4, 'vasc': 5, 'df': 6})\n",
        "\n",
        "  #Aquest illness_code s'utilitzarà com a label de la enfermetat\n",
        "\n",
        "  img_number = len(img_files)\n",
        "\n",
        "  X = metadates.drop('illness_code',axis= 1)\n",
        "  y = metadates['illness_code']\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testing_dist, random_state=42, stratify=y)\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=valitation_dist/(training_dist+valitation_dist), random_state=42, stratify=y_train)\n",
        "\n",
        "  train_data = Formes(X_train['path'].to_numpy(),y_train.to_numpy(),transformation_training)\n",
        "  test_data = Formes(X_test['path'].to_numpy(),y_test.to_numpy(),transformation_default)\n",
        "  validation_data = Formes(X_val['path'].to_numpy(),y_val.to_numpy(),transformation_default)\n",
        "\n",
        "  if SEGMENTATION:\n",
        "\n",
        "    train_data.__setmasks__(X_train['mask_path'].to_numpy())\n",
        "    test_data.__setmasks__(X_test['mask_path'].to_numpy())\n",
        "    validation_data.__setmasks__(X_val['mask_path'].to_numpy())\n",
        "\n",
        "  return train_data, validation_data,test_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amb get_weights obtenim els pesos que tindrà cada classe en les mètriques d'avaluació."
      ],
      "metadata": {
        "id": "44BfDT2ZQaWP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XYwfwJII_rFe"
      },
      "outputs": [],
      "source": [
        "def get_weights():\n",
        "\n",
        "  valors = metadates['dx'].value_counts()\n",
        "  illnesses = valors.keys()\n",
        "  weights = np.zeros(len(illnesses))\n",
        "\n",
        "  i = 0\n",
        "  for x in illnesses:\n",
        "    y = valors[x]\n",
        "    weights[i] = valors.sum() / y\n",
        "    i+= 1\n",
        "\n",
        "  weights = weights / weights.sum()\n",
        "\n",
        "  return (1 - (weights[1]+weights[3]+weights[4])) / (weights[1]+weights[3]+weights[4]) ,weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seguidament tenim tria_model, on definim les nostres arquitectures que utilitzarem. Passam per paràmetre els pesos que tindrà cada classe  en la pèrdua. Utilitzam _transfer_learning_  amb els pesos entrenats a la base de dades ImageNet."
      ],
      "metadata": {
        "id": "iXNEcKBnQqFq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "n1UDZMclAYj5"
      },
      "outputs": [],
      "source": [
        "def tria_model(numero_model,weights):\n",
        "  if numero_model == 0:\n",
        "    alexnetbinary = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    alexnetbinary.classifier = nn.Sequential(\n",
        "    torch.nn.Linear(9216, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 512),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(512, 1)\n",
        "    )\n",
        "    pos_weight = torch.tensor(weights,device = device)\n",
        "    # print(pos_weight.shape)\n",
        "    # print(pos_weight)\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    return alexnetbinary,loss_fn\n",
        "\n",
        "  elif numero_model == 1:\n",
        "    resnetbinary = models.resnet152(weights=\"IMAGENET1K_V1\")\n",
        "    num_features = resnetbinary.fc.in_features\n",
        "    resnetbinary.fc = nn.Linear(in_features=num_features, out_features=1)\n",
        "\n",
        "    pos_weight = torch.tensor(weights,device = device)\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    return resnetbinary,loss_fn\n",
        "\n",
        "  elif numero_model == 2:\n",
        "    googlenet = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1, aux_logits=True)\n",
        "    pos_weight = torch.tensor(weights,device = device)\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    googlenet.aux_logits = False\n",
        "\n",
        "    num_features = googlenet.fc.in_features\n",
        "    googlenet.fc = nn.Linear(in_features=num_features, out_features=1)\n",
        "\n",
        "    return googlenet,loss_fn\n",
        "\n",
        "  elif numero_model == 3:\n",
        "    efficientnet = models.efficientnet_b1(weights='IMAGENET1K_V1')\n",
        "    pos_weight = torch.tensor(weights,device = device)\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    num_features = efficientnet.classifier[1].in_features\n",
        "    efficientnet.classifier[1] = nn.Linear(in_features=num_features, out_features=1)\n",
        "\n",
        "    return efficientnet,loss_fn\n",
        "\n",
        "  elif numero_model == 4:\n",
        "\n",
        "    alexnetmulticlass = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
        "    alexnetmulticlass.classifier[6] = nn.Linear(in_features=4096, out_features=7)\n",
        "\n",
        "    weights = torch.tensor(weights,device = device,dtype= torch.float32).squeeze(0)\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    return alexnetmulticlass,loss_fn\n",
        "\n",
        "  elif numero_model == 5:\n",
        "    resnetmulticlass152 = models.resnet152(weights=\"IMAGENET1K_V1\")\n",
        "    num_features = resnetmulticlass152.fc.in_features\n",
        "    resnetmulticlass152.fc = nn.Linear(in_features=num_features, out_features=7)\n",
        "\n",
        "    weights = torch.tensor(weights,device = device,dtype= torch.float32).squeeze(0)\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    return resnetmulticlass152,loss_fn\n",
        "\n",
        "  elif numero_model == 6:\n",
        "\n",
        "    googlenetmulticlass = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    weights = torch.tensor(weights,device = device,dtype= torch.float32).squeeze(0)\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    num_features = googlenetmulticlass.fc.in_features\n",
        "    googlenetmulticlass.fc = nn.Linear(in_features=num_features, out_features=7)\n",
        "\n",
        "    return googlenetmulticlass,loss_fn\n",
        "\n",
        "  elif numero_model == 7:\n",
        "\n",
        "    efficientnetmulticlass = models.efficientnet_b1(weights='IMAGENET1K_V1')\n",
        "\n",
        "    weights = torch.tensor(weights,device = device,dtype= torch.float32).squeeze(0)\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    num_features = efficientnetmulticlass.classifier[1].in_features\n",
        "    efficientnetmulticlass.classifier[1] = nn.Linear(in_features=num_features, out_features=7)\n",
        "\n",
        "    return efficientnetmulticlass,loss_fn\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amb la funció converteix_a_binari codificam les etiquetes de les enfermetats a les classes benignes i malignes."
      ],
      "metadata": {
        "id": "VVkh-v08iW1G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PsfeV3Yyek6F"
      },
      "outputs": [],
      "source": [
        "def converteix_a_binari(target):\n",
        "  diseases = {'0': 0,'1':1,'2': 0,'3': 1,'4':1,'5':0,'6':0}\n",
        "  target = ([[str(num.item())] for num in target])\n",
        "\n",
        "  mapped_tensor = torch.tensor([[diseases[num[0]]] for num in target])\n",
        "  return mapped_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vjQynJrPzlxX"
      },
      "outputs": [],
      "source": [
        "def train(model,loss_fn,dataloader,optimizer,epoch,device):\n",
        "\n",
        "  train_acc = 0\n",
        "  train_f1 = 0\n",
        "  train_recall = 0\n",
        "  train_precision = 0\n",
        "  train_loss = 0\n",
        "\n",
        "  for batch_num, (input_img, target) in tqdm(enumerate(dataloader), desc=f\"Batches (Època {epoch})\"):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_img = input_img.to(device)\n",
        "        output = model(input_img.to(device))\n",
        "\n",
        "        if isinstance(output, tuple) or hasattr(output, 'logits'): #cas especial per a InceptionV3\n",
        "                output = output.logits\n",
        "\n",
        "        if output.shape[1] > 1: #cas multi classe\n",
        "          a = 1\n",
        "        else: #binary\n",
        "          target = torch.unsqueeze(target, 1) #separa [1,2,3,4] en [[1],[2],[3]]\n",
        "          target = converteix_a_binari(target) #només si volem saber si la enfermetat es benigna o no\n",
        "\n",
        "        if output.shape[1] > 1: #cas multi classe\n",
        "          target = target.to(device)\n",
        "          loss = loss_fn(output, target)\n",
        "        else:\n",
        "          target = target.to(device)\n",
        "          loss = loss_fn(output, target.float())\n",
        "\n",
        "        #transformam el output a probabilitats per a les mètriques d'avaluació\n",
        "\n",
        "        if output.shape[1] > 1:\n",
        "          output = torch.softmax(output,dim = 1) #calculam les probabilitats de cada classe a partir dels logits\n",
        "          output = output.argmax(dim=1) #obtenim la classe que té la probabilitat més alta de les 7\n",
        "          output = output.cpu().detach().numpy()\n",
        "        else:\n",
        "          output = torch.sigmoid(output)   #funció sigmoide per al cas binari\n",
        "          output = (output.cpu().detach().numpy() > 0.5).astype(int)\n",
        "\n",
        "        target = target.cpu().detach().numpy()\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            optimizer.step()\n",
        "\n",
        "        #mètriques weighted\n",
        "        train_acc += accuracy_score(target,output)\n",
        "        train_f1 += f1_score(target,output,average='weighted',zero_division=1)\n",
        "        train_recall += recall_score(target,output,average='weighted',zero_division=1)\n",
        "        train_precision += precision_score(target,output,average='weighted',zero_division=1)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "  return train_acc,train_f1,train_recall,train_precision,train_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6EO8TgQl304Z"
      },
      "outputs": [],
      "source": [
        "def validate(model,loss_fn,data_loader,device):\n",
        "  val_acc = 0\n",
        "  val_f1 = 0\n",
        "  val_recall = 0\n",
        "  val_precision = 0\n",
        "  val_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for batch_num, (input_img, target) in enumerate(data_loader):\n",
        "\n",
        "            input_img = input_img.to(device)\n",
        "            output = model(input_img)\n",
        "\n",
        "            if isinstance(output, tuple) or hasattr(output, 'logits'):\n",
        "                output = output.logits\n",
        "\n",
        "\n",
        "            if output.shape[1] > 1: #multiclass\n",
        "              a = 1\n",
        "            else: #binary\n",
        "              target = torch.unsqueeze(target, 1) #separa [1,2,3,4] en [[1],[2],[3]]\n",
        "              target = converteix_a_binari(target) #només si volem saber si la enfermetat es benigna o no\n",
        "\n",
        "            if output.shape[1] > 1:\n",
        "              target = target.to(device)\n",
        "              loss = loss_fn(output, target)\n",
        "            else:\n",
        "              target = target.to(device)\n",
        "              loss = loss_fn(output, target.float())\n",
        "\n",
        "\n",
        "            if output.shape[1] > 1:\n",
        "              output = torch.softmax(output,dim = 1) #calculam les probabilitats de cada classe a partir dels logits\n",
        "              output = output.argmax(dim=1) #obtenim la classe que té la probabilitat més alta de les 7\n",
        "              output = output.cpu().detach().numpy()\n",
        "            else:\n",
        "              output = torch.sigmoid(output)   #funció sigmoide per al cas binari\n",
        "              output = (output.cpu().detach().numpy() > 0.5).astype(int)\n",
        "\n",
        "\n",
        "            target = target.cpu().detach().numpy()\n",
        "\n",
        "            val_acc  += accuracy_score(target,output)\n",
        "            val_f1 += f1_score(target,output,average='weighted',zero_division=1)\n",
        "            val_recall += recall_score(target,output,average='weighted',zero_division=1)\n",
        "            val_precision += precision_score(target,output,average='weighted',zero_division=1)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "  return val_acc,val_f1,val_recall,val_precision,val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-jUBGQHk5QwK"
      },
      "outputs": [],
      "source": [
        "from ast import And\n",
        "def execute(model,loss_fn,train_loader,val_loader,test_loader,optimizer,epochs,device):\n",
        "\n",
        "  t_loss = np.zeros(epochs)\n",
        "  v_loss = np.zeros(epochs)\n",
        "  acc_t = np.zeros(epochs)\n",
        "  acc_v = np.zeros(epochs)\n",
        "  f1_t = np.zeros(epochs)\n",
        "  f1_v = np.zeros(epochs)\n",
        "  recall_t = np.zeros(epochs)\n",
        "  recall_v = np.zeros(epochs)\n",
        "\n",
        "\n",
        "  interval = 5\n",
        "  requerit = 0.010\n",
        "  last_loss = float('inf') #variables utilitzades a l'early stopping\n",
        "\n",
        "  epoch_number = 0\n",
        "\n",
        "  pbar = tqdm(range(1, epochs + 1))  # tdqm permet tenir text dinàmic\n",
        "\n",
        "  for epoch in pbar:\n",
        "\n",
        "      train_loss = 0\n",
        "      train_acc = 0\n",
        "      train_precision = 0\n",
        "      train_f1 = 0\n",
        "      train_recall = 0\n",
        "      val_acc = 0\n",
        "      val_recall = 0\n",
        "      val_f1 = 0\n",
        "      val_loss = 0\n",
        "      val_precision = 0\n",
        "\n",
        "      batch_num = 1\n",
        "\n",
        "      train_acc,train_f1,train_recall,train_precision,train_loss = train(model,loss_fn,train_loader,optimizer,epoch,device)\n",
        "      val_acc,val_f1,val_recall,val_precision,val_loss  = validate(model,loss_fn,val_loader,device)\n",
        "\n",
        "      #guardam les mètriques a weights and biases\n",
        "      if WEIGHTSANDBIASES:\n",
        "\n",
        "        training_metrics = {\"train/train_loss\": train_loss/len(train_loader),\n",
        "                        \"train/train_acc\":train_acc/len(train_loader),\n",
        "                        \"train/train_f1\":train_f1/len(train_loader),\n",
        "                        \"train/train_recall\":train_recall/len(train_loader),\n",
        "                        \"train/train_precision\":train_precision/len(train_loader)}\n",
        "\n",
        "        val_metrics = {\"val/val_loss\": val_loss/len(val_loader),\n",
        "                      \"val/val_acc\":val_acc/len(val_loader),\n",
        "                      \"val/val_f1\":val_f1/len(val_loader),\n",
        "                      \"val/val_recall\": val_recall/len(val_loader),\n",
        "                      \"val/val_precision\": val_precision/len(val_loader)}\n",
        "\n",
        "        wandb.log({**training_metrics, **val_metrics})\n",
        "\n",
        "      # RESULTATS\n",
        "      train_loss /= len(train_loader)\n",
        "      train_acc /= len(train_loader)\n",
        "      train_f1 /= len(train_loader)\n",
        "      train_recall /= len(train_loader)\n",
        "      train_precision /= len(train_loader)\n",
        "\n",
        "      print(f\"Pèrdua entrenament epoch: {epoch}  train_loss: {train_loss}\")\n",
        "      print(f\"Accuracy train epoch: {epoch}  train_acc: {train_acc}\")\n",
        "      print(f\"F1 train epoch: {epoch}  train_f1: {train_f1}\")\n",
        "      print(f\"Recall train epoch: {epoch}  train_recall: {train_recall}\")\n",
        "\n",
        "      val_loss /= len(val_loader)\n",
        "      val_acc /= len(val_loader)\n",
        "      val_f1 /= len(val_loader)\n",
        "      val_recall /= len(val_loader)\n",
        "      val_precision /= len(val_loader)\n",
        "\n",
        "      print()\n",
        "      print()\n",
        "      print(f\"Pèrdua validació epoch: {epoch}  val_loss: {val_loss}\")\n",
        "      print(f\"Accuracy val epoch: {epoch}  val_acc: {val_acc}\")\n",
        "      print(f\"F1 val epoch: {epoch}  val_f1: {val_f1}\")\n",
        "      print(f\"Recall val epoch: {epoch}  val_recall: {val_recall}\")\n",
        "      print(f\"Recall val epoch: {epoch}  val_precision: {val_precision}\")\n",
        "\n",
        "\n",
        "      #early stopping\n",
        "      if interval > 0:\n",
        "        interval -= 1\n",
        "\n",
        "      if interval == 0:\n",
        "        if last_loss - requerit < train_loss:\n",
        "            print(\"Early Stopping, no hem reduït ni un 0.03 de loss respecte 10 èpoques!!\")\n",
        "            break\n",
        "        else:\n",
        "          interval = 5\n",
        "          last_loss = train_loss\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "D-ia9GpNgOqT"
      },
      "outputs": [],
      "source": [
        "def test(model,dataloader,weights_dir,loss_fn,device):\n",
        "\n",
        "  model.load_state_dict(torch.load(weights_dir))\n",
        "\n",
        "  test_acc = 0\n",
        "  test_f1 = 0\n",
        "  test_recall = 0\n",
        "  test_precision = 0\n",
        "  test_loss = 0\n",
        "\n",
        "  json_obj = []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for batch_num, (input_img, target) in enumerate(dataloader):\n",
        "\n",
        "            input_img = input_img.to(device)\n",
        "            output = model(input_img)\n",
        "\n",
        "            if isinstance(output, tuple) or hasattr(output, 'logits'):\n",
        "                output = output.logits\n",
        "\n",
        "            dades = {}\n",
        "\n",
        "            if output.shape[1] > 1: #multiclass\n",
        "              a = 1\n",
        "            else: #binary\n",
        "              target = torch.unsqueeze(target, 1) #separa [1,2,3,4] en [[1],[2],[3]]\n",
        "              target = converteix_a_binari(target) #només si volem saber si la enfermetat es benigna o no\n",
        "\n",
        "            if output.shape[1] > 1:\n",
        "              target = target.to(device)\n",
        "              loss = loss_fn(output, target)\n",
        "            else:\n",
        "              target = target.to(device)\n",
        "              loss = loss_fn(output, target.float())\n",
        "\n",
        "\n",
        "            if output.shape[1] > 1:\n",
        "              output = torch.softmax(output,dim = 1) #calculam les probabilitats de cada classe a partir dels logits\n",
        "\n",
        "              dades[\"output\"] = output.cpu().detach().tolist() #guardam les probabilitats de l'output\n",
        "\n",
        "              output = output.argmax(dim=1) #obtenim la classe que té la probabilitat més alta de les 7\n",
        "              output = output.cpu().detach().numpy()\n",
        "            else:\n",
        "              output = torch.sigmoid(output)   #funció sigmoide per al cas binari\n",
        "\n",
        "              dades[\"output\"] = output.cpu().detach().tolist() #guardam les probabilitats de l'output\n",
        "\n",
        "              output = (output.cpu().detach().numpy() > 0.5).astype(int)\n",
        "\n",
        "            dades[\"target\"] = target.cpu().detach().tolist()\n",
        "\n",
        "            target = target.cpu().detach().numpy()\n",
        "\n",
        "            dades[\"top1-accuracy\"] = accuracy_score(target,output)\n",
        "            test_acc  += dades[\"top1-accuracy\"]\n",
        "            dades[\"f1-score\"] = f1_score(target,output,average='weighted',zero_division=1)\n",
        "            test_f1 += dades[\"f1-score\"]\n",
        "            dades[\"recall\"] = recall_score(target,output,average='weighted',zero_division=1)\n",
        "            test_recall += dades[\"recall\"]\n",
        "            dades[\"precision\"] = precision_score(target,output,average='weighted',zero_division=1)\n",
        "            test_precision += dades[\"precision\"]\n",
        "\n",
        "            dades[\"loss\"] = loss.item()\n",
        "            test_loss += dades[\"loss\"]\n",
        "\n",
        "            json_obj.append(dades)\n",
        "\n",
        "\n",
        "  return json_obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "O26Tu8uy9OaB"
      },
      "outputs": [],
      "source": [
        "def veure_imatges(train_data):\n",
        "  for i in range(len(train_data)):\n",
        "    path = train_data.__getpath__(i)\n",
        "    clean_img = cv2.imread(path)\n",
        "    mean, std = cv2.meanStdDev(clean_img)\n",
        "\n",
        "    clean_img = cv2.resize(clean_img, (224, 224))\n",
        "    clean_img = torch.tensor(clean_img).permute(2, 0, 1)  # Convert to (C, H, W)\n",
        "\n",
        "    print(clean_img.shape)\n",
        "\n",
        "    imatge,label = train_data.__getitem__(i)\n",
        "    print(imatge.shape)\n",
        "    std = std.flatten()\n",
        "    mean = mean.flatten()\n",
        "    imatge = imatge * (std[:, None, None]) + (mean[:, None, None])\n",
        "\n",
        "    img_numpy = imatge.permute(1, 2, 0).numpy()  # Change from (C, H, W) to (H, W, C)\n",
        "    clean_img = clean_img.permute(1, 2, 0).numpy() #clean_img no es un torch\n",
        "\n",
        "    combined_image = np.concatenate((img_numpy, clean_img), axis=1)\n",
        "    cv2_imshow(combined_image)\n",
        "\n",
        "    time.sleep(5)\n",
        "    clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_VHfhYy6uO7"
      },
      "outputs": [],
      "source": [
        "from itertools import product\n",
        "BINARY = False #Si volem que el resultat de la classificació sigui 0 i 1\n",
        "\n",
        "architectures = {'alexnet': 0,'resnet152':1,'inceptionv3':2,'efficientnetb1':3,'alexnetmulticlass':4,'resnet152multiclass':5,'inceptionv3multiclass':6,'efficientnetb1multiclass':7}\n",
        "#alguns models com InceptionV3 requereixen unes dimensions específiques.\n",
        "img_sizes = {'alexnet': 224,'resnet152':224,'inceptionv3':299,'efficientnetb1':224,'alexnetmulticlass':224,'resnet152multiclass':224,'inceptionv3multiclass':299,'efficientnetb1multiclass':224}\n",
        "\n",
        "nom_model = 'alexnetmulticlass'\n",
        "MODEL = architectures[nom_model]\n",
        "\n",
        "TRAINING = 0.80\n",
        "VALIDATION = 0.10\n",
        "TESTING = 0.10\n",
        "SIZE = img_sizes[nom_model]\n",
        "\n",
        "\n",
        "mean = torch.tensor([194.57463374, 139.13953272, 145.36132088]) /255 #rgb\n",
        "std = torch.tensor([35.92275236, 38.90347617, 43.33101831]) / 255\n",
        "\n",
        "#TRANSFORMATIONS = []\n",
        "\n",
        "if SEGMENTATION == False:\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize((SIZE,SIZE)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean = mean, std=std)\n",
        "  ])\n",
        "\n",
        "  transform_training = transforms.Compose([\n",
        "      transforms.Resize((SIZE,SIZE)),\n",
        "      transforms.RandomHorizontalFlip(p=0.3),\n",
        "      transforms.RandomVerticalFlip(p=0.3),\n",
        "      transforms.RandomRotation(degrees=20),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean = mean, std=std),\n",
        "  ])\n",
        "else:\n",
        "  transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean = mean, std=std)\n",
        "  ])\n",
        "\n",
        "  transform_training = transforms.Compose([\n",
        "      transforms.RandomHorizontalFlip(p=0.3),\n",
        "      transforms.RandomVerticalFlip(p=0.3),\n",
        "      transforms.RandomRotation(degrees=20),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean = mean, std=std),\n",
        "  ])\n",
        "\n",
        "train_data,validation_data,test_data = load_sets(transform_training,transform,TRAINING,VALIDATION,TESTING)\n",
        "\n",
        "\n",
        "EPOCHS = 60\n",
        "batch_size = 32\n",
        "\n",
        "binary_weights, multiple_weights = get_weights()\n",
        "\n",
        "if MODEL < 4: #weights per al loss\n",
        "  weights = binary_weights\n",
        "else:\n",
        "  weights = multiple_weights\n",
        "\n",
        "print(weights)\n",
        "learning_rate  = 1e-5\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model,loss_fn = tria_model(MODEL,weights)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "projectes = ['Ham10000-AlexnetBinary','Ham1000-Resnet152Binary','Ham10000-Inceptionv3Binary','Ham10000-EfficientNetB1Binary',\n",
        "              'Ham10000-AlexnetMulticlass','Ham10000Resnet152Multiclass','Ham10000-Inceptionv3Multiclass','Ham10000-EfficientNetB1Multiclass']\n",
        "\n",
        "if WEIGHTSANDBIASES:\n",
        "    wandb.init(\n",
        "            project=projectes[MODEL],\n",
        "            config={\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"batch_size\": batch_size,\n",
        "                \"lr\": learning_rate,\n",
        "                \"trsize\":len(train_loader),\n",
        "                \"trdist\":TRAINING,\n",
        "                \"vsize\":len(val_loader),\n",
        "                \"vdist\":VALIDATION,\n",
        "                \"weights\":weights,\n",
        "                })\n",
        "    config = wandb.config\n",
        "    print(config)\n",
        "\n",
        "\n",
        "parametres_training = {\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"batch_size\": batch_size,\n",
        "                \"lr\": learning_rate,\n",
        "                \"trsize\":len(train_loader),\n",
        "                \"trdist\":TRAINING,\n",
        "                \"vsize\":len(val_loader),\n",
        "                \"vdist\":VALIDATION,\n",
        "                \"testsize\":len(test_loader),\n",
        "                \"testdist\": TESTING,\n",
        "                \"loss_weights\":str(weights),\n",
        "                \"SEGMENTATION\": SEGMENTATION,\n",
        "                \"CROPPING\": CROPPING,\n",
        "                \"img_size\": SIZE,\n",
        "                \"random_state\": 42,\n",
        "                \"WeightsAndBiases\": wandb.run.get_url(),\n",
        "                \"data_augmentation\": str(transform_training)\n",
        "}\n",
        "\n",
        "carpeta_drive = '/content/drive/MyDrive/Runs/' + projectes[MODEL]\n",
        "os.makedirs(carpeta_drive, exist_ok=True) #cream la carpeta si no existeix\n",
        "\n",
        "last = [os.path.basename(os.path.normpath(path)) for path in sorted(glob(carpeta_drive+\"/*\"))]\n",
        "if len(last) == 0:\n",
        "  current_runs = 0\n",
        "else:\n",
        "  current_runs = int(last[-1])\n",
        "\n",
        "#cada execució tindrà la seva carpeta numerada\n",
        "\n",
        "json_object = json.dumps(parametres_training,indent = 2)\n",
        "\n",
        "#cream la carpeta de l'execució\n",
        "\n",
        "num_execucio = str(current_runs+1)\n",
        "carpeta_execucio = carpeta_drive+\"/\"+ num_execucio\n",
        "os.makedirs(carpeta_execucio,exist_ok=True)\n",
        "\n",
        "#afegim la informació d'entrenament a la carpeta\n",
        "with open(carpeta_execucio+\"/training_info.json\", \"w\") as outfile:\n",
        "  outfile.write(json_object)\n",
        "\n",
        "#guardam els pesos a la carpeta de drive\n",
        "best_model = execute(model,loss_fn,train_loader,val_loader,test_loader,optimizer,EPOCHS,device)\n",
        "carpeta_pesos = carpeta_execucio+'/pesos_'+nom_model+'_'+num_execucio+'.pt'\n",
        "torch.save(model.state_dict(), carpeta_pesos )\n",
        "\n",
        "#també guardam els resultats del test a la carpeta de drive\n",
        "carpeta_pesos = carpeta_execucio+'/pesos_'+nom_model+'_'+num_execucio+'.pt'\n",
        "\n",
        "resultats = test(model,test_loader,carpeta_pesos,loss_fn,device)\n",
        "\n",
        "with open(carpeta_execucio+\"/testing_info.json\", \"w\") as outfile:\n",
        "    json.dump(resultats, outfile, indent=3)\n",
        "\n",
        "\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "name": "AlexNet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}