{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enVives/TFG/blob/main/tasca1/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "4v7z1Tb8sOhk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "\n",
        "\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# !rm -rf /content/sample_data/*\n",
        "\n",
        "# !kaggle datasets download -d \"kmader/skin-cancer-mnist-ham10000\"\n",
        "\n",
        "# !unzip -o skin-cancer-mnist-ham10000.zip -d /content/sample_data/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "!rm -rf /content/sample_data/*\n",
        "\n",
        "!kaggle datasets download -d \"kmader/skin-cancer-mnist-ham10000\"\n",
        "\n",
        "!unzip -o skin-cancer-mnist-ham10000.zip -d /content/sample_data/"
      ],
      "metadata": {
        "id": "BcO_-eS1dYxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadates = pd.read_csv('/content/sample_data/HAM10000_metadata.csv')\n",
        "metadates = metadates.sort_values(by='image_id')\n",
        "metadates.head()\n",
        "print(metadates['dx'].value_counts())\n",
        "print()\n",
        "print(metadates['dx'].value_counts() / sum(metadates['dx'].value_counts()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugqDHdvBtZRA",
        "outputId": "c75ec2c2-ef55-4974-a48c-b5e50a0b10f8"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dx\n",
            "nv       6705\n",
            "mel      1113\n",
            "bkl      1099\n",
            "bcc       514\n",
            "akiec     327\n",
            "vasc      142\n",
            "df        115\n",
            "Name: count, dtype: int64\n",
            "\n",
            "dx\n",
            "nv       0.669496\n",
            "mel      0.111133\n",
            "bkl      0.109735\n",
            "bcc      0.051323\n",
            "akiec    0.032651\n",
            "vasc     0.014179\n",
            "df       0.011483\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nv: melanocytic nevi\n",
        "\n",
        "vasc: vascular lesions\n",
        "\n",
        "mel:melanoma\n",
        "\n",
        "df: dermatofibroma\n",
        "\n",
        "bkl: benign keratosis-like lesions\n",
        "\n",
        "bcc: basal cell carcinoma\n",
        "\n",
        "akiec: Actinic keratoses and intraepithelial carcinoma / Bowen's disease"
      ],
      "metadata": {
        "id": "QcJc98DVvHTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Formes(Dataset):\n",
        "  #Classe on gestionarem les imatges dels fitxers\n",
        "\n",
        "  def __init__(self, images, labels, transform):\n",
        "        super().__init__()\n",
        "        self.paths = images\n",
        "        self.labels = labels\n",
        "        self.len = len(self.paths)\n",
        "        self.transform = transform\n",
        "        #Per defecte pens que el color pot extreure característiques importants, per tant en primer lloc\n",
        "        #entrenarem les imatges de color\n",
        "        self.greyscale = False\n",
        "\n",
        "  def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "  def __setgreyscale__(self,mode):\n",
        "    self.greyscale = mode\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      path = self.paths[index]\n",
        "      label = self.labels[index]\n",
        "\n",
        "      image = cv2.imread(path, cv2.IMREAD_GRAYSCALE if self.greyscale else cv2.IMREAD_COLOR)  # Depén de vosaltres\n",
        "      image = self.transform(image)\n",
        "\n",
        "      return image, label"
      ],
      "metadata": {
        "id": "6PHW-EVhnT3p"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calcula_mitjana_desviacio(img_files_path):\n",
        "  mitjana = np.array([0.0, 0.0, 0.0], dtype=np.float64)\n",
        "  desviacio = np.array([0.0, 0.0, 0.0], dtype=np.float64)\n",
        "\n",
        "  x,y = 224,224\n",
        "  pixels_totals_canal = len(img_files_path) * x * y\n",
        "\n",
        "  for i in range(len(img_files_path)):\n",
        "    imatge = cv2.imread(img_files_path[i])\n",
        "    imatge = cv2.resize(imatge,(x,y))\n",
        "\n",
        "    canal_b, canal_g, canal_r = cv2.split(imatge)\n",
        "\n",
        "    mitjana += np.array([canal_r.sum(), canal_g.sum(), canal_b.sum()])\n",
        "    desviacio += np.array([(canal_r**2).sum(), (canal_g**2).sum(), (canal_b**2).sum()])\n",
        "\n",
        "  mitjana = mitjana / pixels_totals_canal\n",
        "  variance = (desviacio/pixels_totals_canal) - mitjana**2\n",
        "  print(desviacio)\n",
        "  print(variance)\n",
        "  desviacio = np.sqrt(np.maximum(0,variance))\n",
        "\n",
        "  return mitjana,desviacio"
      ],
      "metadata": {
        "id": "-lKr3HM2VvhY"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING = 0.64\n",
        "VALIDATION = 0.16\n",
        "TESTING = 0.20\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "illnes_dictionary = {\n",
        "    'nv': 'Melanocytic nevi',\n",
        "    'mel': 'Melanoma',\n",
        "    'bkl': 'Benign keratosis-like lesions ',\n",
        "    'bcc': 'Basal cell carcinoma',\n",
        "    'akiec': 'Actinic keratoses and intraepithelial carcinoma / Bowens disease',\n",
        "    'vasc': 'Vascular lesions',\n",
        "    'df': 'Dermatofibroma'\n",
        "}\n",
        "\n",
        "img_files_1 = sorted(glob('/content/sample_data/HAM10000_images_part_1/*'))\n",
        "img_files_2 = sorted(glob('/content/sample_data/HAM10000_images_part_2/*'))\n",
        "img_files = img_files_1 + img_files_2\n",
        "\n",
        "img_files = np.array(img_files)\n",
        "\n",
        "imgid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in img_files}\n",
        "\n",
        "metadates['path'] = metadates['image_id'].map(imgid_path_dict.get)\n",
        "metadates['illness'] = metadates['dx'].map(illnes_dictionary.get)\n",
        "metadates['illness_code'] = metadates['dx'].map({'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3, 'akiec': 4, 'vasc': 5, 'df': 6})\n",
        "\n",
        "#Aquest illness_code s'utilitzarà com a label de la enfermetat\n",
        "\n",
        "img_number = len(img_files)\n",
        "\n",
        "\n",
        "X = metadates.drop('illness_code',axis= 1)\n",
        "y = metadates['illness_code']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TESTING, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=VALIDATION/(TRAINING+VALIDATION), random_state=42, stratify=y_train)\n",
        "\n",
        "#Una bona idea seria aplicar data augmentation al conjunt d'entrenament ja que les classes estan molt desbalancejades\n",
        "#Una altra bona idea seria emplear una funció de pèrdua que tengui en compte les classes desbalancejades.\n",
        "\n",
        "#Antes de guardar els datasets en classes Formes, hauriem de caluclar la mitjana i desviació típica de les imatges\n",
        "train_data = Formes(X_train['path'].to_numpy(),y_train.to_numpy(),transform)\n",
        "test_data = Formes(X_test['path'].to_numpy(),y_test.to_numpy(),transform)\n",
        "validation_data = Formes(X_val['path'].to_numpy(),y_val.to_numpy(),transform)\n",
        "\n",
        "\n",
        "mitjana,desviacio = calcula_mitjana_desviacio(img_files)\n",
        "print(mitjana)\n",
        "print(desviacio)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZlOgbNubsoS",
        "outputId": "50a1bc64-1c47-4579-f353-2f577a790e0a"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-37745.27740474 -19255.809691   -21022.728044  ]\n",
            "[194.57463374 139.13953272 145.36132088]\n",
            "[0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Estaria bé millorar la distribució de les classes en el dataset original\n",
        "\n",
        "\n",
        "\n",
        "# labels = numpy.array(metadates['dx'\n",
        "# labels = metadates['dx'].to_numpy()\n",
        "\n",
        "# idx_list = list(range(img_number))\n",
        "# random.shuffle(idx_list)\n",
        "\n",
        "# training_imgs = img_files[idx_list[:int(img_number*TRAINING)]]\n",
        "# training_labels = labels[idx_list[:int(img_number*TRAINING)]]\n",
        "\n",
        "# train_data = Formes(training_imgs,training_labels,transform)\n",
        "\n",
        "# validation_imgs = img_files[idx_list[int(img_number*TRAINING):int(img_number*(TRAINING+VALIDATION))]]\n",
        "# validation_labels = labels[idx_list[int(img_number*TRAINING):int(img_number*(TRAINING+VALIDATION))]]\n",
        "\n",
        "# validation_data = Formes(validation_imgs,validation_labels,transform)\n",
        "\n",
        "# testing_imgs = img_files[idx_list[int(img_number*(TRAINING+VALIDATION)):]]\n",
        "# testing_labels = labels[idx_list[int(img_number*(TRAINING+VALIDATION)):]]\n",
        "\n",
        "# testing_data = Formes(testing_imgs,testing_labels,transform)\n",
        "\n",
        "\n",
        "# print(len(training_imgs))\n",
        "# print(len(validation_imgs))\n",
        "# print(len(testing_imgs))\n",
        "# metadates.to_csv('metadatesnou.csv')"
      ],
      "metadata": {
        "id": "VL5IsKy6aBct"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ENTRENAMENT"
      ],
      "metadata": {
        "id": "gvPO4Jzmvoal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alexnetbinary = models.alexnet(pretrained=False)\n",
        "alexnetmulticlass = models.alexnet(pretrained=False)\n",
        "\n",
        "alexnetbinary.classifier = nn.Sequential(\n",
        "    torch.nn.Linear(9216, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 512),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(512, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "alexnetmulticlass.classifier = nn.Sequential(\n",
        "    torch.nn.Linear(9216, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 512),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(512, 7),  # Ja que tenim 7 classes.\n",
        "    nn.Softmax(dim=1)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XpU9dCgvsaf",
        "outputId": "e9a1c686-3b86-4bc6-9103-36edf1015d94"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5YJqfLM3GVDj"
      },
      "execution_count": 104,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "AlexNet.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}