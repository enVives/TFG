{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enVives/TFG/blob/main/EvaluacioArquitectures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "4v7z1Tb8sOhk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511b4536-22e6-40bf-96e6-b6c6ea25bf3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import wandb\n",
        "import pylab as pl\n",
        "import json\n",
        "\n",
        "from glob import glob\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output,display\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "WEIGHTSANDBIASES = True\n",
        "DOWNLOAD = False\n",
        "# ORIGEN = '/content/drive/MyDrive/HAM10000/skin-cancer-mnist-ham10000/'\n",
        "\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "if DOWNLOAD:\n",
        "  !rm -rf /content/sample_data/*\n",
        "\n",
        "  !kaggle datasets download -d \"kmader/skin-cancer-mnist-ham10000\"\n",
        "\n",
        "  !unzip -o skin-cancer-mnist-ham10000.zip -d /content/sample_data/\n",
        "\n",
        "#471be466c8949671a46c67e7aad0d5a0ac8c9dad\n",
        "\n",
        "if WEIGHTSANDBIASES:\n",
        "  wandb.login()\n",
        "\n",
        "#torch.cuda.default_stream(torch.device('cuda'))\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZDX7scfqUSy_"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "!rm -rf /content/sample_data/*\n",
        "\n",
        "!kaggle datasets download -d \"kmader/skin-cancer-mnist-ham10000\"\n",
        "\n",
        "!unzip -o skin-cancer-mnist-ham10000.zip -d /content/sample_data/"
      ],
      "metadata": {
        "id": "BcO_-eS1dYxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "metadates = pd.read_csv('/content/sample_data/HAM10000_metadata.csv')\n",
        "metadates = metadates.sort_values(by='image_id')\n",
        "metadates.head()\n",
        "print(metadates['dx'].value_counts())\n",
        "print()\n",
        "print(metadates['dx'].value_counts() / sum(metadates['dx'].value_counts()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugqDHdvBtZRA",
        "outputId": "0cd5b82b-6a68-47a0-a576-0571f0c48a22"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dx\n",
            "nv       6705\n",
            "mel      1113\n",
            "bkl      1099\n",
            "bcc       514\n",
            "akiec     327\n",
            "vasc      142\n",
            "df        115\n",
            "Name: count, dtype: int64\n",
            "\n",
            "dx\n",
            "nv       0.669496\n",
            "mel      0.111133\n",
            "bkl      0.109735\n",
            "bcc      0.051323\n",
            "akiec    0.032651\n",
            "vasc     0.014179\n",
            "df       0.011483\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nv: melanocytic nevi\n",
        "\n",
        "vasc: vascular lesions\n",
        "\n",
        "mel:melanoma\n",
        "\n",
        "df: dermatofibroma\n",
        "\n",
        "bkl: benign keratosis-like lesions\n",
        "\n",
        "bcc: basal cell carcinoma\n",
        "\n",
        "akiec: Actinic keratoses and intraepithelial carcinoma / Bowen's disease"
      ],
      "metadata": {
        "id": "QcJc98DVvHTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Formes(Dataset):\n",
        "  #Classe on gestionarem les imatges dels fitxers\n",
        "  dict_illnesses = {0 : 'nv', 1 : 'mel', 2 : 'bkl', 3 : 'bcc', 4 : 'akiec', 5 : 'vasc', 6 : 'df'}\n",
        "\n",
        "  def __init__(self, images, labels, transform):\n",
        "        super().__init__()\n",
        "        self.paths = images\n",
        "        self.labels = labels\n",
        "        self.len = len(self.paths)\n",
        "        self.transform = transform\n",
        "        #Per defecte pens que el color pot extreure característiques importants, per tant en primer lloc\n",
        "        #entrenarem les imatges de color\n",
        "        self.greyscale = False\n",
        "\n",
        "  def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "  def __addlabel__(self,label):\n",
        "    self.labels = np.append(self.labels,label)\n",
        "\n",
        "  def __addPath__(self,path):\n",
        "    self.paths = np.append(self.paths,path)\n",
        "\n",
        "  def __getdist__(self):\n",
        "    return pd.Series(self.labels).value_counts()\n",
        "\n",
        "  def __getlabels__(self):\n",
        "    classes = [[],[],[],[],[],[],[]]\n",
        "    for i in range(len(self.labels)):\n",
        "      classes[self.labels[i]].append(i) #afegim l'index\n",
        "    return classes\n",
        "\n",
        "  def __redistribute__(self,percentages):\n",
        "    #percentages: [15,15,10,10,5,5] percentatges que volem pujar de la resta de classes llevat de nv\n",
        "    threshold = 0.005  #percentatge de marge que deixam a la redistribució\n",
        "    Ntarget = self.len\n",
        "    classes = self.__getlabels__() #indexos de cada clase\n",
        "    afegir = np.array([0,0,0,0,0,0],dtype=np.int64) # de nv mai haurem d'afegir\n",
        "\n",
        "    nmel = len(classes[1]) #nombre inicial de cada clase\n",
        "    nbkl = len(classes[2])\n",
        "    nbcc = len(classes[3])\n",
        "    nakiec = len(classes[4])\n",
        "    nvasc = len(classes[5])\n",
        "    ndf = len(classes[6])\n",
        "\n",
        "    while True:\n",
        "\n",
        "      suma_actual = afegir.sum()\n",
        "\n",
        "      operacio = percentages[0]*Ntarget - nmel\n",
        "      afegir[0] +=  operacio if operacio > 0 else 0\n",
        "      nmel += operacio if operacio > 0 else 0\n",
        "\n",
        "      operacio = percentages[1]*Ntarget - nbkl\n",
        "      afegir[1] += operacio if operacio > 0 else 0\n",
        "      nbkl += operacio if operacio > 0 else 0\n",
        "\n",
        "      operacio = percentages[2]*Ntarget - nbcc\n",
        "      afegir[2] += operacio if operacio > 0 else 0\n",
        "      nbcc += operacio if operacio > 0 else 0\n",
        "\n",
        "      operacio = percentages[3]*Ntarget - nakiec\n",
        "      afegir[3] += operacio if operacio > 0 else 0\n",
        "      nakiec += operacio if operacio > 0 else 0\n",
        "\n",
        "      operacio = percentages[4]*Ntarget - nvasc\n",
        "      afegir[4] += operacio if operacio > 0 else 0\n",
        "      nvasc += operacio if operacio > 0 else 0\n",
        "\n",
        "      operacio = percentages[5]*Ntarget - ndf\n",
        "      afegir[5] += operacio if operacio > 0 else 0\n",
        "      ndf += operacio if operacio > 0 else 0\n",
        "\n",
        "      if (afegir.sum()-suma_actual) < Ntarget*threshold:\n",
        "        break\n",
        "\n",
        "      Ntarget += (afegir.sum()-suma_actual)\n",
        "\n",
        "    #Quedaria afegir a les imatges les còpies\n",
        "    for i in range(len(afegir)):\n",
        "      for j in range(afegir[i]):\n",
        "\n",
        "          self.__addPath__(self.paths[classes[i+1][random.randint(0, len(classes[i+1]) - 1)]])\n",
        "          self.__addlabel__(i+1)\n",
        "\n",
        "    self.len = len(self.labels)\n",
        "\n",
        "  def __setgreyscale__(self,mode):\n",
        "    self.greyscale = mode\n",
        "\n",
        "  def __getpath__(self,index):\n",
        "    return self.paths[index]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      path = self.paths[index]\n",
        "      label = self.labels[index]\n",
        "\n",
        "      image = cv2.imread(path, cv2.IMREAD_GRAYSCALE if self.greyscale else cv2.IMREAD_COLOR)\n",
        "\n",
        "      if self.greyscale:\n",
        "        image = Image.fromarray(image, mode=\"L\")\n",
        "      else:\n",
        "        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "      image = self.transform(image)\n",
        "\n",
        "      return image, label"
      ],
      "metadata": {
        "id": "6PHW-EVhnT3p"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calcula_mitjana_desviacio(img_files_path):\n",
        "  mitjana = np.array([0.0, 0.0, 0.0], dtype=np.float64)\n",
        "  desviacio = np.array([0.0, 0.0, 0.0], dtype=np.float64)\n",
        "\n",
        "  x,y = 256,256\n",
        "  pixels_totals_canal = len(img_files_path) * x * y\n",
        "\n",
        "  for i in range(len(img_files_path)):\n",
        "    imatge = cv2.imread(img_files_path[i])\n",
        "    imatge = cv2.resize(imatge,(x,y))\n",
        "\n",
        "    canal_b, canal_g, canal_r = cv2.split(imatge)\n",
        "\n",
        "    mitjana += np.array([canal_r.sum(), canal_g.sum(), canal_b.sum()])\n",
        "    #desviacio += np.array([(canal_r**2).sum(), (canal_g**2).sum(), (canal_b**2).sum()])\n",
        "\n",
        "  mitjana = mitjana / pixels_totals_canal\n",
        "\n",
        "  for i in range(len(img_files_path)):\n",
        "    imatge = cv2.imread(img_files_path[i])\n",
        "    imatge = cv2.resize(imatge,(x,y))\n",
        "\n",
        "    canal_b, canal_g, canal_r = cv2.split(imatge)\n",
        "    desviacio += np.array([((canal_r-mitjana[0])**2).sum(), ((canal_g-mitjana[1])**2).sum(), ((canal_b-mitjana[2])**2).sum()])\n",
        "\n",
        "\n",
        "  desviacio = np.sqrt(desviacio / pixels_totals_canal)\n",
        "\n",
        "  return mitjana,desviacio"
      ],
      "metadata": {
        "id": "-lKr3HM2VvhY"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_sets(transformation_training,transformation_default,training_dist,valitation_dist,testing_dist,distribution):\n",
        "\n",
        "  illnes_dictionary = {\n",
        "      'nv': 'Melanocytic nevi',\n",
        "      'mel': 'Melanoma',\n",
        "      'bkl': 'Benign keratosis-like lesions ',\n",
        "      'bcc': 'Basal cell carcinoma',\n",
        "      'akiec': 'Actinic keratoses and intraepithelial carcinoma / Bowens disease',\n",
        "      'vasc': 'Vascular lesions',\n",
        "      'df': 'Dermatofibroma'\n",
        "  }\n",
        "\n",
        "  img_files_1 = sorted(glob('/content/sample_data/HAM10000_images_part_1/*'))\n",
        "  img_files_2 = sorted(glob('/content/sample_data/HAM10000_images_part_2/*'))\n",
        "  img_files = img_files_1 + img_files_2\n",
        "\n",
        "  img_files = np.array(img_files)\n",
        "\n",
        "\n",
        "  imgid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in img_files}\n",
        "\n",
        "  metadates['path'] = metadates['image_id'].map(imgid_path_dict.get)\n",
        "  metadates['illness'] = metadates['dx'].map(illnes_dictionary.get)\n",
        "  metadates['illness_code'] = metadates['dx'].map({'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3, 'akiec': 4, 'vasc': 5, 'df': 6})\n",
        "\n",
        "  #Aquest illness_code s'utilitzarà com a label de la enfermetat\n",
        "\n",
        "  img_number = len(img_files)\n",
        "\n",
        "  X = metadates.drop('illness_code',axis= 1)\n",
        "  y = metadates['illness_code']\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testing_dist, random_state=42, stratify=y)\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=valitation_dist/(training_dist+valitation_dist), random_state=42, stratify=y_train)\n",
        "\n",
        "  #Una bona idea seria aplicar data augmentation al conjunt d'entrenament ja que les classes estan molt desbalancejades\n",
        "  #Una altra bona idea seria emplear una funció de pèrdua que tengui en compte les classes desbalancejades.\n",
        "\n",
        "  #Antes de guardar els datasets en classes Formes, hauriem de caluclar la mitjana i desviació típica de les imatges\n",
        "  train_data = Formes(X_train['path'].to_numpy(),y_train.to_numpy(),transformation_training)\n",
        "  test_data = Formes(X_test['path'].to_numpy(),y_test.to_numpy(),transformation_default)\n",
        "  validation_data = Formes(X_val['path'].to_numpy(),y_val.to_numpy(),transformation_default)\n",
        "\n",
        "\n",
        "  #prova1: [0.12,0.12,0.06,0.04,0.02,0.02]\n",
        "  #prova2: [0.12,0.12,0.06,0.04,0.02,0.015]\n",
        "  #prova3: [0.13,0.13,0.07,0.05,0.02,0.015]\n",
        "\n",
        "  if distribution != None:\n",
        "    train_data.__redistribute__(distribution)\n",
        "\n",
        "  return train_data, validation_data,test_data\n"
      ],
      "metadata": {
        "id": "LxaJdwKTtsfD"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weights():\n",
        "\n",
        "  #diseases = {'0': 0,'1':1,'2': 0,'3': 1,'4':1,'5':0,'6':0}\n",
        "\n",
        "  valors = metadates['dx'].value_counts()\n",
        "  print(valors)\n",
        "  illnesses = valors.keys()\n",
        "  weights = np.zeros(len(illnesses))\n",
        "\n",
        "  i = 0\n",
        "  for x in illnesses:\n",
        "    y = valors[x]\n",
        "    weights[i] = valors.sum() / y\n",
        "    i+= 1\n",
        "\n",
        "  weights = weights / weights.sum()\n",
        "\n",
        "  print((1 - (weights[1]+weights[3]+weights[4])) / (weights[1]+weights[3]+weights[4]))\n",
        "  return (1 - (weights[1]+weights[3]+weights[4])) / (weights[1]+weights[3]+weights[4]) ,weights"
      ],
      "metadata": {
        "id": "XYwfwJII_rFe"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Captura de pantalla 2025-01-28 232832.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "FiiMdFnMB-Qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#veure_imatges(train_data,std,mean)"
      ],
      "metadata": {
        "id": "qvLR-CQR_OLU"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ara ja tenim el training preparat. El provarem amb el validation a continuació"
      ],
      "metadata": {
        "id": "s6iyMBCr_33C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ENTRENAMENT"
      ],
      "metadata": {
        "id": "gvPO4Jzmvoal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tria_model(numero_model,weights):\n",
        "  if numero_model == 0:\n",
        "    alexnetbinary = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    alexnetbinary.classifier = nn.Sequential(\n",
        "    torch.nn.Linear(9216, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 512),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(512, 1)\n",
        "    )\n",
        "    pos_weight = torch.tensor(weights,device = device)\n",
        "    # print(pos_weight.shape)\n",
        "    # print(pos_weight)\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    return alexnetbinary,loss_fn\n",
        "\n",
        "  elif numero_model == 1:\n",
        "    resnetbinary = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
        "    resnetbinary.fc = nn.Linear(in_features=2048, out_features=1)\n",
        "\n",
        "    pos_weight = torch.tensor(weights,device = device)\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    return resnetbinary,loss_fn\n",
        "\n",
        "  elif numero_model == 2:\n",
        "    resnetbinary = models.resnet152(weights=\"IMAGENET1K_V1\")\n",
        "    num_features = resnetbinary.fc.in_features\n",
        "    resnetbinary.fc = nn.Linear(in_features=num_features, out_features=1)\n",
        "\n",
        "    pos_weight = torch.tensor(weights,device = device)\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    return resnetbinary,loss_fn\n",
        "\n",
        "  elif numero_model == 3:\n",
        "    googlenet = models.googlenet(weights=\"IMAGENET1K_V1\")\n",
        "    pos_weight = torch.tensor(weights,device = device)\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    num_features = googlenet.fc.in_features\n",
        "    googlenet.fc = nn.Linear(in_features=num_features, out_features=1)\n",
        "\n",
        "    return googlenet,loss_fn\n",
        "\n",
        "  elif numero_model == 4:\n",
        "    efficientnet = models.efficientnet_b3(weights='IMAGENET1K_V1')\n",
        "    pos_weight = torch.tensor(weights,device = device)\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    num_features = efficientnet.classifier[1].in_features\n",
        "    efficientnet.classifier[1] = nn.Linear(in_features=num_features, out_features=1)\n",
        "\n",
        "    return efficientnet,loss_fn\n",
        "\n",
        "  elif numero_model == 5:\n",
        "\n",
        "    alexnetmulticlass = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
        "    alexnetmulticlass.classifier[6] = nn.Linear(in_features=4096, out_features=7)\n",
        "\n",
        "    weights = torch.tensor(weights,device = device,dtype= torch.float32).squeeze(0)\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    return alexnetmulticlass,loss_fn\n",
        "\n",
        "  elif numero_model == 6:\n",
        "\n",
        "    resnetmulticlass = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
        "    num_features = resnetmulticlass.fc.in_features\n",
        "    resnetmulticlass.fc = nn.Linear(in_features=num_features, out_features=7)\n",
        "\n",
        "    weights = torch.tensor(weights,device = device,dtype= torch.float32).squeeze(0)\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    return resnetmulticlass,loss_fn\n",
        "\n",
        "  elif numero_model == 7:\n",
        "    resnetmulticlass152 = models.resnet152(weights=\"IMAGENET1K_V1\")\n",
        "    num_features = resnetmulticlass152.fc.in_features\n",
        "    resnetmulticlass152.fc = nn.Linear(in_features=num_features, out_features=7)\n",
        "\n",
        "    weights = torch.tensor(weights,device = device,dtype= torch.float32).squeeze(0)\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    return resnetmulticlass152,loss_fn\n",
        "\n",
        "  elif numero_model == 8:\n",
        "\n",
        "    googlenetmulticlass = models.googlenet(weights=\"IMAGENET1K_V1\")\n",
        "\n",
        "    weights = torch.tensor(weights,device = device,dtype= torch.float32).squeeze(0)\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    num_features = googlenetmulticlass.fc.in_features\n",
        "    googlenetmulticlass.fc = nn.Linear(in_features=num_features, out_features=1)\n",
        "\n",
        "    return googlenetmulticlass,loss_fn\n",
        "\n",
        "  elif numero_model == 9:\n",
        "\n",
        "    efficientnetmulticlass = models.efficientnet_b3(weights='IMAGENET1K_V1')\n",
        "    pos_weight = torch.tensor(weights,device = device)\n",
        "    loss_fn = nn.CrossEntropyLoss(pos_weight=pos_weight)\n",
        "\n",
        "    num_features = efficientnetmulticlass.fc.in_features\n",
        "    efficientnetmulticlass.fc = nn.Linear(in_features=num_features, out_features=7)\n",
        "\n",
        "    return efficientnet,loss_fn\n",
        "\n"
      ],
      "metadata": {
        "id": "n1UDZMclAYj5"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def converteix_a_binari(target):\n",
        "  #{'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3, 'akiec': 4, 'vasc': 5, 'df': 6}\n",
        "  diseases = {'0': 0,'1':1,'2': 0,'3': 1,'4':1,'5':0,'6':0}\n",
        "  target = ([[str(num.item())] for num in target])\n",
        "\n",
        "  mapped_tensor = torch.tensor([[diseases[num[0]]] for num in target])\n",
        "  return mapped_tensor"
      ],
      "metadata": {
        "id": "PsfeV3Yyek6F"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,loss_fn,dataloader,optimizer,epoch,device):\n",
        "\n",
        "  train_acc = 0\n",
        "  train_f1 = 0\n",
        "  train_recall = 0\n",
        "  train_precision = 0\n",
        "  train_loss = 0\n",
        "\n",
        "  for batch_num, (input_img, target) in tqdm(enumerate(dataloader), desc=f\"Batches (Època {epoch})\"):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_img = input_img.to(device)\n",
        "        output = model(input_img.to(device))\n",
        "\n",
        "        #print(output.shape[1])\n",
        "\n",
        "        if output.shape[1] > 1: #multiclass\n",
        "          a = 1\n",
        "        else: #binary\n",
        "          target = torch.unsqueeze(target, 1) #separa [1,2,3,4] en [[1],[2],[3]]\n",
        "          target = converteix_a_binari(target) #només si volem saber si la enfermetat es benigna o no\n",
        "\n",
        "        if output.shape[1] > 1:\n",
        "          target = target.to(device)\n",
        "          loss = loss_fn(output, target)\n",
        "        else:\n",
        "          target = target.to(device)\n",
        "          loss = loss_fn(output, target.float())\n",
        "\n",
        "\n",
        "        if output.shape[1] > 1:\n",
        "          output = torch.softmax(output,dim = 1) #calculam les probabilitats de cada classe a partir dels logits\n",
        "          output = output.argmax(dim=1) #obtenim la classe que té la probabilitat més alta de les 7\n",
        "          output = output.cpu().detach().numpy()\n",
        "        else:\n",
        "          output = torch.sigmoid(output)   #funció sigmoide per al cas binari\n",
        "          output = (output.cpu().detach().numpy() > 0.5).astype(int)\n",
        "\n",
        "        target = target.cpu().detach().numpy()\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            optimizer.step()\n",
        "\n",
        "        #print(f\"Pèrdua entrenament batch: {batch_num} epoch: {epoch+1}  train_loss: {loss.item()}\")\n",
        "        train_acc += accuracy_score(target,output)\n",
        "        train_f1 += f1_score(target,output,average='weighted',zero_division=1)\n",
        "        train_recall += recall_score(target,output,average='weighted',zero_division=1)\n",
        "        train_precision += precision_score(target,output,average='weighted',zero_division=1)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "  return train_acc,train_f1,train_recall,train_precision,train_loss\n"
      ],
      "metadata": {
        "id": "vjQynJrPzlxX"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model,loss_fn,data_loader,device):\n",
        "  val_acc = 0\n",
        "  val_f1 = 0\n",
        "  val_recall = 0\n",
        "  val_precision = 0\n",
        "  val_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for batch_num, (input_img, target) in enumerate(data_loader):\n",
        "\n",
        "            input_img = input_img.to(device)\n",
        "            output = model(input_img)\n",
        "\n",
        "\n",
        "            if output.shape[1] > 1: #multiclass\n",
        "              a = 1\n",
        "            else: #binary\n",
        "              target = torch.unsqueeze(target, 1) #separa [1,2,3,4] en [[1],[2],[3]]\n",
        "              target = converteix_a_binari(target) #només si volem saber si la enfermetat es benigna o no\n",
        "\n",
        "            if output.shape[1] > 1:\n",
        "              target = target.to(device)\n",
        "              loss = loss_fn(output, target)\n",
        "            else:\n",
        "              target = target.to(device)\n",
        "              loss = loss_fn(output, target.float())\n",
        "\n",
        "\n",
        "            if output.shape[1] > 1:\n",
        "              output = torch.softmax(output,dim = 1) #calculam les probabilitats de cada classe a partir dels logits\n",
        "              output = output.argmax(dim=1) #obtenim la classe que té la probabilitat més alta de les 7\n",
        "              output = output.cpu().detach().numpy()\n",
        "            else:\n",
        "              output = torch.sigmoid(output)   #funció sigmoide per al cas binari\n",
        "              output = (output.cpu().detach().numpy() > 0.5).astype(int)\n",
        "\n",
        "\n",
        "            target = target.cpu().detach().numpy()\n",
        "\n",
        "            val_acc  += accuracy_score(target,output)\n",
        "            val_f1 += f1_score(target,output,average='weighted',zero_division=1)\n",
        "            val_recall += recall_score(target,output,average='weighted',zero_division=1)\n",
        "            val_precision += precision_score(target,output,average='weighted',zero_division=1)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "  return val_acc,val_f1,val_recall,val_precision,val_loss"
      ],
      "metadata": {
        "id": "6EO8TgQl304Z"
      },
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import And\n",
        "def execute(model,loss_fn,train_loader,val_loader,test_loader,optimizer,epochs,device):\n",
        "\n",
        "  t_loss = np.zeros(epochs)\n",
        "  v_loss = np.zeros(epochs)\n",
        "  acc_t = np.zeros(epochs)\n",
        "  acc_v = np.zeros(epochs)\n",
        "  f1_t = np.zeros(epochs)\n",
        "  f1_v = np.zeros(epochs)\n",
        "  recall_t = np.zeros(epochs)\n",
        "  recall_v = np.zeros(epochs)\n",
        "\n",
        "\n",
        "  interval = 10\n",
        "  requerit = 0.03\n",
        "  last_loss = float('inf')\n",
        "\n",
        "  epoch_number = 0\n",
        "\n",
        "  pbar = tqdm(range(1, epochs + 1))  # tdqm permet tenir text dinàmic\n",
        "\n",
        "  for epoch in pbar:\n",
        "\n",
        "      train_loss = 0\n",
        "      train_acc = 0\n",
        "      train_precision = 0\n",
        "      train_f1 = 0\n",
        "      train_recall = 0\n",
        "      val_acc = 0\n",
        "      val_recall = 0\n",
        "      val_f1 = 0\n",
        "      val_loss = 0\n",
        "      val_precision = 0\n",
        "\n",
        "      batch_num = 1\n",
        "\n",
        "      train_acc,train_f1,train_recall,train_precision,train_loss = train(model,loss_fn,train_loader,optimizer,epoch,device)\n",
        "      val_acc,val_f1,val_recall,val_precision,val_loss  = validate(model,loss_fn,val_loader,device)\n",
        "\n",
        "      if WEIGHTSANDBIASES:\n",
        "\n",
        "        training_metrics = {\"train/train_loss\": train_loss/len(train_loader),\n",
        "                        \"train/train_acc\":train_acc/len(train_loader),\n",
        "                        \"train/train_f1\":train_f1/len(train_loader),\n",
        "                        \"train/train_recall\":train_recall/len(train_loader),\n",
        "                        \"train/train_precision\":train_precision/len(train_loader)}\n",
        "\n",
        "        val_metrics = {\"val/val_loss\": val_loss/len(val_loader),\n",
        "                      \"val/val_acc\":val_acc/len(val_loader),\n",
        "                      \"val/val_f1\":val_f1/len(val_loader),\n",
        "                      \"val/val_recall\": val_recall/len(val_loader),\n",
        "                      \"val/val_precision\": val_precision/len(val_loader)}\n",
        "\n",
        "        wandb.log({**training_metrics, **val_metrics})\n",
        "\n",
        "      # RESULTATS\n",
        "      train_loss /= len(train_loader)\n",
        "      train_acc /= len(train_loader)\n",
        "      train_f1 /= len(train_loader)\n",
        "      train_recall /= len(train_loader)\n",
        "      train_precision /= len(train_loader)\n",
        "\n",
        "      print(f\"Pèrdua entrenament epoch: {epoch}  train_loss: {train_loss}\")\n",
        "      print(f\"Accuracy train epoch: {epoch}  train_acc: {train_acc}\")\n",
        "      print(f\"F1 train epoch: {epoch}  train_f1: {train_f1}\")\n",
        "      print(f\"Recall train epoch: {epoch}  train_recall: {train_recall}\")\n",
        "\n",
        "      val_loss /= len(val_loader)\n",
        "      val_acc /= len(val_loader)\n",
        "      val_f1 /= len(val_loader)\n",
        "      val_recall /= len(val_loader)\n",
        "      val_precision /= len(val_loader)\n",
        "\n",
        "      print()\n",
        "      print()\n",
        "      print(f\"Pèrdua validació epoch: {epoch}  val_loss: {val_loss}\")\n",
        "      print(f\"Accuracy val epoch: {epoch}  val_acc: {val_acc}\")\n",
        "      print(f\"F1 val epoch: {epoch}  val_f1: {val_f1}\")\n",
        "      print(f\"Recall val epoch: {epoch}  val_recall: {val_recall}\")\n",
        "      print(f\"Recall val epoch: {epoch}  val_precision: {val_precision}\")\n",
        "\n",
        "\n",
        "\n",
        "      if interval > 0:\n",
        "        interval -= 1\n",
        "\n",
        "      if interval == 0:\n",
        "        if last_loss - requerit < train_loss:\n",
        "            print(\"Early Stopping, no hem reduït ni un 1.5% de loss respecte 10 èpoques!!\")\n",
        "            break\n",
        "        else:\n",
        "          interval = 10\n",
        "          last_loss = train_loss\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "-jUBGQHk5QwK"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model,dataloader,weights_dir,loss_fn,device):\n",
        "\n",
        "  model.load_state_dict(torch.load(weights_dir))\n",
        "\n",
        "  test_acc = 0\n",
        "  test_f1 = 0\n",
        "  test_recall = 0\n",
        "  test_precision = 0\n",
        "  test_loss = 0\n",
        "\n",
        "  json_obj = []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for batch_num, (input_img, target) in enumerate(dataloader):\n",
        "\n",
        "            input_img = input_img.to(device)\n",
        "            output = model(input_img)\n",
        "\n",
        "            dades = {}\n",
        "\n",
        "            if output.shape[1] > 1: #multiclass\n",
        "              a = 1\n",
        "            else: #binary\n",
        "              target = torch.unsqueeze(target, 1) #separa [1,2,3,4] en [[1],[2],[3]]\n",
        "              target = converteix_a_binari(target) #només si volem saber si la enfermetat es benigna o no\n",
        "\n",
        "            if output.shape[1] > 1:\n",
        "              target = target.to(device)\n",
        "              loss = loss_fn(output, target)\n",
        "            else:\n",
        "              target = target.to(device)\n",
        "              loss = loss_fn(output, target.float())\n",
        "\n",
        "\n",
        "            if output.shape[1] > 1:\n",
        "              output = torch.softmax(output,dim = 1) #calculam les probabilitats de cada classe a partir dels logits\n",
        "\n",
        "              dades[\"output\"] = output.cpu().detach().tolist() #guardam les probabilitats de l'output\n",
        "\n",
        "              output = output.argmax(dim=1) #obtenim la classe que té la probabilitat més alta de les 7\n",
        "              output = output.cpu().detach().numpy()\n",
        "            else:\n",
        "              output = torch.sigmoid(output)   #funció sigmoide per al cas binari\n",
        "\n",
        "              dades[\"output\"] = output.cpu().detach().tolist() #guardam les probabilitats de l'output\n",
        "\n",
        "              output = (output.cpu().detach().numpy() > 0.5).astype(int)\n",
        "\n",
        "            dades[\"target\"] = target.cpu().detach().tolist()\n",
        "\n",
        "            target = target.cpu().detach().numpy()\n",
        "\n",
        "            dades[\"top1-accuracy\"] = accuracy_score(target,output)\n",
        "            test_acc  += dades[\"top1-accuracy\"]\n",
        "            dades[\"f1-score\"] = f1_score(target,output,average='weighted',zero_division=1)\n",
        "            test_f1 += dades[\"f1-score\"]\n",
        "            dades[\"recall\"] = recall_score(target,output,average='weighted',zero_division=1)\n",
        "            test_recall += dades[\"recall\"]\n",
        "            dades[\"precision\"] = precision_score(target,output,average='weighted',zero_division=1)\n",
        "            test_precision += dades[\"precision\"]\n",
        "\n",
        "            dades[\"loss\"] = loss.item()\n",
        "            test_loss += dades[\"loss\"]\n",
        "\n",
        "            json_obj.append(dades)\n",
        "\n",
        "\n",
        "  return json_obj"
      ],
      "metadata": {
        "id": "D-ia9GpNgOqT"
      },
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def veure_imatges(train_data):\n",
        "  for i in range(len(train_data)):\n",
        "    path = train_data.__getpath__(i)\n",
        "    clean_img = cv2.imread(path)\n",
        "    mean, std = cv2.meanStdDev(clean_img)\n",
        "    clean_img = torch.tensor(clean_img)\n",
        "\n",
        "    imatge,label = train_data.__getitem__(i)\n",
        "\n",
        "    std = std.flatten()\n",
        "    mean = mean.flatten()\n",
        "    imatge = imatge * (std[:, None, None]) + (mean[:, None, None])\n",
        "\n",
        "    img_numpy = imatge.permute(1, 2, 0).numpy()  # Change from (C, H, W) to (H, W, C)\n",
        "    clean_img = clean_img.permute(1, 2, 0).numpy() #clean_img no es un torch\n",
        "\n",
        "    combined_image = np.concatenate((img_numpy, clean_img), axis=1)\n",
        "    cv2_imshow(combined_image)  #\n",
        "\n",
        "    time.sleep(5)\n",
        "    clear_output(wait=True)"
      ],
      "metadata": {
        "id": "O26Tu8uy9OaB"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "BINARY = True #Si volem que el resultat de la classificació sigui 0 i 1\n",
        "\n",
        "architectures = {'alexnet': 0,'resnet': 1,'resnet152':2,'googlenet':3,'efficientnet':4,'alexnetmulticlass':5,'resnet50multiclass':6,'resnet150multiclass':7,'googlenetmulticlass':8,'efficientnetmulticlass':9}\n",
        "nom_model = 'alexnet'\n",
        "MODEL = architectures[nom_model]\n",
        "\n",
        "TRAINING = 0.80\n",
        "VALIDATION = 0.10\n",
        "TESTING = 0.10\n",
        "SIZE = 224\n",
        "\n",
        "\n",
        "mean = torch.tensor([194.57463374, 139.13953272, 145.36132088]) /255 #rgb\n",
        "std = torch.tensor([35.92275236, 38.90347617, 43.33101831]) / 255\n",
        "\n",
        "TRANSFORMATIONS = []\n",
        "DISTRIBUTIONS = None\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((SIZE,SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = mean, std=std)\n",
        "])\n",
        "\n",
        "transform_training = transforms.Compose([\n",
        "    transforms.Resize((SIZE,SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.3),\n",
        "    transforms.RandomVerticalFlip(p=0.3),\n",
        "    #transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomRotation(degrees=20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),\n",
        "    #transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
        "    #transforms.RandomGrayscale(p=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = mean, std=std),\n",
        "])\n",
        "\n",
        "train_data,validation_data,test_data = load_sets(transform_training,transform,TRAINING,VALIDATION,TESTING,DISTRIBUTIONS)\n",
        "\n",
        "\n",
        "veure_imatges(train_data)\n",
        "\n",
        "EPOCHS = 60\n",
        "batch_size = 32\n",
        "\n",
        "binary_weights, multiple_weights = get_weights()\n",
        "\n",
        "if MODEL < 5:\n",
        "  weights = binary_weights\n",
        "else:\n",
        "  weights = multiple_weights\n",
        "\n",
        "\n",
        "learning_rate  = 1e-5\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model,loss_fn = tria_model(MODEL,weights)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "projectes = ['Ham10000-AlexnetBinary','Ham1000-ResnetBinary','Ham1000-Resnet152Binary','Ham10000-GoogleNetBinary','Ham10000-EfficientNetBinary',\n",
        "              'Ham10000-AlexnetMulticlass','Ham10000ResnetMulticlass','Ham10000Resnet152Multiclass','Ham10000-GoogleNetMulticlass','Ham10000-EfficientNetMulticlass']\n",
        "\n",
        "parametres_training = {\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"batch_size\": batch_size,\n",
        "                \"lr\": learning_rate,\n",
        "                \"trsize\":len(train_loader),\n",
        "                \"trdist\":TRAINING,\n",
        "                \"vsize\":len(val_loader),\n",
        "                \"vdist\":VALIDATION,\n",
        "                \"testsize\":len(test_loader),\n",
        "                \"testdist\": TESTING,\n",
        "                \"loss_weights\":weights,\n",
        "                \"data_augmentation\": str(transform_training)\n",
        "}\n",
        "\n",
        "carpeta_drive = '/content/drive/MyDrive/Runs/' + projectes[MODEL]\n",
        "os.makedirs(carpeta_drive, exist_ok=True) #cream la carpeta si no existeix\n",
        "\n",
        "current_runs = len([d for d in os.listdir(carpeta_drive) if os.path.isdir(os.path.join(carpeta_drive, d))]) #número d'execucions fetes de cada model\n",
        "\n",
        "#cada execució tindrà la seva carpeta numerada\n",
        "\n",
        "json_object = json.dumps(parametres_training,indent = 2)\n",
        "\n",
        "#cream la carpeta de l'execució\n",
        "\n",
        "num_execucio = str(current_runs)\n",
        "carpeta_execucio = carpeta_drive+\"/\"+ num_execucio\n",
        "os.makedirs(carpeta_execucio,exist_ok=True)\n",
        "\n",
        "#afegim la informació d'entrenament a la carpeta\n",
        "with open(carpeta_execucio+\"/training_info.json\", \"w\") as outfile:\n",
        "  outfile.write(json_object)\n",
        "\n",
        "\n",
        "if WEIGHTSANDBIASES:\n",
        "    wandb.init(\n",
        "            project=projectes[MODEL],\n",
        "            config={\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"batch_size\": batch_size,\n",
        "                \"lr\": learning_rate,\n",
        "                \"trsize\":len(train_loader),\n",
        "                \"trdist\":TRAINING,\n",
        "                \"vsize\":len(val_loader),\n",
        "                \"vdist\":VALIDATION,\n",
        "                \"weights\":weights,\n",
        "                })\n",
        "    config = wandb.config\n",
        "    print(config)\n",
        "\n",
        "#guardam els pesos a la carpeta de drive\n",
        "best_model = execute(model,loss_fn,train_loader,val_loader,test_loader,optimizer,EPOCHS,device)\n",
        "carpeta_pesos = carpeta_execucio+'/pesos_'+nom_model+'_'+num_execucio+'.pt'\n",
        "torch.save(model.state_dict(), carpeta_pesos )\n",
        "\n",
        "#també guardam els resultats del test a la carpeta de drive\n",
        "carpeta_pesos = carpeta_execucio+'/pesos_'+nom_model+'_'+str(current_runs)+'.pt'\n",
        "\n",
        "resultats = test(model,test_loader,carpeta_pesos,loss_fn,device)\n",
        "\n",
        "with open(carpeta_execucio+\"/testing_info.json\", \"w\") as outfile:\n",
        "    json.dump(resultats, outfile, indent=3)\n",
        "\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "9_VHfhYy6uO7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "57905c54-9d3c-420c-8698-622cbfa2049f"
      },
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 224 and the array at index 1 has size 600",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-265-6f79663586b2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mveure_imatges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-264-2f0edb30f7e4>\u001b[0m in \u001b[0;36mveure_imatges\u001b[0;34m(train_data)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mclean_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#clean_img no es un torch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcombined_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_image\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 224 and the array at index 1 has size 600"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "AlexNet.ipynb",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}