{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enVives/TFG/blob/main/EvaluacioArquitectures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v7z1Tb8sOhk",
        "outputId": "d0270c57-67b3-4c73-aeb6-d7bbfea8489d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import wandb\n",
        "import pylab as pl\n",
        "import json\n",
        "\n",
        "from glob import glob\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output,display\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "WEIGHTSANDBIASES = True\n",
        "DOWNLOAD = False\n",
        "CROPPING = False\n",
        "SEGMENTATION = False\n",
        "CLAHE = False\n",
        "\n",
        "# ORIGEN = '/content/drive/MyDrive/HAM10000/skin-cancer-mnist-ham10000/'\n",
        "\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "if DOWNLOAD:\n",
        "  !rm -rf /content/sample_data/*\n",
        "\n",
        "  !kaggle datasets download -d \"kmader/skin-cancer-mnist-ham10000\"\n",
        "\n",
        "  !unzip -o skin-cancer-mnist-ham10000.zip -d /content/sample_data/\n",
        "\n",
        "  !kaggle datasets download -d \"tschandl/ham10000-lesion-segmentations\"\n",
        "\n",
        "  !unzip -o ham10000-lesion-segmentations.zip -d /content/sample_data/\n",
        "\n",
        "#471be466c8949671a46c67e7aad0d5a0ac8c9dad\n",
        "\n",
        "if WEIGHTSANDBIASES:\n",
        "  wandb.login()\n",
        "\n",
        "#torch.cuda.default_stream(torch.device('cuda'))\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ZDX7scfqUSy_"
      },
      "outputs": [],
      "source": [
        "# !mkdir -p ~/.kaggle\n",
        "# !mv /content/kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcO_-eS1dYxM"
      },
      "source": [
        "!rm -rf /content/sample_data/*\n",
        "\n",
        "!kaggle datasets download -d \"kmader/skin-cancer-mnist-ham10000\"\n",
        "\n",
        "!unzip -o skin-cancer-mnist-ham10000.zip -d /content/sample_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugqDHdvBtZRA",
        "outputId": "12e0c90c-c7c3-437d-9a7a-8497f07511b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dx\n",
            "nv       6705\n",
            "mel      1113\n",
            "bkl      1099\n",
            "bcc       514\n",
            "akiec     327\n",
            "vasc      142\n",
            "df        115\n",
            "Name: count, dtype: int64\n",
            "\n",
            "dx\n",
            "nv       0.669496\n",
            "mel      0.111133\n",
            "bkl      0.109735\n",
            "bcc      0.051323\n",
            "akiec    0.032651\n",
            "vasc     0.014179\n",
            "df       0.011483\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "metadates = pd.read_csv('/content/sample_data/HAM10000_metadata.csv')\n",
        "metadates = metadates.sort_values(by='image_id')\n",
        "metadates.head()\n",
        "print(metadates['dx'].value_counts())\n",
        "print()\n",
        "print(metadates['dx'].value_counts() / sum(metadates['dx'].value_counts()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcJc98DVvHTr"
      },
      "source": [
        "nv: melanocytic nevi\n",
        "\n",
        "vasc: vascular lesions\n",
        "\n",
        "mel:melanoma\n",
        "\n",
        "df: dermatofibroma\n",
        "\n",
        "bkl: benign keratosis-like lesions\n",
        "\n",
        "bcc: basal cell carcinoma\n",
        "\n",
        "akiec: Actinic keratoses and intraepithelial carcinoma / Bowen's disease"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "6PHW-EVhnT3p"
      },
      "outputs": [],
      "source": [
        "class Formes(Dataset):\n",
        "  #Classe on gestionarem les imatges dels fitxers\n",
        "  dict_illnesses = {0 : 'nv', 1 : 'mel', 2 : 'bkl', 3 : 'bcc', 4 : 'akiec', 5 : 'vasc', 6 : 'df'}\n",
        "\n",
        "  def __init__(self, images, labels, transform):\n",
        "        super().__init__()\n",
        "        self.paths = images\n",
        "        self.labels = labels\n",
        "        self.len = len(self.paths)\n",
        "        self.transform = transform\n",
        "        #Per defecte pens que el color pot extreure característiques importants, per tant en primer lloc\n",
        "        #entrenarem les imatges de color\n",
        "        self.greyscale = False\n",
        "\n",
        "  def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "  def __setmasks__(self,masks):\n",
        "      self.masks = masks\n",
        "\n",
        "  def __getmask__(self,i):\n",
        "      return self.masks[i]\n",
        "\n",
        "  def __lenmasks__(self):\n",
        "    return len(self.masks)\n",
        "\n",
        "  def __addlabel__(self,label):\n",
        "    self.labels = np.append(self.labels,label)\n",
        "\n",
        "  def __addPath__(self,path):\n",
        "    self.paths = np.append(self.paths,path)\n",
        "\n",
        "  def __getdist__(self):\n",
        "    return pd.Series(self.labels).value_counts()\n",
        "\n",
        "  def __getlabels__(self):\n",
        "    classes = [[],[],[],[],[],[],[]]\n",
        "    for i in range(len(self.labels)):\n",
        "      classes[self.labels[i]].append(i) #afegim l'index\n",
        "    return classes\n",
        "\n",
        "  def __setgreyscale__(self,mode):\n",
        "    self.greyscale = mode\n",
        "\n",
        "  def __getpath__(self,index):\n",
        "    return self.paths[index]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      path = self.paths[index]\n",
        "      label = self.labels[index]\n",
        "\n",
        "      image = cv2.imread(path, cv2.IMREAD_GRAYSCALE if self.greyscale else cv2.IMREAD_COLOR)\n",
        "\n",
        "      if SEGMENTATION:\n",
        "        mask = cv2.imread(self.masks[index], cv2.IMREAD_GRAYSCALE)\n",
        "        _, mask_binaria = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "        image = cv2.bitwise_and(image, image, mask=mask_binaria)\n",
        "\n",
        "        non_black_pixels = np.where(image > 0)\n",
        "\n",
        "        x_min, x_max = np.min(non_black_pixels[1]), np.max(non_black_pixels[1])\n",
        "        y_min, y_max = np.min(non_black_pixels[0]), np.max(non_black_pixels[0])\n",
        "\n",
        "        marge = 10\n",
        "        if ((x_min - marge) >= 0):\n",
        "            x_min = x_min - marge\n",
        "        if ((x_max + marge) <= 224):\n",
        "            x_max = x_max + marge\n",
        "\n",
        "        if CROPPING:\n",
        "          image = image[y_min:y_max, x_min:x_max]\n",
        "\n",
        "        # print(cropped_image.shape)\n",
        "        image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "      #preprocessament\n",
        "      if CLAHE:\n",
        "        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=1.5, tileGridSize=(8,8))\n",
        "        l_clahe = clahe.apply(l)\n",
        "        lab_clahe = cv2.merge((l_clahe, a, b))\n",
        "        image = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      if self.greyscale:\n",
        "        image = Image.fromarray(image, mode=\"L\")\n",
        "      else:\n",
        "        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "      image = self.transform(image)\n",
        "\n",
        "      return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "-lKr3HM2VvhY"
      },
      "outputs": [],
      "source": [
        "def calcula_mitjana_desviacio(img_files_path):\n",
        "  mitjana = np.array([0.0, 0.0, 0.0], dtype=np.float64)\n",
        "  desviacio = np.array([0.0, 0.0, 0.0], dtype=np.float64)\n",
        "\n",
        "  x,y = 256,256\n",
        "  pixels_totals_canal = len(img_files_path) * x * y\n",
        "\n",
        "  for i in range(len(img_files_path)):\n",
        "    imatge = cv2.imread(img_files_path[i])\n",
        "    imatge = cv2.resize(imatge,(x,y))\n",
        "\n",
        "    canal_b, canal_g, canal_r = cv2.split(imatge)\n",
        "\n",
        "    mitjana += np.array([canal_r.sum(), canal_g.sum(), canal_b.sum()])\n",
        "    #desviacio += np.array([(canal_r**2).sum(), (canal_g**2).sum(), (canal_b**2).sum()])\n",
        "\n",
        "  mitjana = mitjana / pixels_totals_canal\n",
        "\n",
        "  for i in range(len(img_files_path)):\n",
        "    imatge = cv2.imread(img_files_path[i])\n",
        "    imatge = cv2.resize(imatge,(x,y))\n",
        "\n",
        "    canal_b, canal_g, canal_r = cv2.split(imatge)\n",
        "    desviacio += np.array([((canal_r-mitjana[0])**2).sum(), ((canal_g-mitjana[1])**2).sum(), ((canal_b-mitjana[2])**2).sum()])\n",
        "\n",
        "\n",
        "  desviacio = np.sqrt(desviacio / pixels_totals_canal)\n",
        "\n",
        "  return mitjana,desviacio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "LxaJdwKTtsfD"
      },
      "outputs": [],
      "source": [
        "def load_sets(transformation_training,transformation_default,training_dist,valitation_dist,testing_dist,distribution):\n",
        "\n",
        "  illnes_dictionary = {\n",
        "      'nv': 'Melanocytic nevi',\n",
        "      'mel': 'Melanoma',\n",
        "      'bkl': 'Benign keratosis-like lesions ',\n",
        "      'bcc': 'Basal cell carcinoma',\n",
        "      'akiec': 'Actinic keratoses and intraepithelial carcinoma / Bowens disease',\n",
        "      'vasc': 'Vascular lesions',\n",
        "      'df': 'Dermatofibroma'\n",
        "  }\n",
        "\n",
        "  img_files_1 = sorted(glob('/content/sample_data/HAM10000_images_part_1/*'))\n",
        "  img_files_2 = sorted(glob('/content/sample_data/HAM10000_images_part_2/*'))\n",
        "  img_files = img_files_1 + img_files_2\n",
        "\n",
        "  img_files = np.array(img_files)\n",
        "\n",
        "  mask_files = sorted(glob('/content/sample_data/HAM10000_segmentations_lesion_tschandl/*'))\n",
        "\n",
        "  imgid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in img_files}\n",
        "\n",
        "  mask_path_dict = {os.path.splitext(os.path.basename(x))[0].replace('_segmentation', ''): x for x in mask_files}\n",
        "\n",
        "  #print(mask_path_dict)\n",
        "\n",
        "  #{'ISIC_0024306_segmentation': '/content/sample_data/HAM10000_segmentations_lesion_tschandl/ISIC_0024306_segmentation.png'\n",
        "\n",
        "  metadates['path'] = metadates['image_id'].map(imgid_path_dict.get)\n",
        "  metadates['mask_path'] = metadates['image_id'].map(mask_path_dict.get)\n",
        "\n",
        "  metadates['illness'] = metadates['dx'].map(illnes_dictionary.get)\n",
        "  metadates['illness_code'] = metadates['dx'].map({'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3, 'akiec': 4, 'vasc': 5, 'df': 6})\n",
        "\n",
        "  #Aquest illness_code s'utilitzarà com a label de la enfermetat\n",
        "\n",
        "  img_number = len(img_files)\n",
        "\n",
        "  X = metadates.drop('illness_code',axis= 1)\n",
        "  y = metadates['illness_code']\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testing_dist, random_state=42, stratify=y)\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=valitation_dist/(training_dist+valitation_dist), random_state=42, stratify=y_train)\n",
        "\n",
        "  #Una bona idea seria aplicar data augmentation al conjunt d'entrenament ja que les classes estan molt desbalancejades\n",
        "  #Una altra bona idea seria emplear una funció de pèrdua que tengui en compte les classes desbalancejades.\n",
        "\n",
        "  #Antes de guardar els datasets en classes Formes, hauriem de caluclar la mitjana i desviació típica de les imatges\n",
        "  train_data = Formes(X_train['path'].to_numpy(),y_train.to_numpy(),transformation_training)\n",
        "  test_data = Formes(X_test['path'].to_numpy(),y_test.to_numpy(),transformation_default)\n",
        "  validation_data = Formes(X_val['path'].to_numpy(),y_val.to_numpy(),transformation_default)\n",
        "\n",
        "  if SEGMENTATION:\n",
        "\n",
        "    train_data.__setmasks__(X_train['mask_path'].to_numpy())\n",
        "    test_data.__setmasks__(X_test['mask_path'].to_numpy())\n",
        "    validation_data.__setmasks__(X_val['mask_path'].to_numpy())\n",
        "\n",
        "  return train_data, validation_data,test_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "XYwfwJII_rFe"
      },
      "outputs": [],
      "source": [
        "def get_weights():\n",
        "\n",
        "  #diseases = {'0': 0,'1':1,'2': 0,'3': 1,'4':1,'5':0,'6':0}\n",
        "\n",
        "  valors = metadates['dx'].value_counts()\n",
        "  illnesses = valors.keys()\n",
        "  weights = np.zeros(len(illnesses))\n",
        "\n",
        "  i = 0\n",
        "  for x in illnesses:\n",
        "    y = valors[x]\n",
        "    weights[i] = valors.sum() / y\n",
        "    i+= 1\n",
        "\n",
        "  weights = weights / weights.sum()\n",
        "\n",
        "  return (1 - (weights[1]+weights[3]+weights[4])) / (weights[1]+weights[3]+weights[4]) ,weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiiMdFnMB-Qx"
      },
      "source": [
        "![Captura de pantalla 2025-01-28 232832.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "qvLR-CQR_OLU"
      },
      "outputs": [],
      "source": [
        "#veure_imatges(train_data,std,mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6iyMBCr_33C"
      },
      "source": [
        "Ara ja tenim el training preparat. El provarem amb el validation a continuació"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvPO4Jzmvoal"
      },
      "source": [
        "##ENTRENAMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "n1UDZMclAYj5"
      },
      "outputs": [],
      "source": [
        "def tria_model(numero_model,weights):\n",
        "  if numero_model == 0:\n",
        "    alexnetbinary = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    alexnetbinary.classifier = nn.Sequential(\n",
        "    torch.nn.Linear(9216, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 512),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(512, 1)\n",
        "    )\n",
        "    pos_weight = torch.tensor(weights,device = device)\n",
        "    # print(pos_weight.shape)\n",
        "    # print(pos_weight)\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    return alexnetbinary,loss_fn\n",
        "\n",
        "  # elif numero_model == 1:\n",
        "  #   resnetbinary = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
        "  #   resnetbinary.fc = nn.Linear(in_features=2048, out_features=1)\n",
        "\n",
        "  #   pos_weight = torch.tensor(weights,device = device)\n",
        "  #   loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "  #   return resnetbinary,loss_fn\n",
        "\n",
        "  elif numero_model == 1:\n",
        "    resnetbinary = models.resnet152(weights=\"IMAGENET1K_V1\")\n",
        "    num_features = resnetbinary.fc.in_features\n",
        "    resnetbinary.fc = nn.Linear(in_features=num_features, out_features=1)\n",
        "\n",
        "    pos_weight = torch.tensor(weights,device = device)\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    return resnetbinary,loss_fn\n",
        "\n",
        "  elif numero_model == 2:\n",
        "    googlenet = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1, aux_logits=True)\n",
        "    pos_weight = torch.tensor(weights,device = device)\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    googlenet.aux_logits = False\n",
        "\n",
        "    num_features = googlenet.fc.in_features\n",
        "    googlenet.fc = nn.Linear(in_features=num_features, out_features=1)\n",
        "\n",
        "    return googlenet,loss_fn\n",
        "\n",
        "  elif numero_model == 3:\n",
        "    efficientnet = models.efficientnet_b1(weights='IMAGENET1K_V1')\n",
        "    pos_weight = torch.tensor(weights,device = device)\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    num_features = efficientnet.classifier[1].in_features\n",
        "    efficientnet.classifier[1] = nn.Linear(in_features=num_features, out_features=1)\n",
        "\n",
        "    return efficientnet,loss_fn\n",
        "\n",
        "  elif numero_model == 4:\n",
        "\n",
        "    alexnetmulticlass = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
        "    alexnetmulticlass.classifier[6] = nn.Linear(in_features=4096, out_features=7)\n",
        "\n",
        "    weights = torch.tensor(weights,device = device,dtype= torch.float32).squeeze(0)\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    return alexnetmulticlass,loss_fn\n",
        "\n",
        "  # elif numero_model == 6:\n",
        "\n",
        "  #   resnetmulticlass = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
        "  #   num_features = resnetmulticlass.fc.in_features\n",
        "  #   resnetmulticlass.fc = nn.Linear(in_features=num_features, out_features=7)\n",
        "\n",
        "  #   weights = torch.tensor(weights,device = device,dtype= torch.float32).squeeze(0)\n",
        "  #   loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "  #   return resnetmulticlass,loss_fn\n",
        "\n",
        "  elif numero_model == 5:\n",
        "    resnetmulticlass152 = models.resnet152(weights=\"IMAGENET1K_V1\")\n",
        "    num_features = resnetmulticlass152.fc.in_features\n",
        "    resnetmulticlass152.fc = nn.Linear(in_features=num_features, out_features=7)\n",
        "\n",
        "    weights = torch.tensor(weights,device = device,dtype= torch.float32).squeeze(0)\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    return resnetmulticlass152,loss_fn\n",
        "\n",
        "  elif numero_model == 6:\n",
        "\n",
        "    googlenetmulticlass = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    weights = torch.tensor(weights,device = device,dtype= torch.float32).squeeze(0)\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    num_features = googlenetmulticlass.fc.in_features\n",
        "    googlenetmulticlass.fc = nn.Linear(in_features=num_features, out_features=1)\n",
        "\n",
        "    return googlenetmulticlass,loss_fn\n",
        "\n",
        "  elif numero_model == 7:\n",
        "\n",
        "    efficientnetmulticlass = models.efficientnet_b1(weights='IMAGENET1K_V1')\n",
        "\n",
        "    weights = torch.tensor(weights,device = device,dtype= torch.float32).squeeze(0)\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    num_features = efficientnetmulticlass.classifier[1].in_features\n",
        "    efficientnetmulticlass.classifier[1] = nn.Linear(in_features=num_features, out_features=7)\n",
        "\n",
        "    return efficientnetmulticlass,loss_fn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "PsfeV3Yyek6F"
      },
      "outputs": [],
      "source": [
        "def converteix_a_binari(target):\n",
        "  #{'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3, 'akiec': 4, 'vasc': 5, 'df': 6}\n",
        "  diseases = {'0': 0,'1':1,'2': 0,'3': 1,'4':1,'5':0,'6':0}\n",
        "  target = ([[str(num.item())] for num in target])\n",
        "\n",
        "  mapped_tensor = torch.tensor([[diseases[num[0]]] for num in target])\n",
        "  return mapped_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "vjQynJrPzlxX"
      },
      "outputs": [],
      "source": [
        "def train(model,loss_fn,dataloader,optimizer,epoch,device):\n",
        "\n",
        "  train_acc = 0\n",
        "  train_f1 = 0\n",
        "  train_recall = 0\n",
        "  train_precision = 0\n",
        "  train_loss = 0\n",
        "\n",
        "  for batch_num, (input_img, target) in tqdm(enumerate(dataloader), desc=f\"Batches (Època {epoch})\"):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_img = input_img.to(device)\n",
        "        output = model(input_img.to(device))\n",
        "\n",
        "        if isinstance(output, tuple) or hasattr(output, 'logits'):\n",
        "                output = output.logits\n",
        "\n",
        "        #print(output.shape[1])\n",
        "\n",
        "        if output.shape[1] > 1: #multiclass\n",
        "          a = 1\n",
        "        else: #binary\n",
        "          target = torch.unsqueeze(target, 1) #separa [1,2,3,4] en [[1],[2],[3]]\n",
        "          target = converteix_a_binari(target) #només si volem saber si la enfermetat es benigna o no\n",
        "\n",
        "        if output.shape[1] > 1:\n",
        "          target = target.to(device)\n",
        "          loss = loss_fn(output, target)\n",
        "        else:\n",
        "          target = target.to(device)\n",
        "          loss = loss_fn(output, target.float())\n",
        "\n",
        "\n",
        "        if output.shape[1] > 1:\n",
        "          output = torch.softmax(output,dim = 1) #calculam les probabilitats de cada classe a partir dels logits\n",
        "          output = output.argmax(dim=1) #obtenim la classe que té la probabilitat més alta de les 7\n",
        "          output = output.cpu().detach().numpy()\n",
        "        else:\n",
        "          output = torch.sigmoid(output)   #funció sigmoide per al cas binari\n",
        "          output = (output.cpu().detach().numpy() > 0.5).astype(int)\n",
        "\n",
        "        target = target.cpu().detach().numpy()\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            optimizer.step()\n",
        "\n",
        "        #print(f\"Pèrdua entrenament batch: {batch_num} epoch: {epoch+1}  train_loss: {loss.item()}\")\n",
        "        train_acc += accuracy_score(target,output)\n",
        "        train_f1 += f1_score(target,output,average='weighted',zero_division=1)\n",
        "        train_recall += recall_score(target,output,average='weighted',zero_division=1)\n",
        "        train_precision += precision_score(target,output,average='weighted',zero_division=1)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "  return train_acc,train_f1,train_recall,train_precision,train_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "6EO8TgQl304Z"
      },
      "outputs": [],
      "source": [
        "def validate(model,loss_fn,data_loader,device):\n",
        "  val_acc = 0\n",
        "  val_f1 = 0\n",
        "  val_recall = 0\n",
        "  val_precision = 0\n",
        "  val_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for batch_num, (input_img, target) in enumerate(data_loader):\n",
        "\n",
        "            input_img = input_img.to(device)\n",
        "            output = model(input_img)\n",
        "\n",
        "            if isinstance(output, tuple) or hasattr(output, 'logits'):\n",
        "                output = output.logits\n",
        "\n",
        "\n",
        "            if output.shape[1] > 1: #multiclass\n",
        "              a = 1\n",
        "            else: #binary\n",
        "              target = torch.unsqueeze(target, 1) #separa [1,2,3,4] en [[1],[2],[3]]\n",
        "              target = converteix_a_binari(target) #només si volem saber si la enfermetat es benigna o no\n",
        "\n",
        "            if output.shape[1] > 1:\n",
        "              target = target.to(device)\n",
        "              loss = loss_fn(output, target)\n",
        "            else:\n",
        "              target = target.to(device)\n",
        "              loss = loss_fn(output, target.float())\n",
        "\n",
        "\n",
        "            if output.shape[1] > 1:\n",
        "              output = torch.softmax(output,dim = 1) #calculam les probabilitats de cada classe a partir dels logits\n",
        "              output = output.argmax(dim=1) #obtenim la classe que té la probabilitat més alta de les 7\n",
        "              output = output.cpu().detach().numpy()\n",
        "            else:\n",
        "              output = torch.sigmoid(output)   #funció sigmoide per al cas binari\n",
        "              output = (output.cpu().detach().numpy() > 0.5).astype(int)\n",
        "\n",
        "\n",
        "            target = target.cpu().detach().numpy()\n",
        "\n",
        "            val_acc  += accuracy_score(target,output)\n",
        "            val_f1 += f1_score(target,output,average='weighted',zero_division=1)\n",
        "            val_recall += recall_score(target,output,average='weighted',zero_division=1)\n",
        "            val_precision += precision_score(target,output,average='weighted',zero_division=1)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "  return val_acc,val_f1,val_recall,val_precision,val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "-jUBGQHk5QwK"
      },
      "outputs": [],
      "source": [
        "from ast import And\n",
        "def execute(model,loss_fn,train_loader,val_loader,test_loader,optimizer,epochs,device):\n",
        "\n",
        "  t_loss = np.zeros(epochs)\n",
        "  v_loss = np.zeros(epochs)\n",
        "  acc_t = np.zeros(epochs)\n",
        "  acc_v = np.zeros(epochs)\n",
        "  f1_t = np.zeros(epochs)\n",
        "  f1_v = np.zeros(epochs)\n",
        "  recall_t = np.zeros(epochs)\n",
        "  recall_v = np.zeros(epochs)\n",
        "\n",
        "\n",
        "  interval = 5\n",
        "  requerit = 0.010\n",
        "  last_loss = float('inf')\n",
        "\n",
        "  epoch_number = 0\n",
        "\n",
        "  pbar = tqdm(range(1, epochs + 1))  # tdqm permet tenir text dinàmic\n",
        "\n",
        "  for epoch in pbar:\n",
        "\n",
        "      train_loss = 0\n",
        "      train_acc = 0\n",
        "      train_precision = 0\n",
        "      train_f1 = 0\n",
        "      train_recall = 0\n",
        "      val_acc = 0\n",
        "      val_recall = 0\n",
        "      val_f1 = 0\n",
        "      val_loss = 0\n",
        "      val_precision = 0\n",
        "\n",
        "      batch_num = 1\n",
        "\n",
        "      train_acc,train_f1,train_recall,train_precision,train_loss = train(model,loss_fn,train_loader,optimizer,epoch,device)\n",
        "      val_acc,val_f1,val_recall,val_precision,val_loss  = validate(model,loss_fn,val_loader,device)\n",
        "\n",
        "      if WEIGHTSANDBIASES:\n",
        "\n",
        "        training_metrics = {\"train/train_loss\": train_loss/len(train_loader),\n",
        "                        \"train/train_acc\":train_acc/len(train_loader),\n",
        "                        \"train/train_f1\":train_f1/len(train_loader),\n",
        "                        \"train/train_recall\":train_recall/len(train_loader),\n",
        "                        \"train/train_precision\":train_precision/len(train_loader)}\n",
        "\n",
        "        val_metrics = {\"val/val_loss\": val_loss/len(val_loader),\n",
        "                      \"val/val_acc\":val_acc/len(val_loader),\n",
        "                      \"val/val_f1\":val_f1/len(val_loader),\n",
        "                      \"val/val_recall\": val_recall/len(val_loader),\n",
        "                      \"val/val_precision\": val_precision/len(val_loader)}\n",
        "\n",
        "        wandb.log({**training_metrics, **val_metrics})\n",
        "\n",
        "      # RESULTATS\n",
        "      train_loss /= len(train_loader)\n",
        "      train_acc /= len(train_loader)\n",
        "      train_f1 /= len(train_loader)\n",
        "      train_recall /= len(train_loader)\n",
        "      train_precision /= len(train_loader)\n",
        "\n",
        "      print(f\"Pèrdua entrenament epoch: {epoch}  train_loss: {train_loss}\")\n",
        "      print(f\"Accuracy train epoch: {epoch}  train_acc: {train_acc}\")\n",
        "      print(f\"F1 train epoch: {epoch}  train_f1: {train_f1}\")\n",
        "      print(f\"Recall train epoch: {epoch}  train_recall: {train_recall}\")\n",
        "\n",
        "      val_loss /= len(val_loader)\n",
        "      val_acc /= len(val_loader)\n",
        "      val_f1 /= len(val_loader)\n",
        "      val_recall /= len(val_loader)\n",
        "      val_precision /= len(val_loader)\n",
        "\n",
        "      print()\n",
        "      print()\n",
        "      print(f\"Pèrdua validació epoch: {epoch}  val_loss: {val_loss}\")\n",
        "      print(f\"Accuracy val epoch: {epoch}  val_acc: {val_acc}\")\n",
        "      print(f\"F1 val epoch: {epoch}  val_f1: {val_f1}\")\n",
        "      print(f\"Recall val epoch: {epoch}  val_recall: {val_recall}\")\n",
        "      print(f\"Recall val epoch: {epoch}  val_precision: {val_precision}\")\n",
        "\n",
        "\n",
        "\n",
        "      if interval > 0:\n",
        "        interval -= 1\n",
        "\n",
        "      if interval == 0:\n",
        "        if last_loss - requerit < train_loss:\n",
        "            print(\"Early Stopping, no hem reduït ni un 0.03 de loss respecte 10 èpoques!!\")\n",
        "            break\n",
        "        else:\n",
        "          interval = 5\n",
        "          last_loss = train_loss\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "D-ia9GpNgOqT"
      },
      "outputs": [],
      "source": [
        "def test(model,dataloader,weights_dir,loss_fn,device):\n",
        "\n",
        "  model.load_state_dict(torch.load(weights_dir))\n",
        "\n",
        "  test_acc = 0\n",
        "  test_f1 = 0\n",
        "  test_recall = 0\n",
        "  test_precision = 0\n",
        "  test_loss = 0\n",
        "\n",
        "  json_obj = []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for batch_num, (input_img, target) in enumerate(dataloader):\n",
        "\n",
        "            input_img = input_img.to(device)\n",
        "            output = model(input_img)\n",
        "\n",
        "            if isinstance(output, tuple) or hasattr(output, 'logits'):\n",
        "                output = output.logits\n",
        "\n",
        "            dades = {}\n",
        "\n",
        "            if output.shape[1] > 1: #multiclass\n",
        "              a = 1\n",
        "            else: #binary\n",
        "              target = torch.unsqueeze(target, 1) #separa [1,2,3,4] en [[1],[2],[3]]\n",
        "              target = converteix_a_binari(target) #només si volem saber si la enfermetat es benigna o no\n",
        "\n",
        "            if output.shape[1] > 1:\n",
        "              target = target.to(device)\n",
        "              loss = loss_fn(output, target)\n",
        "            else:\n",
        "              target = target.to(device)\n",
        "              loss = loss_fn(output, target.float())\n",
        "\n",
        "\n",
        "            if output.shape[1] > 1:\n",
        "              output = torch.softmax(output,dim = 1) #calculam les probabilitats de cada classe a partir dels logits\n",
        "\n",
        "              dades[\"output\"] = output.cpu().detach().tolist() #guardam les probabilitats de l'output\n",
        "\n",
        "              output = output.argmax(dim=1) #obtenim la classe que té la probabilitat més alta de les 7\n",
        "              output = output.cpu().detach().numpy()\n",
        "            else:\n",
        "              output = torch.sigmoid(output)   #funció sigmoide per al cas binari\n",
        "\n",
        "              dades[\"output\"] = output.cpu().detach().tolist() #guardam les probabilitats de l'output\n",
        "\n",
        "              output = (output.cpu().detach().numpy() > 0.5).astype(int)\n",
        "\n",
        "            dades[\"target\"] = target.cpu().detach().tolist()\n",
        "\n",
        "            target = target.cpu().detach().numpy()\n",
        "\n",
        "            dades[\"top1-accuracy\"] = accuracy_score(target,output)\n",
        "            test_acc  += dades[\"top1-accuracy\"]\n",
        "            dades[\"f1-score\"] = f1_score(target,output,average='weighted',zero_division=1)\n",
        "            test_f1 += dades[\"f1-score\"]\n",
        "            dades[\"recall\"] = recall_score(target,output,average='weighted',zero_division=1)\n",
        "            test_recall += dades[\"recall\"]\n",
        "            dades[\"precision\"] = precision_score(target,output,average='weighted',zero_division=1)\n",
        "            test_precision += dades[\"precision\"]\n",
        "\n",
        "            dades[\"loss\"] = loss.item()\n",
        "            test_loss += dades[\"loss\"]\n",
        "\n",
        "            json_obj.append(dades)\n",
        "\n",
        "\n",
        "  return json_obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "O26Tu8uy9OaB"
      },
      "outputs": [],
      "source": [
        "def veure_imatges(train_data):\n",
        "  for i in range(len(train_data)):\n",
        "    path = train_data.__getpath__(i)\n",
        "    clean_img = cv2.imread(path)\n",
        "    mean, std = cv2.meanStdDev(clean_img)\n",
        "\n",
        "    clean_img = cv2.resize(clean_img, (224, 224))\n",
        "    clean_img = torch.tensor(clean_img).permute(2, 0, 1)  # Convert to (C, H, W)\n",
        "\n",
        "    print(clean_img.shape)\n",
        "\n",
        "    imatge,label = train_data.__getitem__(i)\n",
        "    print(imatge.shape)\n",
        "    std = std.flatten()\n",
        "    mean = mean.flatten()\n",
        "    imatge = imatge * (std[:, None, None]) + (mean[:, None, None])\n",
        "\n",
        "    img_numpy = imatge.permute(1, 2, 0).numpy()  # Change from (C, H, W) to (H, W, C)\n",
        "    clean_img = clean_img.permute(1, 2, 0).numpy() #clean_img no es un torch\n",
        "\n",
        "    combined_image = np.concatenate((img_numpy, clean_img), axis=1)\n",
        "    cv2_imshow(combined_image)\n",
        "\n",
        "    time.sleep(5)\n",
        "    clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cf24b1826b274525a4e1f0c4d8f866c9",
            "5e8f6225623c4afe95c4e458476d675c",
            "2910ad0d8bfe4775a698d3663618808d",
            "c333eb4741894a6ea84490febcfc5679",
            "151b0a12a8bd45dbbe7155af3778f823",
            "48ba1020a770442686d61a0b69bb3954",
            "e45c024ef94140128be8d912ed427226",
            "cf606f0632a94b1d96fc98d82d76550c",
            "14d76ae178a84b9ab0f05b19e1eb90bb",
            "33fdf8631e25435ea18f8c99f669989e",
            "2db0fd3b9110436da86208b9b12e10f0",
            "fd29651bb8054adcaedce76707950d43",
            "501e3065f63e4f46a1b8432d38c03368",
            "8e83c21ecb534ab98957155b8a0e20d8",
            "fc95d7a3e953405bb663abbbc3c340f6",
            "3a717f40910446c99ee745d4fb4cfe35",
            "1220ca5b999c4e62a92349b319406b37",
            "58b83b1894404cbcbadd693da831569b",
            "3f66b123bdb644f0bad1f07210eec759",
            "11611a4ddc6348e49e8e73ea67903fc0",
            "2dad41a1ceea4549bc5870ed655a07a6",
            "188bd4217cd34b06aad41ecc5b50c20b"
          ]
        },
        "id": "9_VHfhYy6uO7",
        "outputId": "00dbf32f-924a-471b-83b7-03dabb5027e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.00657042 0.03958192 0.04008614 0.08570948 0.13472377 0.31024417\n",
            " 0.3830841 ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/train_acc</td><td>▁█</td></tr><tr><td>train/train_f1</td><td>▁█</td></tr><tr><td>train/train_loss</td><td>█▁</td></tr><tr><td>train/train_precision</td><td>▁█</td></tr><tr><td>train/train_recall</td><td>▁█</td></tr><tr><td>val/val_acc</td><td>▁█</td></tr><tr><td>val/val_f1</td><td>▁█</td></tr><tr><td>val/val_loss</td><td>█▁</td></tr><tr><td>val/val_precision</td><td>▁█</td></tr><tr><td>val/val_recall</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/train_acc</td><td>0.79896</td></tr><tr><td>train/train_f1</td><td>0.81905</td></tr><tr><td>train/train_loss</td><td>0.57156</td></tr><tr><td>train/train_precision</td><td>0.87078</td></tr><tr><td>train/train_recall</td><td>0.79896</td></tr><tr><td>val/val_acc</td><td>0.81582</td></tr><tr><td>val/val_f1</td><td>0.83186</td></tr><tr><td>val/val_loss</td><td>0.54814</td></tr><tr><td>val/val_precision</td><td>0.87783</td></tr><tr><td>val/val_recall</td><td>0.81582</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">swept-lion-8</strong> at: <a href='https://wandb.ai/pjvivesmorey-uib/Ham10000-Inceptionv3Binary/runs/uuxu63sx' target=\"_blank\">https://wandb.ai/pjvivesmorey-uib/Ham10000-Inceptionv3Binary/runs/uuxu63sx</a><br> View project at: <a href='https://wandb.ai/pjvivesmorey-uib/Ham10000-Inceptionv3Binary' target=\"_blank\">https://wandb.ai/pjvivesmorey-uib/Ham10000-Inceptionv3Binary</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250527_091108-uuxu63sx/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250527_091636-90ppulvr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/pjvivesmorey-uib/Ham10000-Inceptionv3Multiclass/runs/90ppulvr' target=\"_blank\">true-darkness-2</a></strong> to <a href='https://wandb.ai/pjvivesmorey-uib/Ham10000-Inceptionv3Multiclass' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/pjvivesmorey-uib/Ham10000-Inceptionv3Multiclass' target=\"_blank\">https://wandb.ai/pjvivesmorey-uib/Ham10000-Inceptionv3Multiclass</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/pjvivesmorey-uib/Ham10000-Inceptionv3Multiclass/runs/90ppulvr' target=\"_blank\">https://wandb.ai/pjvivesmorey-uib/Ham10000-Inceptionv3Multiclass/runs/90ppulvr</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epochs': 60, 'batch_size': 32, 'lr': 1e-05, 'trsize': 251, 'trdist': 0.8, 'vsize': 32, 'vdist': 0.1, 'weights': [0.0065704208816761995, 0.03958191555403316, 0.04008614377765142, 0.08570947862186559, 0.13472376761969088, 0.31024416909604874, 0.383084104449034], 'CLAHE': False}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/60 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf24b1826b274525a4e1f0c4d8f866c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches (Època 1): 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd29651bb8054adcaedce76707950d43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'InceptionOutputs' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-5d2027763575>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;31m#guardam els pesos a la carpeta de drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0mcarpeta_pesos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcarpeta_execucio\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/pesos_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnom_model\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnum_execucio\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcarpeta_pesos\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-c9c9f83c26b8>\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(model, loss_fn, train_loader, val_loader, test_loader, optimizer, epochs, device)\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0mbatch_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_f1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_recall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_precision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m       \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_f1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_recall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_precision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loss\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-659ff602a261>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, dataloader, optimizer, epoch, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#print(output.shape[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#multiclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m           \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'InceptionOutputs' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "from itertools import product\n",
        "BINARY = False #Si volem que el resultat de la classificació sigui 0 i 1\n",
        "\n",
        "architectures = {'alexnet': 0,'resnet152':1,'inceptionv3':2,'efficientnetb1':3,'alexnetmulticlass':4,'resnet152multiclass':5,'inceptionv3multiclass':6,'efficientnetb1multiclass':7}\n",
        "img_sizes = {'alexnet': 224,'resnet152':224,'inceptionv3':299,'efficientnetb1':224,'alexnetmulticlass':224,'resnet152multiclass':224,'inceptionv3multiclass':299,'efficientnetb1multiclass':224}\n",
        "\n",
        "nom_model = 'inceptionv3multiclass'\n",
        "MODEL = architectures[nom_model]\n",
        "\n",
        "TRAINING = 0.80\n",
        "VALIDATION = 0.10\n",
        "TESTING = 0.10\n",
        "SIZE = img_sizes[nom_model]\n",
        "\n",
        "\n",
        "mean = torch.tensor([194.57463374, 139.13953272, 145.36132088]) /255 #rgb\n",
        "std = torch.tensor([35.92275236, 38.90347617, 43.33101831]) / 255\n",
        "\n",
        "TRANSFORMATIONS = []\n",
        "DISTRIBUTIONS = None\n",
        "\n",
        "if SEGMENTATION == False:\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize((SIZE,SIZE)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean = mean, std=std)\n",
        "  ])\n",
        "\n",
        "  transform_training = transforms.Compose([\n",
        "      transforms.Resize((SIZE,SIZE)),\n",
        "      transforms.RandomHorizontalFlip(p=0.3),\n",
        "      transforms.RandomVerticalFlip(p=0.3),\n",
        "      transforms.RandomRotation(degrees=20),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean = mean, std=std),\n",
        "  ])\n",
        "else:\n",
        "  transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean = mean, std=std)\n",
        "  ])\n",
        "\n",
        "  transform_training = transforms.Compose([\n",
        "      transforms.RandomHorizontalFlip(p=0.3),\n",
        "      transforms.RandomVerticalFlip(p=0.3),\n",
        "      transforms.RandomRotation(degrees=20),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean = mean, std=std),\n",
        "  ])\n",
        "\n",
        "CLAHE = False\n",
        "train_data,validation_data,test_data = load_sets(transform_training,transform,TRAINING,VALIDATION,TESTING,DISTRIBUTIONS)\n",
        "\n",
        "\n",
        "EPOCHS = 60\n",
        "batch_size = 32\n",
        "\n",
        "binary_weights, multiple_weights = get_weights()\n",
        "\n",
        "if MODEL < 4:\n",
        "  weights = binary_weights\n",
        "else:\n",
        "  weights = multiple_weights\n",
        "\n",
        "print(weights)\n",
        "learning_rate  = 1e-5\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model,loss_fn = tria_model(MODEL,weights)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "projectes = ['Ham10000-AlexnetBinary','Ham1000-Resnet152Binary','Ham10000-Inceptionv3Binary','Ham10000-EfficientNetB1Binary',\n",
        "              'Ham10000-AlexnetMulticlass','Ham10000Resnet152Multiclass','Ham10000-Inceptionv3Multiclass','Ham10000-EfficientNetB1Multiclass']\n",
        "\n",
        "if WEIGHTSANDBIASES:\n",
        "    wandb.init(\n",
        "            project=projectes[MODEL],\n",
        "            config={\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"batch_size\": batch_size,\n",
        "                \"lr\": learning_rate,\n",
        "                \"trsize\":len(train_loader),\n",
        "                \"trdist\":TRAINING,\n",
        "                \"vsize\":len(val_loader),\n",
        "                \"vdist\":VALIDATION,\n",
        "                \"weights\":weights,\n",
        "                \"CLAHE\": CLAHE,\n",
        "                })\n",
        "    config = wandb.config\n",
        "    print(config)\n",
        "\n",
        "\n",
        "parametres_training = {\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"batch_size\": batch_size,\n",
        "                \"lr\": learning_rate,\n",
        "                \"trsize\":len(train_loader),\n",
        "                \"trdist\":TRAINING,\n",
        "                \"vsize\":len(val_loader),\n",
        "                \"vdist\":VALIDATION,\n",
        "                \"testsize\":len(test_loader),\n",
        "                \"testdist\": TESTING,\n",
        "                \"loss_weights\":str(weights),\n",
        "                \"SEGMENTATION\": SEGMENTATION,\n",
        "                \"CROPPING\": CROPPING,\n",
        "                \"img_size\": SIZE,\n",
        "                \"random_state\": 42,\n",
        "                \"WeightsAndBiases\": wandb.run.get_url(),\n",
        "                \"data_augmentation\": str(transform_training)\n",
        "}\n",
        "\n",
        "carpeta_drive = '/content/drive/MyDrive/Runs/' + projectes[MODEL]\n",
        "os.makedirs(carpeta_drive, exist_ok=True) #cream la carpeta si no existeix\n",
        "\n",
        "current_runs = len([d for d in os.listdir(carpeta_drive) if os.path.isdir(os.path.join(carpeta_drive, d))]) #número d'execucions fetes de cada model\n",
        "\n",
        "#cada execució tindrà la seva carpeta numerada\n",
        "\n",
        "json_object = json.dumps(parametres_training,indent = 2)\n",
        "\n",
        "#cream la carpeta de l'execució\n",
        "\n",
        "num_execucio = str(current_runs)\n",
        "carpeta_execucio = carpeta_drive+\"/\"+ num_execucio\n",
        "os.makedirs(carpeta_execucio,exist_ok=True)\n",
        "\n",
        "#afegim la informació d'entrenament a la carpeta\n",
        "with open(carpeta_execucio+\"/training_info.json\", \"w\") as outfile:\n",
        "  outfile.write(json_object)\n",
        "\n",
        "#guardam els pesos a la carpeta de drive\n",
        "best_model = execute(model,loss_fn,train_loader,val_loader,test_loader,optimizer,EPOCHS,device)\n",
        "carpeta_pesos = carpeta_execucio+'/pesos_'+nom_model+'_'+num_execucio+'.pt'\n",
        "torch.save(model.state_dict(), carpeta_pesos )\n",
        "\n",
        "#també guardam els resultats del test a la carpeta de drive\n",
        "carpeta_pesos = carpeta_execucio+'/pesos_'+nom_model+'_'+str(current_runs)+'.pt'\n",
        "\n",
        "resultats = test(model,test_loader,carpeta_pesos,loss_fn,device)\n",
        "\n",
        "with open(carpeta_execucio+\"/testing_info.json\", \"w\") as outfile:\n",
        "    json.dump(resultats, outfile, indent=3)\n",
        "\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(validation_data.__getmask__(3))\n",
        "# print(validation_data.__getpath__(3))\n",
        "# print(validation_data.__len__())\n",
        "# print(validation_data.__lenmasks__())"
      ],
      "metadata": {
        "id": "yljRsbHMONPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iZqvWw-4d1gx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "name": "AlexNet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cf24b1826b274525a4e1f0c4d8f866c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e8f6225623c4afe95c4e458476d675c",
              "IPY_MODEL_2910ad0d8bfe4775a698d3663618808d",
              "IPY_MODEL_c333eb4741894a6ea84490febcfc5679"
            ],
            "layout": "IPY_MODEL_151b0a12a8bd45dbbe7155af3778f823"
          }
        },
        "5e8f6225623c4afe95c4e458476d675c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48ba1020a770442686d61a0b69bb3954",
            "placeholder": "​",
            "style": "IPY_MODEL_e45c024ef94140128be8d912ed427226",
            "value": "  0%"
          }
        },
        "2910ad0d8bfe4775a698d3663618808d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf606f0632a94b1d96fc98d82d76550c",
            "max": 60,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14d76ae178a84b9ab0f05b19e1eb90bb",
            "value": 0
          }
        },
        "c333eb4741894a6ea84490febcfc5679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33fdf8631e25435ea18f8c99f669989e",
            "placeholder": "​",
            "style": "IPY_MODEL_2db0fd3b9110436da86208b9b12e10f0",
            "value": " 0/60 [00:00&lt;?, ?it/s]"
          }
        },
        "151b0a12a8bd45dbbe7155af3778f823": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48ba1020a770442686d61a0b69bb3954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e45c024ef94140128be8d912ed427226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf606f0632a94b1d96fc98d82d76550c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14d76ae178a84b9ab0f05b19e1eb90bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33fdf8631e25435ea18f8c99f669989e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2db0fd3b9110436da86208b9b12e10f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd29651bb8054adcaedce76707950d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_501e3065f63e4f46a1b8432d38c03368",
              "IPY_MODEL_8e83c21ecb534ab98957155b8a0e20d8",
              "IPY_MODEL_fc95d7a3e953405bb663abbbc3c340f6"
            ],
            "layout": "IPY_MODEL_3a717f40910446c99ee745d4fb4cfe35"
          }
        },
        "501e3065f63e4f46a1b8432d38c03368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1220ca5b999c4e62a92349b319406b37",
            "placeholder": "​",
            "style": "IPY_MODEL_58b83b1894404cbcbadd693da831569b",
            "value": "Batches (Època 1): "
          }
        },
        "8e83c21ecb534ab98957155b8a0e20d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f66b123bdb644f0bad1f07210eec759",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11611a4ddc6348e49e8e73ea67903fc0",
            "value": 0
          }
        },
        "fc95d7a3e953405bb663abbbc3c340f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dad41a1ceea4549bc5870ed655a07a6",
            "placeholder": "​",
            "style": "IPY_MODEL_188bd4217cd34b06aad41ecc5b50c20b",
            "value": " 0/? [00:00&lt;?, ?it/s]"
          }
        },
        "3a717f40910446c99ee745d4fb4cfe35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1220ca5b999c4e62a92349b319406b37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58b83b1894404cbcbadd693da831569b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f66b123bdb644f0bad1f07210eec759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "11611a4ddc6348e49e8e73ea67903fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dad41a1ceea4549bc5870ed655a07a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "188bd4217cd34b06aad41ecc5b50c20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}