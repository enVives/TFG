{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNnMkFqyRa20MPdSyST4XKQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enVives/TFG/blob/main/FeatureDistancesNew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2Nzx9gO8R_A",
        "outputId": "7126e32d-1e2c-4be2-8b5b-72244356919b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import wandb\n",
        "import pylab as pl\n",
        "import json\n",
        "import shutil\n",
        "\n",
        "from glob import glob\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output,display\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "from google.colab import drive\n",
        "\n",
        "DOWNLOAD = False\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "MODELS = {\n",
        "    0: 'AlexnetBinary',\n",
        "    1: 'Resnet152Binary',\n",
        "    2: 'Inceptionv3Binary',\n",
        "    3: 'EfficientNetB1Binary',\n",
        "    4: 'AlexnetMulticlass',\n",
        "    5: 'Resnet152Multiclass',\n",
        "    6: 'Inceptionv3Multiclass',\n",
        "    7: 'EfficientnetB1Multiclass',\n",
        "}\n",
        "\n",
        "DISTANCES = {\n",
        "    'Cosin' : 0,\n",
        "    'L2' : 1\n",
        "}\n",
        "\n",
        "\n",
        "MODEL = MODELS[5] #we pick a model\n",
        "picked = 'Cosin'\n",
        "DISTANCE = DISTANCES[picked] #we pick a distance\n",
        "\n",
        "RUN = 22 #we pick a run\n",
        "\n",
        "#we obtain the distances\n",
        "TRAINING_FEATURES_FILE = \"/content/drive/MyDrive/Runs/Ham10000\"+MODEL+\"/\"+str(RUN)+\"/Features/training_features.txt\"\n",
        "TESTING_FEATURES_FILE = \"/content/drive/MyDrive/Runs/Ham10000\"+MODEL+\"/\"+str(RUN)+\"/Features/testing_features.txt\"\n",
        "\n",
        "#cream el folder per a les distances\n",
        "DIST_FOLDER = \"/content/drive/MyDrive/Runs/Ham10000\"+MODEL+\"/\"+str(RUN)+\"/Dist/\"+picked\n",
        "\n",
        "if os.path.exists(DIST_FOLDER):\n",
        "    shutil.rmtree(DIST_FOLDER)\n",
        "\n",
        "os.makedirs(DIST_FOLDER,exist_ok=True)\n",
        "\n",
        "if DOWNLOAD:\n",
        "  !rm -rf /content/sample_data/*\n",
        "\n",
        "  !kaggle datasets download -d \"kmader/skin-cancer-mnist-ham10000\"\n",
        "\n",
        "  !unzip -o skin-cancer-mnist-ham10000.zip -d /content/sample_data/\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import TextIOWrapper\n",
        "from numpy.linalg import norm\n",
        "import sys\n",
        "import ast\n",
        "import shutil\n",
        "\n",
        "def genera_dists():\n",
        "  csv.field_size_limit(sys.maxsize)\n",
        "  dict_illnesses = {0 : 'nv', 1 : 'mel', 2 : 'bkl', 3 : 'bcc', 4 : 'akiec', 5 : 'vasc', 6 : 'df'}\n",
        "  #we will save the metadata in each folder\n",
        "\n",
        "  fi = DIST_FOLDER+'/distances.txt'\n",
        "\n",
        "  #headers of distancex.txt\n",
        "  headers = [\"test_img\",\"test_img_pred_label\",\"test_img_label\",\"top_distances\",\"top_images_labels\",\"top_images_names\",\"bottom_distances\",\"bottom_images_labels\",\"bottom_images_names\"]\n",
        "\n",
        "  with open(fi, mode=\"w\", newline=\"\") as file:\n",
        "      writer = csv.writer(file, delimiter=';')\n",
        "      writer.writerow(headers)  # Write header\n",
        "\n",
        "  #obrim el fitxer de testing\n",
        "  with open(TESTING_FEATURES_FILE ,newline = '') as ftst:\n",
        "\n",
        "    test_features = csv.DictReader(ftst,delimiter=',')\n",
        "    number = 0\n",
        "    for i in test_features:\n",
        "      number = number + 1\n",
        "      test_img_name = i['Image Name'] #Image name\n",
        "      test_img_features = np.array(ast.literal_eval(i['FC Input'])) #FC Input\n",
        "      test_img_path = i['Image Path'] #Image Path\n",
        "      test_img_label = i['Label'] #Label\n",
        "\n",
        "      if DISTANCE == 0: #cosin distance, we look for the highest value close to 1\n",
        "        top5dist = np.array([0,0,0,0,0],dtype=object)\n",
        "        bottom5dist = np.array([np.inf,np.inf,np.inf,np.inf,np.inf],dtype=object)\n",
        "      else: #l2 distance, we look for the closest nomber to 0\n",
        "        top5dist = np.array([np.inf,np.inf,np.inf,np.inf,np.inf],dtype=object)\n",
        "        bottom5dist = np.array([0,0,0,0,0],dtype=object)\n",
        "\n",
        "      top5labels = np.array([-1,-1,-1,-1,-1],dtype=object)\n",
        "      bottom5labels = np.array([-1,-1,-1,-1,-1],dtype=object)\n",
        "      top5names = np.array([\"\",\"\",\"\",\"\",\"\"],dtype=object)\n",
        "      bottom5names = np.array([\"\",\"\",\"\",\"\",\"\"],dtype=object)\n",
        "      top5paths = np.array([\"\",\"\",\"\",\"\",\"\"],dtype=object)\n",
        "      bottom5paths = np.array([\"\",\"\",\"\",\"\",\"\"],dtype=object)\n",
        "\n",
        "      #we open the training features\n",
        "      with open(TRAINING_FEATURES_FILE, newline='') as ftr:\n",
        "        tr_features = csv.DictReader(ftr,delimiter = ',')\n",
        "\n",
        "        for j in tr_features:\n",
        "          train_img_name = j['Image Name'] #Image name\n",
        "          train_img_features = np.array(ast.literal_eval(j['FC Input'])) #FC Input\n",
        "          train_img_path = j['Image Path'] #Image Path\n",
        "          train_img_label = j['Label'] #Label\n",
        "\n",
        "          if DISTANCE == 0: #cosin\n",
        "            distance = np.dot(test_img_features,train_img_features)/(norm(test_img_features)*norm(train_img_features))\n",
        "          else: #l2\n",
        "            distance = norm(test_img_features - train_img_features)\n",
        "\n",
        "          #we update the top 5 or bottom 5 or neither\n",
        "          if DISTANCE == 0:\n",
        "            for k in range(len(top5dist)):\n",
        "              if distance > top5dist[k]:\n",
        "                top5dist[k] = distance\n",
        "                top5labels[k] = dict_illnesses[int(train_img_label)]\n",
        "                top5paths[k] = train_img_path\n",
        "                top5names[k] = train_img_name\n",
        "                break\n",
        "              if distance < bottom5dist[k]:\n",
        "                bottom5dist[k] = distance\n",
        "                bottom5labels[k] = dict_illnesses[int(train_img_label)]\n",
        "                bottom5paths[k] = train_img_path\n",
        "                bottom5names[k] = train_img_name\n",
        "                break\n",
        "          else:\n",
        "            for k in range(len(top5dist)):\n",
        "              if distance < top5dist[k]:\n",
        "                top5dist[k] = distance\n",
        "                top5labels[k] = dict_illnesses[int(train_img_label)]\n",
        "                top5paths[k] = train_img_path\n",
        "                top5names[k] = train_img_name\n",
        "                break\n",
        "              if distance > bottom5dist[k]:\n",
        "                bottom5dist[k] = distance\n",
        "                bottom5labels[k] = dict_illnesses[int(train_img_label)]\n",
        "                bottom5paths[k] = train_img_path\n",
        "                bottom5names[k] = train_img_name\n",
        "                break\n",
        "\n",
        "        #we create the folder of our test image, it will have name and label\n",
        "        os.makedirs(DIST_FOLDER+'/'+test_img_name.split('.')[0]+'('+dict_illnesses[int(test_img_label)]+')/',exist_ok=True)\n",
        "\n",
        "        #we want to order the top and bottom depending on the distance\n",
        "        if DISTANCE == 0:\n",
        "          sorted_indices = np.argsort(top5dist)[::-1]\n",
        "        else:\n",
        "          sorted_indices = np.argsort(top5dist)\n",
        "\n",
        "        #si utilitzam la distància cosin ens interessa que la distància més gran sigui la primera\n",
        "\n",
        "        top5dist = top5dist[sorted_indices]\n",
        "        top5labels = top5labels[sorted_indices]\n",
        "        top5paths = top5paths[sorted_indices]\n",
        "        top5names = top5names[sorted_indices]\n",
        "\n",
        "        if DISTANCE == 0:\n",
        "          sorted_indices = np.argsort(bottom5dist)[::-1]\n",
        "        else:\n",
        "          sorted_indices = np.argsort(bottom5dist)\n",
        "\n",
        "        bottom5dist = bottom5dist[sorted_indices]\n",
        "        bottom5labels = bottom5labels[sorted_indices]\n",
        "        bottom5paths = bottom5paths[sorted_indices]\n",
        "        bottom5names = bottom5names[sorted_indices]\n",
        "\n",
        "        #corregir actual label\n",
        "        data_row = [test_img_name.split('.')[0],test_img_label,test_img_label,[round(num,6) for num in top5dist.astype(float).tolist()],top5labels,top5names.astype(str).tolist(),[round(num,6) for num in bottom5dist.astype(float).tolist()],bottom5labels,bottom5names.astype(str).tolist()]\n",
        "\n",
        "        #guardarem els data_row disn un fitxer de txt i crearem les carpetes top i bottom\n",
        "\n",
        "        #ens interessa ara el nom de la enfermetat\n",
        "        test_img_label = dict_illnesses[int(test_img_label)]\n",
        "\n",
        "        os.makedirs(DIST_FOLDER+'/'+test_img_name.split('.')[0]+'('+test_img_label+')'+'/Top/',exist_ok=True)\n",
        "        os.makedirs(DIST_FOLDER+'/'+test_img_name.split('.')[0]+'('+test_img_label+')'+'/Bottom/',exist_ok=True)\n",
        "\n",
        "        #we save the top images in the TOP folder\n",
        "        for l in range(len(top5paths)):\n",
        "          shutil.copy(top5paths[l], DIST_FOLDER+'/'+test_img_name.split('.')[0]+'('+test_img_label+')/Top/'+str(l)+'_'+top5labels[l]+'.jpg')\n",
        "\n",
        "        #we save our test image\n",
        "        shutil.copy(test_img_path ,DIST_FOLDER+'/'+test_img_name.split('.')[0]+'('+test_img_label+')/'+test_img_label+'_imatge_test_'+test_img_name)\n",
        "\n",
        "        #we save the bottom images in the BOTTOM folder\n",
        "\n",
        "        for m in range(len(bottom5paths)):\n",
        "          shutil.copy(bottom5paths[m], DIST_FOLDER+'/'+test_img_name.split('.')[0]+'('+test_img_label+')/Bottom/'+str(m)+'_'+bottom5labels[m]+'.jpg')\n",
        "\n",
        "        #we write the data row in the file\n",
        "        with open(fi, mode=\"a\", newline=\"\") as file:\n",
        "          writer = csv.writer(file, delimiter=';')\n",
        "          writer.writerow(data_row)  # Write row immediately\n",
        "\n",
        "        print(number)\n",
        "\n",
        "        if number == 100:\n",
        "          break\n",
        "\n",
        "  print(\"CSV file written successfully.\")"
      ],
      "metadata": {
        "id": "aU21okj094I0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p ~/.kaggle\n",
        "# !mv /content/kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "bVQDISVu8ttG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genera_dists()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7hKqkm4HM3d",
        "outputId": "0a61316e-d33d-4f5c-b85d-c5a3a063bb73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n"
          ]
        }
      ]
    }
  ]
}