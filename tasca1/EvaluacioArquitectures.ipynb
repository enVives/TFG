{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enVives/TFG/blob/main/tasca1/EvaluacioArquitectures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4v7z1Tb8sOhk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "\n",
        "\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# !rm -rf /content/sample_data/*\n",
        "\n",
        "# !kaggle datasets download -d \"kmader/skin-cancer-mnist-ham10000\"\n",
        "\n",
        "# !unzip -o skin-cancer-mnist-ham10000.zip -d /content/sample_data/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "!rm -rf /content/sample_data/*\n",
        "\n",
        "!kaggle datasets download -d \"kmader/skin-cancer-mnist-ham10000\"\n",
        "\n",
        "!unzip -o skin-cancer-mnist-ham10000.zip -d /content/sample_data/"
      ],
      "metadata": {
        "id": "BcO_-eS1dYxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadates = pd.read_csv('/content/sample_data/HAM10000_metadata.csv')\n",
        "metadates = metadates.sort_values(by='image_id')\n",
        "metadates.head()\n",
        "print(metadates['dx'].value_counts())\n",
        "print()\n",
        "print(metadates['dx'].value_counts() / sum(metadates['dx'].value_counts()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugqDHdvBtZRA",
        "outputId": "8ae0f36b-d95e-4c2f-b931-42b157507366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dx\n",
            "nv       6705\n",
            "mel      1113\n",
            "bkl      1099\n",
            "bcc       514\n",
            "akiec     327\n",
            "vasc      142\n",
            "df        115\n",
            "Name: count, dtype: int64\n",
            "\n",
            "dx\n",
            "nv       0.669496\n",
            "mel      0.111133\n",
            "bkl      0.109735\n",
            "bcc      0.051323\n",
            "akiec    0.032651\n",
            "vasc     0.014179\n",
            "df       0.011483\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nv: melanocytic nevi\n",
        "\n",
        "vasc: vascular lesions\n",
        "\n",
        "mel:melanoma\n",
        "\n",
        "df: dermatofibroma\n",
        "\n",
        "bkl: benign keratosis-like lesions\n",
        "\n",
        "bcc: basal cell carcinoma\n",
        "\n",
        "akiec: Actinic keratoses and intraepithelial carcinoma / Bowen's disease"
      ],
      "metadata": {
        "id": "QcJc98DVvHTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Formes(Dataset):\n",
        "  #Classe on gestionarem les imatges dels fitxers\n",
        "  dict_illnesses = {0 : 'nv', 1 : 'mel', 2 : 'bkl', 3 : 'bcc', 4 : 'akiec', 5 : 'vasc', 6 : 'df'}\n",
        "\n",
        "  def __init__(self, images, labels, transform):\n",
        "        super().__init__()\n",
        "        self.paths = images\n",
        "        self.labels = labels\n",
        "        self.len = len(self.paths)\n",
        "        self.transform = transform\n",
        "        #Per defecte pens que el color pot extreure característiques importants, per tant en primer lloc\n",
        "        #entrenarem les imatges de color\n",
        "        self.greyscale = False\n",
        "\n",
        "  def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "  def __addlabel__(self,label):\n",
        "    self.labels = np.append(self.labels,label)\n",
        "\n",
        "  def __addPath__(self,path):\n",
        "    self.paths = np.append(self.paths,path)\n",
        "\n",
        "  def __getdist__(self):\n",
        "    return pd.Series(self.labels).value_counts()\n",
        "\n",
        "  def __getlabels__(self):\n",
        "    classes = [[],[],[],[],[],[],[]]\n",
        "    for i in range(len(self.labels)):\n",
        "      classes[self.labels[i]].append(i) #afegim l'index\n",
        "    return classes\n",
        "\n",
        "  def __redistribute__(self,percentages):\n",
        "    #percentages: [15,15,10,10,5,5] percentatges que volem pujar de la resta de classes llevat de nv\n",
        "    threshold = 0.005  #percentatge de marge que deixam a la redistribució\n",
        "    Ntarget = self.len\n",
        "    classes = self.__getlabels__() #indexos de cada clase\n",
        "    afegir = np.array([0,0,0,0,0,0],dtype=np.int64) # de nv mai haurem d'afegir\n",
        "\n",
        "    nmel = len(classes[1]) #nombre inicial de cada clase\n",
        "    nbkl = len(classes[2])\n",
        "    nbcc = len(classes[3])\n",
        "    nakiec = len(classes[4])\n",
        "    nvasc = len(classes[5])\n",
        "    ndf = len(classes[6])\n",
        "\n",
        "    while True:\n",
        "\n",
        "      suma_actual = afegir.sum()\n",
        "\n",
        "      operacio = percentages[0]*Ntarget - nmel\n",
        "      afegir[0] +=  operacio if operacio > 0 else 0\n",
        "      nmel += operacio if operacio > 0 else 0\n",
        "\n",
        "      operacio = percentages[1]*Ntarget - nbkl\n",
        "      afegir[1] += operacio if operacio > 0 else 0\n",
        "      nbkl += operacio if operacio > 0 else 0\n",
        "\n",
        "      operacio = percentages[2]*Ntarget - nbcc\n",
        "      afegir[2] += operacio if operacio > 0 else 0\n",
        "      nbcc += operacio if operacio > 0 else 0\n",
        "\n",
        "      operacio = percentages[3]*Ntarget - nakiec\n",
        "      afegir[3] += operacio if operacio > 0 else 0\n",
        "      nakiec += operacio if operacio > 0 else 0\n",
        "\n",
        "      operacio = percentages[4]*Ntarget - nvasc\n",
        "      afegir[4] += operacio if operacio > 0 else 0\n",
        "      nvasc += operacio if operacio > 0 else 0\n",
        "\n",
        "      operacio = percentages[5]*Ntarget - ndf\n",
        "      afegir[5] += operacio if operacio > 0 else 0\n",
        "      ndf += operacio if operacio > 0 else 0\n",
        "\n",
        "      if (afegir.sum()-suma_actual) < Ntarget*threshold:\n",
        "        break\n",
        "\n",
        "      Ntarget += (afegir.sum()-suma_actual)\n",
        "\n",
        "    #Quedaria afegir a les imatges les còpies\n",
        "    for i in range(len(afegir)):\n",
        "      for j in range(afegir[i]):\n",
        "\n",
        "          self.__addPath__(self.paths[classes[i+1][random.randint(0, len(classes[i+1]) - 1)]])\n",
        "          self.__addlabel__(i+1)\n",
        "\n",
        "    self.len = len(self.labels)\n",
        "\n",
        "  def __setgreyscale__(self,mode):\n",
        "    self.greyscale = mode\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      path = self.paths[index]\n",
        "      label = self.labels[index]\n",
        "\n",
        "      image = cv2.imread(path, cv2.IMREAD_GRAYSCALE if self.greyscale else cv2.IMREAD_COLOR)  # Depén de vosaltres\n",
        "      image = self.transform(image)\n",
        "\n",
        "      return image, label"
      ],
      "metadata": {
        "id": "6PHW-EVhnT3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calcula_mitjana_desviacio(img_files_path):\n",
        "  mitjana = np.array([0.0, 0.0, 0.0], dtype=np.float64)\n",
        "  desviacio = np.array([0.0, 0.0, 0.0], dtype=np.float64)\n",
        "\n",
        "  x,y = 256,256\n",
        "  pixels_totals_canal = len(img_files_path) * x * y\n",
        "\n",
        "  for i in range(len(img_files_path)):\n",
        "    imatge = cv2.imread(img_files_path[i])\n",
        "    imatge = cv2.resize(imatge,(x,y))\n",
        "\n",
        "    canal_b, canal_g, canal_r = cv2.split(imatge)\n",
        "\n",
        "    mitjana += np.array([canal_r.sum(), canal_g.sum(), canal_b.sum()])\n",
        "    #desviacio += np.array([(canal_r**2).sum(), (canal_g**2).sum(), (canal_b**2).sum()])\n",
        "\n",
        "  mitjana = mitjana / pixels_totals_canal\n",
        "\n",
        "  for i in range(len(img_files_path)):\n",
        "    imatge = cv2.imread(img_files_path[i])\n",
        "    imatge = cv2.resize(imatge,(x,y))\n",
        "\n",
        "    canal_b, canal_g, canal_r = cv2.split(imatge)\n",
        "    desviacio += np.array([((canal_r-mitjana[0])**2).sum(), ((canal_g-mitjana[1])**2).sum(), ((canal_b-mitjana[2])**2).sum()])\n",
        "\n",
        "\n",
        "  desviacio = np.sqrt(desviacio / pixels_totals_canal)\n",
        "\n",
        "  return mitjana,desviacio"
      ],
      "metadata": {
        "id": "-lKr3HM2VvhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING = 0.64\n",
        "VALIDATION = 0.16\n",
        "TESTING = 0.20\n",
        "SIZE = 224\n",
        "\n",
        "illnes_dictionary = {\n",
        "    'nv': 'Melanocytic nevi',\n",
        "    'mel': 'Melanoma',\n",
        "    'bkl': 'Benign keratosis-like lesions ',\n",
        "    'bcc': 'Basal cell carcinoma',\n",
        "    'akiec': 'Actinic keratoses and intraepithelial carcinoma / Bowens disease',\n",
        "    'vasc': 'Vascular lesions',\n",
        "    'df': 'Dermatofibroma'\n",
        "}\n",
        "\n",
        "img_files_1 = sorted(glob('/content/sample_data/HAM10000_images_part_1/*'))\n",
        "img_files_2 = sorted(glob('/content/sample_data/HAM10000_images_part_2/*'))\n",
        "img_files = img_files_1 + img_files_2\n",
        "\n",
        "img_files = np.array(img_files)\n",
        "\n",
        "#mitjana,desviacio = calcula_mitjana_desviacio(img_files)\n",
        "#S'ha descobert amb aquesta funció que la mitjana = [194.57463374 139.13953272 145.36132088]\n",
        "#I desviació= [35.92275236 38.90347617 43.33101831]\n",
        "mean = torch.tensor([194.57463374, 139.13953272, 145.36132088]) /255 #rgb\n",
        "std = torch.tensor([35.92275236, 38.90347617, 43.33101831]) / 255\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = mean, std=std)\n",
        "])\n",
        "\n",
        "transform_training = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = mean, std=std),\n",
        "    transforms.Resize((SIZE,SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomRotation(degrees=20),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
        "    transforms.RandomGrayscale(p=0.1),\n",
        "])\n",
        "\n",
        "imgid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in img_files}\n",
        "\n",
        "metadates['path'] = metadates['image_id'].map(imgid_path_dict.get)\n",
        "metadates['illness'] = metadates['dx'].map(illnes_dictionary.get)\n",
        "metadates['illness_code'] = metadates['dx'].map({'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3, 'akiec': 4, 'vasc': 5, 'df': 6})\n",
        "\n",
        "#Aquest illness_code s'utilitzarà com a label de la enfermetat\n",
        "\n",
        "img_number = len(img_files)\n",
        "\n",
        "\n",
        "X = metadates.drop('illness_code',axis= 1)\n",
        "y = metadates['illness_code']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TESTING, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=VALIDATION/(TRAINING+VALIDATION), random_state=42, stratify=y_train)\n",
        "\n",
        "#Una bona idea seria aplicar data augmentation al conjunt d'entrenament ja que les classes estan molt desbalancejades\n",
        "#Una altra bona idea seria emplear una funció de pèrdua que tengui en compte les classes desbalancejades.\n",
        "\n",
        "#Antes de guardar els datasets en classes Formes, hauriem de caluclar la mitjana i desviació típica de les imatges\n",
        "train_data = Formes(X_train['path'].to_numpy(),y_train.to_numpy(),transform_training)\n",
        "test_data = Formes(X_test['path'].to_numpy(),y_test.to_numpy(),transform)\n",
        "validation_data = Formes(X_val['path'].to_numpy(),y_val.to_numpy(),transform)\n",
        "\n",
        "\n",
        "#prova1: [0.12,0.12,0.06,0.04,0.02,0.02]\n",
        "#prova2: [0.12,0.12,0.06,0.04,0.02,0.015]\n",
        "#prova3: [0.13,0.13,0.07,0.05,0.02,0.015]\n",
        "\n",
        "print(train_data.__getdist__())\n",
        "train_data.__redistribute__([0.12,0.12,0.06,0.04,0.02,0.015])\n",
        "print(train_data.__getdist__())\n",
        "print(train_data.len)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cZlOgbNubsoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe0465aa-9427-4b7b-c124-87a574a71bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    4291\n",
            "1     712\n",
            "2     703\n",
            "3     329\n",
            "4     209\n",
            "5      91\n",
            "6      74\n",
            "Name: count, dtype: int64\n",
            "0    4291\n",
            "2     819\n",
            "1     819\n",
            "3     409\n",
            "4     272\n",
            "5     135\n",
            "6     101\n",
            "Name: count, dtype: int64\n",
            "6846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def veure_imatges(train_data,std,mean):\n",
        "  for i in range(len(train_data)):\n",
        "    imatge,label = train_data.__getitem__(i)\n",
        "\n",
        "    imatge = imatge * (std[:, None, None]*255) + (mean[:, None, None]*255)\n",
        "\n",
        "    # Convert the tensor back to a NumPy array\n",
        "    img_numpy = imatge.permute(1, 2, 0).numpy()  # Change from (C, H, W) to (H, W, C)\n",
        "    cv2_imshow(img_numpy)\n",
        "    time.sleep(5)\n",
        "    clear_output(wait=True)"
      ],
      "metadata": {
        "id": "1YnLcPMeI356"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#veure_imatges(train_data,std,mean)"
      ],
      "metadata": {
        "id": "qvLR-CQR_OLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ara ja tenim el training preparat. El provarem amb el validation a continuació"
      ],
      "metadata": {
        "id": "s6iyMBCr_33C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ENTRENAMENT"
      ],
      "metadata": {
        "id": "gvPO4Jzmvoal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tria_model(numero_model):\n",
        "  if numero_model == 0:\n",
        "    alexnetbinary = models.alexnet(pretrained=False)\n",
        "    alexnetbinary.classifier = nn.Sequential(\n",
        "    torch.nn.Linear(9216, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 512),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(512, 1),\n",
        "    nn.Sigmoid()\n",
        "    )\n",
        "    return alexnetbinary\n",
        "  elif numero_model == 1:\n",
        "    alexnetmulticlass = models.alexnet(pretrained=False)\n",
        "    alexnetmulticlass.classifier = nn.Sequential(\n",
        "    torch.nn.Linear(9216, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 512),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(512, 7),  # Ja que tenim 7 classes.\n",
        "    nn.Softmax(dim=1)\n",
        "    )\n",
        "    return alexnetmulticlass\n"
      ],
      "metadata": {
        "id": "n1UDZMclAYj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tria_model(0)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XpU9dCgvsaf",
        "outputId": "034707ae-299d-494f-abb0-15e24ddf1d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=9216, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=512, out_features=1, bias=True)\n",
              "    (7): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5YJqfLM3GVDj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "EvaluacioArquitectures.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}