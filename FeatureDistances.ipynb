{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPAb9TcM+6eCioa4DF7EX9q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enVives/TFG/blob/main/FeatureDistances.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBBrozgPtidt",
        "outputId": "5be743ea-9ed1-4098-907d-5b7668189dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import wandb\n",
        "import pylab as pl\n",
        "import json\n",
        "\n",
        "from glob import glob\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output,display\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "DOWNLOAD = False\n",
        "CLAHE = False\n",
        "# ORIGEN = '/content/drive/MyDrive/HAM10000/skin-cancer-mnist-ham10000/'\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "if DOWNLOAD:\n",
        "  !rm -rf /content/sample_data/*\n",
        "\n",
        "  !kaggle datasets download -d \"kmader/skin-cancer-mnist-ham10000\"\n",
        "\n",
        "  !unzip -o skin-cancer-mnist-ham10000.zip -d /content/sample_data/\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metadates = pd.read_csv('/content/sample_data/HAM10000_metadata.csv')\n",
        "metadates = metadates.sort_values(by='image_id')"
      ],
      "metadata": {
        "id": "gx-XW9ApuJY7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Formes(Dataset):\n",
        "  #Classe on gestionarem les imatges dels fitxers\n",
        "  dict_illnesses = {0 : 'nv', 1 : 'mel', 2 : 'bkl', 3 : 'bcc', 4 : 'akiec', 5 : 'vasc', 6 : 'df'}\n",
        "\n",
        "  def __init__(self, images, labels, transform):\n",
        "        super().__init__()\n",
        "        self.paths = images\n",
        "        self.labels = labels\n",
        "        self.len = len(self.paths)\n",
        "        self.transform = transform\n",
        "        #Per defecte pens que el color pot extreure característiques importants, per tant en primer lloc\n",
        "        #entrenarem les imatges de color\n",
        "        self.greyscale = False\n",
        "\n",
        "  def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "  def __addlabel__(self,label):\n",
        "    self.labels = np.append(self.labels,label)\n",
        "\n",
        "  def __addPath__(self,path):\n",
        "    self.paths = np.append(self.paths,path)\n",
        "\n",
        "  def __getdist__(self):\n",
        "    return pd.Series(self.labels).value_counts()\n",
        "\n",
        "  def __getlabels__(self):\n",
        "    classes = [[],[],[],[],[],[],[]]\n",
        "    for i in range(len(self.labels)):\n",
        "      classes[self.labels[i]].append(i) #afegim l'index\n",
        "    return classes\n",
        "\n",
        "  def __setgreyscale__(self,mode):\n",
        "    self.greyscale = mode\n",
        "\n",
        "  def __getpath__(self,index):\n",
        "    return self.paths[index]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      path = self.paths[index]\n",
        "      label = self.labels[index]\n",
        "\n",
        "      image = cv2.imread(path, cv2.IMREAD_GRAYSCALE if self.greyscale else cv2.IMREAD_COLOR)\n",
        "\n",
        "      #preprocessament\n",
        "      if CLAHE:\n",
        "        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=1.5, tileGridSize=(8,8))\n",
        "        l_clahe = clahe.apply(l)\n",
        "        lab_clahe = cv2.merge((l_clahe, a, b))\n",
        "        image = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "\n",
        "      if self.greyscale:\n",
        "        image = Image.fromarray(image, mode=\"L\")\n",
        "      else:\n",
        "        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "      image = self.transform(image)\n",
        "\n",
        "      return image, label"
      ],
      "metadata": {
        "id": "9kwkcN53v7QT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_sets(transformation_training,transformation_default,training_dist,valitation_dist,testing_dist,distribution):\n",
        "\n",
        "  illnes_dictionary = {\n",
        "      'nv': 'Melanocytic nevi',\n",
        "      'mel': 'Melanoma',\n",
        "      'bkl': 'Benign keratosis-like lesions ',\n",
        "      'bcc': 'Basal cell carcinoma',\n",
        "      'akiec': 'Actinic keratoses and intraepithelial carcinoma / Bowens disease',\n",
        "      'vasc': 'Vascular lesions',\n",
        "      'df': 'Dermatofibroma'\n",
        "  }\n",
        "\n",
        "  img_files_1 = sorted(glob('/content/sample_data/HAM10000_images_part_1/*'))\n",
        "  img_files_2 = sorted(glob('/content/sample_data/HAM10000_images_part_2/*'))\n",
        "  img_files = img_files_1 + img_files_2\n",
        "\n",
        "  img_files = np.array(img_files)\n",
        "\n",
        "\n",
        "  imgid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in img_files}\n",
        "\n",
        "  metadates['path'] = metadates['image_id'].map(imgid_path_dict.get)\n",
        "  metadates['illness'] = metadates['dx'].map(illnes_dictionary.get)\n",
        "  metadates['illness_code'] = metadates['dx'].map({'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3, 'akiec': 4, 'vasc': 5, 'df': 6})\n",
        "\n",
        "  #Aquest illness_code s'utilitzarà com a label de la enfermetat\n",
        "\n",
        "  img_number = len(img_files)\n",
        "\n",
        "  X = metadates.drop('illness_code',axis= 1)\n",
        "  y = metadates['illness_code']\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testing_dist, random_state=42, stratify=y)\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=valitation_dist/(training_dist+valitation_dist), random_state=42, stratify=y_train)\n",
        "\n",
        "  #Una bona idea seria aplicar data augmentation al conjunt d'entrenament ja que les classes estan molt desbalancejades\n",
        "  #Una altra bona idea seria emplear una funció de pèrdua que tengui en compte les classes desbalancejades.\n",
        "\n",
        "  #Antes de guardar els datasets en classes Formes, hauriem de caluclar la mitjana i desviació típica de les imatges\n",
        "  train_data = Formes(X_train['path'].to_numpy(),y_train.to_numpy(),transformation_training)\n",
        "  test_data = Formes(X_test['path'].to_numpy(),y_test.to_numpy(),transformation_default)\n",
        "  validation_data = Formes(X_val['path'].to_numpy(),y_val.to_numpy(),transformation_default)\n",
        "\n",
        "\n",
        "  #prova1: [0.12,0.12,0.06,0.04,0.02,0.02]\n",
        "  #prova2: [0.12,0.12,0.06,0.04,0.02,0.015]\n",
        "  #prova3: [0.13,0.13,0.07,0.05,0.02,0.015]\n",
        "\n",
        "  if distribution != None:\n",
        "    train_data.__redistribute__(distribution)\n",
        "\n",
        "  return train_data, validation_data,test_data"
      ],
      "metadata": {
        "id": "8trqqs38v-Tk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import norm\n",
        "import sys\n",
        "import ast\n",
        "\n",
        "def genera_dists(model,test_data,activation):\n",
        "  PATH = '/content/drive/MyDrive/Features/embeddings.txt'\n",
        "  csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "  total = test_data.__len__()\n",
        "\n",
        "  data = [[\"test_img\",\"test_img_path\",\"test_img_label\",\"distances\",\"labels\",\"paths\"]]\n",
        "\n",
        "\n",
        "  #iteram imatges de test\n",
        "  for i in range(total):\n",
        "\n",
        "    imatge,label = test_data.__getitem__(i)\n",
        "    imatge = imatge.to(device)\n",
        "    imatge = imatge.unsqueeze(0)\n",
        "\n",
        "    img_path = test_data.__getpath__(i)\n",
        "    img_name = img_path.split('/')\n",
        "    img_name = img_name[len(img_name)-1]\n",
        "\n",
        "    distances = [np.inf,np.inf,np.inf,np.inf,np.inf]\n",
        "    classes_properes = [\"\",\"\",\"\",\"\",\"\"]\n",
        "    paths = [\"\",\"\",\"\",\"\",\"\"]\n",
        "\n",
        "    output = model(imatge)\n",
        "\n",
        "    my_feature = activation['lastlayer'].flatten().cpu().detach().numpy()\n",
        "\n",
        "    with open(PATH, mode='r') as file:\n",
        "\n",
        "      features = csv.reader(file,delimiter=',')\n",
        "      #botam la capçalera\n",
        "      next(features)\n",
        "\n",
        "      k = 0\n",
        "      for rows in features:\n",
        "\n",
        "        print(rows)\n",
        "        fcnoutput = np.array(ast.literal_eval(rows[1]))\n",
        "        path = rows[2]\n",
        "        label = rows[3]\n",
        "\n",
        "        comparing_feature = fcnoutput\n",
        "        cosine = np.dot(my_feature,comparing_feature)/(norm(my_feature)*norm(comparing_feature))\n",
        "        for j in range(len(distances)):\n",
        "          if cosine < distances[j]:\n",
        "            distances[j] = cosine\n",
        "            classes_properes[j] = label\n",
        "            paths[j] = path\n",
        "\n",
        "        print(k)\n",
        "        k += 1\n",
        "\n",
        "    data.append([img_name,img_path,label,distances,classes_properes,paths])\n",
        "    print(i)\n",
        "\n",
        "  f = '/content/drive/MyDrive/Features/'+'distances.csv'\n",
        "  with open(f, mode=\"w\", newline=\"\") as file:\n",
        "      writer = csv.writer(file,delimiter=';')\n",
        "      writer.writerows(data)  # Writes multiple rows at once\n",
        "\n",
        "  print(\"CSV file written successfully.\")"
      ],
      "metadata": {
        "id": "jh5kfY4tw1BZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = torch.tensor([194.57463374, 139.13953272, 145.36132088]) /255 #rgb\n",
        "std = torch.tensor([35.92275236, 38.90347617, 43.33101831]) / 255\n",
        "\n",
        "TRAINING = 0.80\n",
        "VALIDATION = 0.10\n",
        "TESTING = 0.10\n",
        "SIZE = 224\n",
        "\n",
        "DISTRIBUTIONS = None\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((SIZE,SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = mean, std=std)\n",
        "])\n",
        "\n",
        "transform_training = transforms.Compose([\n",
        "    transforms.Resize((SIZE,SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.3),\n",
        "    transforms.RandomVerticalFlip(p=0.3),\n",
        "    transforms.RandomRotation(degrees=20),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = mean, std=std),\n",
        "])\n",
        "\n",
        "CLAHE = True\n",
        "train_data,validation_data,test_data = load_sets(transform_training,transform,TRAINING,VALIDATION,TESTING,DISTRIBUTIONS)\n",
        "\n",
        "PATH = '/content/drive/MyDrive/Runs/Ham10000Resnet152Multiclass/1/pesos_resnet152multiclass_1.pt'\n",
        "\n",
        "resnetmulticlass152 = models.resnet152()\n",
        "num_features = resnetmulticlass152.fc.in_features\n",
        "resnetmulticlass152.fc = nn.Linear(in_features=num_features, out_features=7)\n",
        "\n",
        "resnetmulticlass152.load_state_dict(torch.load(PATH, weights_only=True))\n",
        "\n",
        "activation = {}\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activation[name] = input[0].detach()\n",
        "    return hook\n",
        "\n",
        "\n",
        "model = resnetmulticlass152\n",
        "#model.layer4.register_forward_hook(get_activation('layer4'))\n",
        "\n",
        "model.fc.register_forward_hook(get_activation('lastlayer'))\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "genera_dists(model,test_data,activation)"
      ],
      "metadata": {
        "id": "2SkYOuXowGPY",
        "outputId": "73c3f40e-6eb1-48be-e2e5-59f5e31da5b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ISIC_0026187.jpg', '[0.89235574 0.46314925 0.8941267  0.39894742 0.38418075 0.5070819\\n 0.5637766  0.4532664  0.48777074 0.42715588 0.76940614 0.55679166\\n 0.54054475 0.5324636  0.5448049  0.27523732 0.16487789 0.31695288\\n 0.64668256 0.30634332 0.4313739  0.50641674 0.5242867  0.4347223\\n 0.6244728  0.46898082 0.5500631  0.5312281  0.5383415  0.5316729\\n 0.52895325 0.33369693 0.20161228 0.64145786 0.31406313 0.64415985\\n 0.34596556 0.31160367 0.31363264 0.5663007  0.42918497 0.44606593\\n 0.71453536 0.42325112 0.50501984 0.337419   0.32292455 0.6833426\\n 0.19683667 0.5027751  0.45199227 0.40105465 0.5898176  0.44699827\\n 0.68755245 0.26828933 0.47090024 0.42026487 0.42979494 0.2789482\\n 0.42421892 0.3645789  0.42801774 0.4986044  0.44819704 0.40232572\\n 0.40576416 0.6409064  0.46757615 0.44835046 0.48932648 0.37170613\\n 0.42401052 0.45446828 0.39043128 0.36105365 0.4527489  0.18722343\\n 0.3528408  0.527716   0.5865579  0.28183904 0.4151619  0.40869203\\n 0.5802676  0.5276307  0.2603831  0.57591504 0.5685247  0.43797967\\n 0.48367718 0.45874572 0.5815044  0.48841178 0.33414394 0.4104186\\n 0.6155271  0.4768165  0.6063968  0.23888022 0.38753578 0.54488665\\n 0.52811646 0.4446795  0.48939148 0.5451343  0.47324502 0.40415636\\n 0.24344088 0.23814465 0.58028215 0.2968325  0.4894132  0.46008542\\n 0.5154869  0.3484262  0.4921061  0.45856044 0.5350741  0.50680166\\n 0.5438898  0.37021616 0.57952195 0.48463827 0.43292797 0.30662835\\n 0.42275453 0.3727319  0.37104672 0.29009262 0.6112803  0.36102885\\n 0.63073397 0.43584517 0.7171018  0.48610803 0.40677145 0.4575287\\n 0.45135692 0.51429033 0.47372058 0.45326278 0.3570572  0.39929137\\n 0.27335712 0.3326606  0.3966834  0.47896194 0.51146954 0.51211125\\n 0.57274157 0.54973346 0.35952103 0.38477823 0.5510882  0.9329457\\n 0.28323168 0.5387967  0.5349483  0.27438232 0.4639318  0.29745218\\n 0.44696683 0.3298023  0.40179408 0.75885504 0.78360146 0.3954238\\n 0.51574755 0.49086115 0.2894196  0.40820307 0.6733542  0.42475352\\n 0.82380015 0.4743498  0.5270885  0.4819589  0.46302116 0.42711714\\n 0.40163666 0.28322366 0.5438107  0.4269975  0.5980365  0.3596011\\n 0.5467361  0.25232294 0.47676682 0.382295   0.5536069  0.41677132\\n 0.5561038  0.55192214 0.46566564 0.4309089  0.5470164  0.4135737\\n 0.41326904 0.47480616 0.53261656 0.3851144  0.5795898  0.32553193\\n 0.39990723 0.35792598 0.681494   0.6494161  0.5608495  0.48861095\\n 0.54498434 0.38727093 0.5958681  0.41410643 0.46111986 0.6940826\\n 0.5650635  0.5696155  0.45453867 0.42222258 0.4734929  0.3893279\\n 0.49934527 0.4255426  0.49858323 0.5502256  0.42196515 0.55792075\\n 0.37911266 0.4884941  0.30258644 0.41898143 0.31341577 0.3737838\\n 0.50082433 0.31676248 0.50074804 0.4904695  0.47355402 0.59487987\\n 0.4828821  0.38912728 0.4496635  0.5477259  0.3565911  0.48714733\\n 0.46194616 0.5266604  0.41230416 0.3165269  0.59100956 0.578464\\n 0.8108631  0.48087814 0.57160467 0.38866004 0.31763285 0.42893392\\n 0.5430116  0.3979673  0.5143211  0.47203335 0.675352   0.5986841\\n 0.47039497 0.49787286 0.37197638 0.37714732 0.500866   0.5062111\\n 0.4370265  0.4065558  0.59531844 0.520916   0.55473083 0.6651717\\n 0.54056406 0.49239773 0.28177133 0.58796155 0.5512199  0.56300604\\n 0.47489312 0.45299318 0.606213   0.4546547  0.3944409  0.54600203\\n 0.4407608  0.37813175 0.46185285 0.36298624 0.48270786 0.42739946\\n 0.48331738 0.36591682 0.42898038 0.45484427 0.5058906  0.14637056\\n 0.40774652 0.710583   0.60750514 0.4889754  0.4684765  0.45099825\\n 0.43353978 0.42782593 0.32299468 0.62504804 0.3501071  0.39849222\\n 0.36598638 0.48350048 0.336525   0.5015134  0.5599343  0.42081758\\n 0.5145566  0.35565612 0.4188631  0.62260497 0.4603747  0.4678594\\n 0.4897232  0.45593643 0.4413396  0.44629848 0.30420992 0.50531536\\n 0.5358828  0.5785284  0.6009074  0.5650365  0.4359581  0.56220055\\n 0.44944078 0.68824375 0.4504719  0.5177024  0.22656012 0.46107563\\n 0.31579193 0.5502249  0.28720397 0.46109605 0.43150002 0.19979753\\n 0.34373742 0.5370492  0.41617647 0.4071301  0.50168085 0.46648714\\n 0.41695014 0.35420895 0.48454106 0.4044625  0.49931923 0.41305986\\n 0.3992694  0.44246033 0.4396422  0.5685715  0.48796767 0.45441148\\n 0.3374822  0.50338656 0.48969096 0.4770007  0.45706245 0.51211166\\n 0.4915446  0.41199484 0.37458235 0.4742986  0.44818082 0.5763783\\n 0.41678447 0.5533551  0.629603   0.34451038 0.4915275  0.42475274\\n 0.5084104  0.20600232 0.68796086 0.3105826  0.59147626 0.2641937\\n 0.4158985  0.4653958  0.46083122 0.47788924 0.6050379  0.4868635\\n 0.6453954  0.3078264  0.2790126  0.6317865  0.27461413 0.42142537\\n 0.65743464 0.70707655 0.42145756 0.53786206 0.43044552 0.5616318\\n 0.28419647 0.400066   0.68048173 0.63968104 0.42701456 0.41587767\\n 0.4326959  0.4121959  0.44907355 0.40628406 0.4654643  0.503864\\n 0.5940017  0.43181127 0.47121927 0.4870643  0.47381443 0.47575697\\n 0.45041174 0.5783387  0.82740355 0.5477259  0.41366172 0.3525139\\n 0.47241694 0.40889844 0.49748182 0.53831667 0.45313904 0.61164397\\n 0.7063932  0.48545983 0.4690491  0.40064347 0.40009576 0.5352558\\n 0.46687552 0.63180166 0.531064   0.49184346 0.47822717 0.37912345\\n 0.36359856 0.5060202  0.36363608 0.5285934  0.4420594  0.45395863\\n 0.43289238 0.29533243 0.4038375  0.4933219  0.47049534 0.4964543\\n 0.49878645 0.47835252 0.33485997 0.41119492 0.6296711  0.51072246\\n 0.4322341  0.49966076 0.51440626 0.3778658  0.45705378 0.39182752\\n 0.51059043 0.54106015 0.52352965 0.41456166 0.5244289  0.47743264\\n 0.48727843 0.45860887 0.53631663 0.5272393  0.3894954  0.39181182\\n 0.62093693 0.48693988 0.43294555 0.53808093 0.4957414  0.2929917\\n 0.40966266 0.5003566  0.4709771  0.17706358 0.4916057  0.4712861\\n 0.48856968 0.41816634 0.47535628 0.35917592 0.46665102 0.54523844\\n 0.48717886 0.48365003 0.5758141  0.6411097  0.40581816 0.4992161\\n 0.42054293 0.4268596  0.6012274  0.534144   0.43232796 0.5935792\\n 0.4200946  0.50178    0.49884796 0.37175578 0.50326663 0.4329719\\n 0.43042186 0.56535053 0.34459895 0.521106   0.48136973 0.66717887\\n 0.44516557 0.385245   0.5180459  0.44728807 0.49098608 0.5204536\\n 0.38670906 0.23528235 0.7526273  0.51696086 0.5235273  0.40947917\\n 0.64626926 0.32238188 0.5306007  0.40721235 0.6703947  0.5104731\\n 0.37050784 0.53347456 0.6060464  0.4643107  1.0580833  0.4824612\\n 0.5432012  0.43288726 0.6150898  0.385179   0.36059102 0.41985437\\n 1.1597155  0.7263939  0.4769183  0.51982045 0.40790507 0.364726\\n 0.43654722 0.5046737  0.42129922 0.39478454 0.66047907 0.50513995\\n 0.3328036  0.54793453 0.31950137 0.39637578 0.46564054 0.44108543\\n 0.44024152 0.39675742 0.5033386  0.48310804 0.57096183 0.4158589\\n 0.4561779  0.49073035 0.4222978  0.51714224 0.48058763 0.4695795\\n 0.61322004 0.5127689  0.52083755 0.41595027 0.54582703 0.7310214\\n 0.5103738  0.51886994 0.3911359  0.48040378 0.58904344 0.6447955\\n 0.26714963 0.55333865 0.64714694 0.2768278  0.55413514 0.37433562\\n 0.5135485  0.40360004 0.35934296 0.389371   0.51813227 0.41450748\\n 0.5894     0.40059155 0.46715176 0.64484864 0.32785922 0.3894267\\n 0.59013784 0.5560375  0.5387712  0.46246484 0.56060594 0.39530808\\n 0.501816   0.6094389  0.5660653  0.4206728  0.52543133 0.46295524\\n 0.33171508 0.7057193  0.48959482 0.34983918 0.56514126 0.41226235\\n 0.43629953 0.469545   0.41909778 0.418504   0.4403533  0.37649038\\n 0.56409055 0.43654868 0.59227043 0.48947036 0.37798294 0.7065341\\n 0.41007262 0.3337941  0.31905147 0.33855683 0.40747032 0.48924497\\n 0.46524692 0.51099443 0.63183343 0.52661055 0.7204399  0.3904562\\n 0.53734    0.394278   0.52762634 0.46447155 0.41761422 0.5610573\\n 0.37579536 0.600118   0.5242714  0.4509387  0.49902272 0.37387007\\n 0.5415279  0.437699   0.38466206 0.4725896  0.5470457  0.4545309\\n 0.5040481  0.5721537  0.35904008 0.32497537 0.6411439  0.4612235\\n 0.44373804 0.38157123 0.55593437 0.42403477 0.41576657 0.30531418\\n 0.41845807 0.47910994 0.6713966  0.39932266 0.47884437 0.49203312\\n 0.35981292 0.60268474 0.49021164 0.44407964 0.40432948 0.6597863\\n 0.34157068 0.4574892  0.7082292  0.59192586 0.4228552  0.4610377\\n 0.55390066 0.4080325  0.6322807  0.6270952  0.45416567 0.43656212\\n 0.31933212 0.5848234  0.49112964 0.37245706 0.74583405 0.4486721\\n 0.49214077 0.5847703  0.6261274  0.42907855 0.6035287  0.54136646\\n 0.5175942  0.49715516 0.50504977 0.819396   0.46596467 0.4773701\\n 0.46332517 0.47192946 0.41121575 0.6685433  0.37195274 0.48371404\\n 0.612425   0.52884763 0.32523    0.20003447 0.39827767 0.49331513\\n 0.40467936 0.5617149  0.43335524 0.23479077 0.5575643  0.46074143\\n 0.4587527  0.4687352  0.46420932 0.42294958 0.43350175 0.5046572\\n 0.3842086  0.45953634 0.5378185  0.4562564  0.5037485  0.32442617\\n 0.43354613 0.4967442  0.41000435 0.45206544 0.26183337 0.6048646\\n 0.45694122 0.43833774 0.43838096 0.789138   0.35190326 0.58414733\\n 0.53802043 0.5387627  0.5276393  0.37225115 0.6798867  0.5559357\\n 0.49036148 0.92510796 0.6807152  0.51210374 0.4336656  0.46646807\\n 0.39313638 0.48360434 0.32567653 0.26020798 0.33425635 0.54272074\\n 0.5178988  0.5252151  0.5691663  0.35421667 0.29223216 0.31852657\\n 0.49397805 0.52822113 0.4364291  0.34617832 0.49926758 0.3239997\\n 0.4681439  0.37316757 0.50756234 0.671756   0.30914682 0.75743216\\n 0.40849283 0.5072732  0.26587906 0.45691714 0.5094639  0.48213273\\n 0.38289046 0.5415947  0.3516218  0.50784796 0.60570496 0.4665978\\n 0.48920625 0.6130072  0.34538352 0.35700786 0.6200105  0.43128982\\n 0.42383218 0.47509167 0.4921011  0.47160256 0.5439674  0.3976745\\n 0.55166125 0.40757665 0.42322573 0.4033786  0.50573194 0.37167746\\n 0.41996247 0.4365616  0.41466194 0.51195896 0.7077289  0.5121846\\n 0.5124789  0.5963043  0.34343013 0.6413423  0.6368285  0.41880906\\n 0.43557474 0.50460637 0.42613634 0.47423849 0.5500125  0.50522405\\n 0.5221107  0.47946486 0.56879    0.3977631  0.71063626 0.50988907\\n 0.63604385 0.33883113 0.45375952 0.3526928  0.6111235  0.37359607\\n 0.5273385  0.40027025 0.40343067 0.34834367 0.49668035 0.31328586\\n 0.5267399  0.48152283 0.5564252  0.39581087 0.64120126 0.5424246\\n 0.41267717 0.4673345  0.45080113 0.40262318 0.42682087 0.5531932\\n 0.51070577 0.24413933 0.5513501  0.42012215 0.53046525 0.32668927\\n 0.41311225 0.39751923 0.59593254 0.42286924 0.7528165  0.42308533\\n 0.26046842 0.4178863  0.39206016 0.4173172  0.4466337  0.50949454\\n 0.41737434 0.44671682 0.36139455 0.6258015  0.5288233  0.6329145\\n 0.5771682  0.44158536 0.7270715  0.49720567 0.39732826 0.551778\\n 0.5445394  0.4688973  0.570004   0.40960848 0.83657074 0.54209316\\n 0.549504   0.4582883  0.5426756  0.40985432 0.4630743  0.5153661\\n 0.55595297 0.36076942 0.46222192 0.5099613  0.4573908  0.47545657\\n 0.45203438 0.47293413 0.37580743 0.471453   0.5789832  0.475877\\n 0.49166012 0.4711573  0.4191974  0.54646164 0.63858205 0.4117703\\n 0.6185295  0.25602642 0.3417992  0.511707   0.5247295  0.44040182\\n 0.49742672 0.34595668 0.4333208  0.50142044 0.35098615 0.5275855\\n 0.5714447  0.5232151  0.5087409  0.5952167  0.4853881  0.5303424\\n 0.78294605 0.55455154 0.33064145 0.25128683 0.46417063 0.459689\\n 0.3944701  0.5755559  0.42321497 0.39551237 0.52880377 0.39605\\n 0.30399543 0.4972794  0.2778284  0.34510887 0.5105359  0.37390983\\n 0.7520884  0.51034194 0.5013004  0.44623548 0.52509284 0.35706857\\n 0.5067773  0.28083506 0.3871881  0.4838977  0.53585404 0.6755248\\n 0.3930771  0.4742405  0.55756354 0.56695163 0.45419052 0.43269888\\n 0.6056439  0.20562144 0.5400077  0.6060975  0.40507612 0.5335611\\n 0.48328048 0.7189049  0.35112175 0.5428345  0.5304766  0.43668228\\n 0.54833573 0.593827   0.47012776 0.6184468  0.44118538 0.3017934\\n 0.52308255 0.46080938 0.54062325 0.44052747 0.48716953 0.40188724\\n 0.3476611  0.39805686 0.6246968  0.4598088  0.4010866  0.3760952\\n 0.37645906 0.49155065 0.5574618  0.70392656 0.39241642 0.45822033\\n 0.49846867 0.45424527 0.3251887  0.32984722 0.6352057  0.38977\\n 0.44347253 0.4146403  0.5392882  0.47550875 0.5832285  0.5697703\\n 0.438924   0.612298   0.36241314 0.6739013  0.6140321  0.7281253\\n 0.57704043 0.20149669 0.45726946 0.4750808  0.43961868 0.6636776\\n 0.4513345  0.51125145 0.67177284 0.5309046  0.49059817 0.65338826\\n 0.30689356 0.5946955  0.5811321  0.36178672 0.5815563  0.46693957\\n 0.3722092  0.41258544 0.47543275 0.53388643 0.34118417 0.4558257\\n 0.60192555 0.38902086 0.43060622 0.4006631  0.44705638 0.47410434\\n 0.42772603 0.34703064 0.5287193  0.41732368 0.40215355 0.5112405\\n 0.40686366 0.4055184  0.63772136 0.53782386 0.24043472 0.42702508\\n 0.31359562 0.46488214 0.38001397 0.40848586 0.5326157  0.51178896\\n 0.50998026 0.4343806  0.45290476 0.24561863 0.3136184  0.48484677\\n 0.49736267 0.5604936  0.423567   0.44360086 0.3583006  0.4582109\\n 0.4742448  0.6304033  0.32288375 0.46107194 0.48616427 0.53789794\\n 0.42580846 0.3409641  0.4033008  0.3749779  0.44889006 0.5498839\\n 0.50465274 0.38504842 0.44526142 0.40213776 0.61403084 0.5391137\\n 0.43942896 0.48286965 0.45947903 0.27622628 0.8007006  0.5135204\\n 0.43421975 0.46883202 0.59780586 0.41175961 0.40287164 0.2830024\\n 0.42915368 0.60213345 0.5008948  0.40940037 0.4740264  0.7003922\\n 0.5159604  0.38544723 0.37235838 0.37793022 0.35340515 0.37453842\\n 0.37262145 0.4674914  0.49856812 0.6682158  0.38831407 0.49768588\\n 0.4011636  0.6422092  0.2737084  0.539441   0.35737547 0.48306638\\n 0.81932986 0.37430203 0.43845764 0.27707115 0.41442546 0.3977015\\n 0.6025796  0.4019214  0.37616068 0.5157198  0.34931257 0.4106488\\n 0.4263396  0.55298716 0.70428777 0.47827268 0.43087876 0.47812334\\n 0.41533983 0.6567266  0.29422498 0.38581458 0.48355958 0.48196054\\n 0.45805672 0.33957434 0.5040592  0.4007615  0.5421932  0.3600414\\n 0.54830754 0.47247177 0.61157596 0.34146515 0.56701094 0.47204986\\n 0.57541496 0.46137673 0.52177787 0.33851054 0.4598681  0.5249261\\n 0.39586857 0.63651866 0.4944205  0.6099859  0.4889901  0.5904946\\n 0.5776336  0.82444113 0.46245793 0.44154856 0.36373675 0.41466057\\n 0.5113871  0.42565808 0.45566675 0.5751924  0.3925825  0.29334322\\n 0.5360478  0.45062566 0.7330109  0.3922495  0.39781353 0.70394504\\n 0.5131627  0.6273466  0.4261385  0.42180625 0.5730521  0.34210262\\n 0.498665   0.36877644 0.50033593 0.63953096 0.34291503 0.4465286\\n 0.4484506  0.2965178  0.58144253 0.48983756 0.4271618  0.48481065\\n 0.52754223 0.50534    0.5425129  0.34343985 0.27054673 0.4649524\\n 0.46973068 0.49626446 0.29790032 0.45870605 0.46550122 0.2631605\\n 0.53306866 0.39259943 0.6030084  0.54324704 0.4209931  0.3371224\\n 0.43444344 0.5257672  0.66689074 0.47709444 0.6230955  0.34185857\\n 0.5918217  0.47690555 0.6613902  0.4555147  0.22577046 0.2736581\\n 0.52275383 0.31558558 0.44189453 0.60330313 0.37138623 0.45349467\\n 0.49484712 0.60140085 0.44196042 0.53169554 0.3557181  0.5727339\\n 0.493031   0.5193438  0.51165116 0.48847583 0.52272713 0.4118864\\n 0.5673236  0.41780514 0.681956   0.43286884 0.4161902  0.61909115\\n 0.4631094  0.44941297 0.48454532 0.7093496  0.34855503 0.62963086\\n 0.4174037  0.5270834  0.44652602 0.5511882  0.40907255 0.49492735\\n 0.5605516  0.5679088  0.5884173  0.52828896 0.46637866 0.5727736\\n 0.40701208 0.39644474 0.5164142  0.41390485 0.41469648 0.53430176\\n 0.49128234 0.6474835  0.45770982 0.38800624 0.3371177  0.352422\\n 0.3182642  0.5940011  0.33833504 0.6228371  0.394046   0.29690385\\n 0.24690491 0.4875826  0.45342267 0.5742892  0.44547683 0.46051818\\n 0.31407946 0.37612244 0.44536895 0.40824038 0.5718094  0.19777948\\n 0.51577115 0.5245072  0.45056367 0.58881354 0.50922954 0.47614148\\n 0.5601584  0.408006   0.85480404 0.5220671  0.48459497 0.38499597\\n 0.51039886 0.266689   0.6425078  0.4938711  0.7417651  0.49890018\\n 0.6129054  0.52280796 0.47057506 0.47358742 0.4735029  0.64809686\\n 0.6265091  0.48025927 0.5382164  0.28721508 0.39618003 0.52209103\\n 0.57002246 0.74143606 0.38574162 0.4762398  0.59916645 0.7004122\\n 0.49925345 0.48433718 0.51119    0.34908473 0.6023191  0.537554\\n 0.21371193 0.46532556 0.57322997 0.44150063 0.5256675  0.3302663\\n 0.93380916 0.34788582 0.532706   0.44262165 0.28010288 0.49632335\\n 0.62731993 0.6776311  0.5315629  0.7686339  0.5025253  0.5281334\\n 0.6830941  0.46601337 0.81696004 0.5925644  0.5214842  0.46055922\\n 0.60965383 0.4167946  0.49964708 0.3576773  0.4677063  0.32204255\\n 0.41207442 0.8663523  0.4652067  0.52647793 0.4029254  0.39003143\\n 0.36050826 0.42081916 0.3172286  0.42880008 0.24739759 0.4525864\\n 0.59296167 0.47934663 0.46819177 0.40506166 0.36805958 0.44233876\\n 0.53532434 0.50111824 0.3834273  0.71883374 0.44902903 0.44135296\\n 0.43828776 0.4041143  0.32785186 0.35786405 0.48263672 0.5073653\\n 0.48093936 0.82603157 0.4325656  0.5418996  0.3418087  0.6410967\\n 0.56155306 0.52082807 0.4924588  0.42159885 0.45515275 0.26114956\\n 0.41958803 0.5611727  0.39795792 0.5169192  0.5718466  0.28532937\\n 0.50781304 0.5408617  0.51101804 0.5110447  0.42899412 0.55896765\\n 0.4349643  0.42542642 0.6066983  0.58191234 0.40076843 0.3198269\\n 0.386723   0.44599587 0.41430008 0.39917162 0.37660006 0.3907475\\n 0.5518403  0.56388    0.53815025 0.37505192 0.33020818 0.43797\\n 0.44895133 0.3211814  0.5735949  0.31664965 0.33818465 0.41414353\\n 0.46762607 0.44701508 0.46593198 0.46417657 0.64447796 0.4028448\\n 0.5668573  0.5503815  0.524346   0.4724509  0.36439335 0.4384012\\n 0.40348226 0.4366631  0.47678998 0.38970217 0.64083606 0.37183133\\n 0.38233596 0.46579936 0.5955163  0.491749   0.4778604  0.2666846\\n 0.46458793 0.3277616  0.84859467 0.48344713 0.41808537 0.7070717\\n 0.40724042 0.38199615 0.4530637  0.4234664  0.33951584 0.51333207\\n 0.5049039  0.28065497 0.32117498 0.458805   0.37366587 0.34042904\\n 0.5510302  0.39582255 0.54324526 0.50412047 0.36255485 0.4139222\\n 0.51708245 0.2912387  0.2824078  0.42339024 0.50159335 0.41404366\\n 0.3908351  0.44392833 0.4863439  0.46745887 0.59300786 0.48229504\\n 0.5423425  0.4083219  0.4402675  0.38420144 0.3133286  0.6485189\\n 0.4755704  0.5597193  0.33041552 0.45623448 0.33469656 0.36824632\\n 0.38274425 0.33779702 0.65485823 0.44504344 0.545396   0.49766994\\n 0.5519294  0.4112623  0.6432554  0.46113017 0.53253376 0.5306705\\n 0.5619828  0.5409613  0.76498216 0.6688784  0.6498978  0.45779\\n 0.4739137  0.49945426 0.50964963 0.341606   0.48345065 0.5686518\\n 0.44784328 0.6160618  0.5235302  0.44267228 0.46089053 0.43182287\\n 0.4590065  0.43798956 0.4628557  0.4736125  0.4536326  0.4919117\\n 0.4544373  0.39384142 0.4789794  0.43923703 0.41535687 0.45349813\\n 0.21653152 0.36332142 0.51528656 0.38268793 0.6096539  0.38816273\\n 0.42120323 0.5074102  0.48273405 0.7108221  0.78727424 0.7703553\\n 0.5022111  0.61232024 0.3869015  0.43959862 0.5534749  0.50282246\\n 0.30754578 0.63070756 0.4060496  0.67414045 0.4787536  0.6699127\\n 0.47502613 0.5287769  0.2101939  0.5779965  0.46911484 0.4270046\\n 0.65051264 0.49104977 0.24847704 0.3349618  0.37332305 0.3914228\\n 0.58267325 0.5873366  0.450966   0.5232708  0.58719784 0.52125317\\n 0.46883896 0.59181225 0.45416266 0.4010047  0.5278557  0.6251811\\n 0.26354942 0.559372   0.47790605 0.59206146 0.46142772 0.3674549\\n 0.5141807  0.53274286 0.22886483 0.43131593 0.6722479  0.5632873\\n 0.45379907 0.37823182 0.59487253 0.5617116  0.49519286 0.52726096\\n 0.3590066  0.7339113  0.6625171  0.49592215 0.48080903 0.5201745\\n 0.4714674  0.41698143 0.56163156 0.4478895  0.32908452 0.4292357\\n 0.37768722 0.5622065  0.45701745 0.37227133 0.40690377 0.33419752\\n 0.4032897  0.38938406 0.43783188 0.4580447  0.37126634 0.39982963\\n 0.42797437 0.43978873 0.30076692 0.6091177  0.5003922  0.4374362\\n 0.4674205  0.45340455 0.3497199  0.5032485  0.24484034 0.4902397\\n 0.40314808 0.68347836 0.5183052  0.57176054 0.5308142  0.34224164\\n 0.37629583 0.43191504 0.5664731  0.61890423 0.7207154  0.45351237\\n 0.47536817 1.1561325  0.4920597  0.34777862 0.41790187 0.565909\\n 0.99460167 0.23838769 0.35777226 0.41516915 0.33906686 0.5687427\\n 0.63540065 0.24449329 0.60012674 0.4117363  0.43403718 0.44002914\\n 0.47692546 0.5890918  0.56132126 0.35668468 0.44291973 0.5388502\\n 0.4808176  0.42378208 0.45919535 0.35850033 0.5988938  0.4021685\\n 0.4312082  0.4387368  0.4864923  0.43769243 0.51584363 0.40457818\\n 0.50675833 0.46383    0.3794026  0.5832501  0.4360385  0.3675932\\n 0.43489814 0.3841491  0.7134779  0.60910845 0.40163603 0.54106164\\n 0.5487173  0.4669862  0.41718802 0.5141784  0.76913714 0.37327197\\n 0.46866497 0.3680638  0.2176609  0.3766209  0.3574501  0.4866002\\n 0.3546854  0.5029477  0.5108671  0.43139654 0.4646045  0.32120952\\n 0.4147675  0.5671147  0.42912602 0.2970839  0.53025335 0.45482147\\n 0.5607898  0.53735846 0.37676358 0.6266393  0.33392447 0.46941367\\n 0.62096345 0.40869045 0.42846468 0.48738945 0.5653458  0.35363224\\n 0.50959736 0.5315839  0.34924918 0.37364584 0.42818895 0.3972881\\n 0.38135645 0.52982813 0.49558842 0.39272147 0.52887976 0.4248997\\n 0.3991996  0.6192384  0.3816834  0.53582877 0.49795464 0.77686244\\n 0.69574976 0.47685522 0.3800724  0.44837674 0.56946987 0.6737875\\n 0.5281878  0.40994626 0.4843229  0.51131904 0.43845105 0.40543157\\n 0.49252528 0.4793342  0.40130076 0.36503386 0.3288989  0.39175174\\n 0.4601394  0.5605147  0.41686052 0.467214   0.34567407 0.34584832\\n 0.33842462 0.35163602 0.4371458  0.39270872 0.19564757 0.32339692\\n 0.516791   0.32955223 0.31383765 0.3768604  0.50402147 0.4852434\\n 0.69592345 0.57413435 0.3837354  0.3665877  0.4273683  0.5404972\\n 0.5522707  0.57853925 0.4518241  0.50157684 0.41877517 0.43881816\\n 0.4570047  0.27245674 0.44489777 0.48816794 0.4218693  0.8954914\\n 0.4415562  0.6025478  0.52529514 0.450352   0.61755806 0.53964037\\n 0.5164713  0.49447295 0.44196066 0.3741284  0.37534574 0.3417782\\n 0.4970391  0.36616555 0.78459024 0.4534138  0.47278625 0.2551811\\n 0.3706986  0.47977388 0.39655167 0.3672001  0.5052648  0.6570903\\n 0.3513762  0.50347334 1.0825871  0.42937765 0.55404764 0.44137603\\n 0.52399737 0.29087383 0.46105325 0.39146706 0.5400168  0.51618856\\n 0.6191074  0.32208067 0.3139949  0.5756869  0.3338674  0.25584647\\n 0.43231335 0.37319884 0.3458938  0.5508759  0.46293274 0.44006324\\n 0.60862124 0.47981974 0.39920127 0.36374438 0.55008835 0.5065466\\n 0.44305676 0.46349105 0.4421346  0.4877041  0.66119677 0.7492509\\n 0.62794644 0.24973573 0.5528952  0.5166705  0.48309228 0.49104533\\n 0.5703085  0.30132154 0.4106486  0.5788985  0.4174673  0.80073756\\n 0.6175738  0.4797188  0.6187739  0.45374584 0.55440533 0.54033923\\n 0.5621229  0.63205284 0.57017106 0.38297513 0.35839984 0.47175458\\n 0.46950585 0.38947734 0.3463368  0.53044903 0.3144173  0.42731708\\n 0.4492807  0.6276493  0.7731031  0.45029566 0.5795241  0.39322054\\n 0.21731621 0.422509   0.5577347  0.50649315 0.4730033  0.5635476\\n 0.40390185 0.7716424  0.36091518 0.3962867  0.48971882 0.43739638\\n 0.41194966 0.53792596 0.52148014 0.571965   0.52574015 0.42053762\\n 0.46862215 0.38380274 0.44930008 0.7449202  0.41782    0.52570325\\n 0.4776108  0.58339244 0.68377435 0.62499726 0.54285395 0.47141513\\n 0.5709893  0.47144675 0.41280508 0.34036463 0.40366313 0.47933757\\n 0.5573484  0.4846259  0.36799774 0.58685595 0.50915015 0.54704696\\n 0.61462575 0.468263   0.3344209  0.37688336 0.62447023 0.2948323\\n 0.65062714 0.33087415 0.5535439  0.6026322  0.666256   0.7181288\\n 0.43399724 0.3012889  0.49737096 0.5111336  0.5417175  0.4212458\\n 0.4231022  0.42426777]', '/content/sample_data/HAM10000_images_part_1/ISIC_0026187.jpg', '0']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (<unknown>, line 1)",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \u001b[1;32m\"<ipython-input-24-3b0fbd9b7cd1>\"\u001b[0m, line \u001b[1;32m52\u001b[0m, in \u001b[1;35m<cell line: 0>\u001b[0m\n    genera_dists(model,test_data,activation)\n",
            "  File \u001b[1;32m\"<ipython-input-23-b923970ae2de>\"\u001b[0m, line \u001b[1;32m43\u001b[0m, in \u001b[1;35mgenera_dists\u001b[0m\n    fcnoutput = np.array(ast.literal_eval(rows[1]))\n",
            "  File \u001b[1;32m\"/usr/lib/python3.11/ast.py\"\u001b[0m, line \u001b[1;32m64\u001b[0m, in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\n",
            "\u001b[0;36m  File \u001b[0;32m\"/usr/lib/python3.11/ast.py\"\u001b[0;36m, line \u001b[0;32m50\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [0.89235574 0.46314925 0.8941267  0.39894742 0.38418075 0.5070819\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    }
  ]
}