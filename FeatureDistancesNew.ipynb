{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPuhd9LRY9V21XjLAiggzqm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enVives/TFG/blob/main/FeatureDistancesNew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calcul de la similitud entre imatges\n",
        "\n",
        "Aquest fitxer segueix l'execució al fitxer de FeatureExtraction. Després d'haver guardat els vectors de característiques de les imatges pertanyens al conjunts d'entrenament i de test calcularem la seva similitud (distància) entre els vectors pertanyents a ambdós fitxers.\n",
        "\n",
        "De cada vector pertanyent al conjunt de test cercarem els _k_ vectors del conjunt d'entrenament més propers i més llunyans. En el nostre cas _k_ = 5.\n",
        "\n",
        "La distància obtinguda i la informació dels _k_ vectors més propers i llunyans es guardarà dins un fitxer de text. Degut al fet que en aquest projecte experimentarem amb les funcions L2 i cosin (per al càlcul de similitud), tindrem una carpeta per a cada una d'aquestes mètriques. Dins aquesta carpeta hi guardarem el nostre fitxer de text amb les distàncies obtingudes.\n",
        "\n",
        "Les dues carpetes de L2 i cosin es guardaràn dins la carpeta 'Dist', que es situarà dins la mateixa carpeta dels pesos utilitzats en tot el procés.\n",
        "\n",
        "Dins 'model/numero_execució/Dist/funció_distància/_'  hi crearem també una carpeta per a cada imatge de test. Aquestes carpetes tindrán el nom de l'identificador de la imatge amb la seva classe 'ISIC_00...(malaltia)'. Dins aquestes carpetes hi guardarem les _k_ imatges més properes i més llunyanes i la imatge de test en format jpg."
      ],
      "metadata": {
        "id": "jGPQ5-31o02a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2Nzx9gO8R_A",
        "outputId": "61733109-3421-4e1a-aa36-90346da41e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import wandb\n",
        "import pylab as pl\n",
        "import json\n",
        "import shutil\n",
        "\n",
        "from glob import glob\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output,display\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "from google.colab import drive\n",
        "\n",
        "DOWNLOAD = False\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "MODELS = {\n",
        "    0: 'AlexnetBinary',\n",
        "    1: 'Resnet152Binary',\n",
        "    2: 'Inceptionv3Binary',\n",
        "    3: 'EfficientNetB1Binary',\n",
        "    4: 'AlexnetMulticlass',\n",
        "    5: 'Resnet152Multiclass',\n",
        "    6: 'Inceptionv3Multiclass',\n",
        "    7: 'EfficientnetB1Multiclass',\n",
        "}\n",
        "\n",
        "DISTANCES = {\n",
        "    'Cosin' : 0,\n",
        "    'L2' : 1\n",
        "}\n",
        "\n",
        "\n",
        "MODEL = MODELS[6] #triam un model\n",
        "picked = 'L2'\n",
        "DISTANCE = DISTANCES[picked] #triam una distància\n",
        "\n",
        "RUN = 9 #triam el nombre de l'execució\n",
        "\n",
        "#direcció dels fitxers de característiques\n",
        "TRAINING_FEATURES_FILE = \"/content/drive/MyDrive/Runs/Ham10000-\"+MODEL+\"/\"+str(RUN)+\"/Features/training_features.txt\"\n",
        "TESTING_FEATURES_FILE = \"/content/drive/MyDrive/Runs/Ham10000-\"+MODEL+\"/\"+str(RUN)+\"/Features/testing_features.txt\"\n",
        "\n",
        "#cream el folder per a les distances\n",
        "DIST_FOLDER = \"/content/drive/MyDrive/Runs/Ham10000-\"+MODEL+\"/\"+str(RUN)+\"/Dist/\"+picked\n",
        "\n",
        "if os.path.exists(DIST_FOLDER):\n",
        "    shutil.rmtree(DIST_FOLDER)\n",
        "\n",
        "os.makedirs(DIST_FOLDER,exist_ok=True)\n",
        "\n",
        "if DOWNLOAD:\n",
        "  !rm -rf /content/sample_data/*\n",
        "\n",
        "  !kaggle datasets download -d \"kmader/skin-cancer-mnist-ham10000\"\n",
        "\n",
        "  !unzip -o skin-cancer-mnist-ham10000.zip -d /content/sample_data/\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import TextIOWrapper\n",
        "from numpy.linalg import norm\n",
        "import sys\n",
        "import ast\n",
        "import shutil\n",
        "\n",
        "def genera_dists():\n",
        "  csv.field_size_limit(sys.maxsize)\n",
        "  dict_illnesses = {0 : 'nv', 1 : 'mel', 2 : 'bkl', 3 : 'bcc', 4 : 'akiec', 5 : 'vasc', 6 : 'df'}\n",
        "\n",
        "  fi = DIST_FOLDER+'/distances.txt'\n",
        "\n",
        "  #informació guardada als fitxers de text\n",
        "  headers = [\"test_img\",\"test_img_pred_label\",\"test_img_label\",\"top_distances\",\"top_images_labels\",\"top_images_names\",\"bottom_distances\",\"bottom_images_labels\",\"bottom_images_names\"]\n",
        "\n",
        "  with open(fi, mode=\"w\", newline=\"\") as file:\n",
        "      writer = csv.writer(file, delimiter=';')\n",
        "      writer.writerow(headers)\n",
        "\n",
        "  #obrim el fitxer de testing\n",
        "  with open(TESTING_FEATURES_FILE ,newline = '') as ftst:\n",
        "\n",
        "    test_features = csv.DictReader(ftst,delimiter=',')\n",
        "    number = 0\n",
        "    for i in test_features:\n",
        "      number = number + 1\n",
        "      test_img_name = i['Image Name']\n",
        "      test_img_features = np.array(ast.literal_eval(i['FC Input']))\n",
        "      test_img_path = i['Image Path']\n",
        "      test_img_label = i['Label']\n",
        "\n",
        "      if DISTANCE == 0: #si utilitzam la distància cosin, cercarem els valors més propers a 1\n",
        "        top5dist = np.array([0,0,0,0,0],dtype=object)\n",
        "        bottom5dist = np.array([np.inf,np.inf,np.inf,np.inf,np.inf],dtype=object)\n",
        "      else: #d'altra banda, si utilitzam la distància l2, cercam els valors més propers a 0\n",
        "        top5dist = np.array([np.inf,np.inf,np.inf,np.inf,np.inf],dtype=object)\n",
        "        bottom5dist = np.array([0,0,0,0,0],dtype=object)\n",
        "\n",
        "      top5labels = np.array([-1,-1,-1,-1,-1],dtype=object)\n",
        "      bottom5labels = np.array([-1,-1,-1,-1,-1],dtype=object)\n",
        "      top5names = np.array([\"\",\"\",\"\",\"\",\"\"],dtype=object)\n",
        "      bottom5names = np.array([\"\",\"\",\"\",\"\",\"\"],dtype=object)\n",
        "      top5paths = np.array([\"\",\"\",\"\",\"\",\"\"],dtype=object)\n",
        "      bottom5paths = np.array([\"\",\"\",\"\",\"\",\"\"],dtype=object)\n",
        "\n",
        "      #obrim el fitxer de training\n",
        "      with open(TRAINING_FEATURES_FILE, newline='') as ftr:\n",
        "        tr_features = csv.DictReader(ftr,delimiter = ',')\n",
        "\n",
        "        for j in tr_features:\n",
        "          train_img_name = j['Image Name']\n",
        "          train_img_features = np.array(ast.literal_eval(j['FC Input']))\n",
        "          train_img_path = j['Image Path']\n",
        "          train_img_label = j['Label']\n",
        "\n",
        "          if DISTANCE == 0: #cosin\n",
        "            distance = np.dot(test_img_features,train_img_features)/(norm(test_img_features)*norm(train_img_features))\n",
        "          else: #l2\n",
        "            distance = norm(test_img_features - train_img_features)\n",
        "\n",
        "          #actualitzam el top 5, bottom 5 o cap dels dos\n",
        "          if DISTANCE == 0: #cosin\n",
        "            for k in range(len(top5dist)):\n",
        "              if distance > top5dist[k]:\n",
        "                top5dist[k] = distance\n",
        "                top5labels[k] = dict_illnesses[int(train_img_label)]\n",
        "                top5paths[k] = train_img_path\n",
        "                top5names[k] = train_img_name\n",
        "                break\n",
        "              if distance < bottom5dist[k]:\n",
        "                bottom5dist[k] = distance\n",
        "                bottom5labels[k] = dict_illnesses[int(train_img_label)]\n",
        "                bottom5paths[k] = train_img_path\n",
        "                bottom5names[k] = train_img_name\n",
        "                break\n",
        "          else: #l2\n",
        "            for k in range(len(top5dist)):\n",
        "              if distance < top5dist[k]:\n",
        "                top5dist[k] = distance\n",
        "                top5labels[k] = dict_illnesses[int(train_img_label)]\n",
        "                top5paths[k] = train_img_path\n",
        "                top5names[k] = train_img_name\n",
        "                break\n",
        "              if distance > bottom5dist[k]:\n",
        "                bottom5dist[k] = distance\n",
        "                bottom5labels[k] = dict_illnesses[int(train_img_label)]\n",
        "                bottom5paths[k] = train_img_path\n",
        "                bottom5names[k] = train_img_name\n",
        "                break\n",
        "\n",
        "        #we create the folder of our test image, it will have name and label\n",
        "        os.makedirs(DIST_FOLDER+'/'+test_img_name.split('.')[0]+'('+dict_illnesses[int(test_img_label)]+')/',exist_ok=True)\n",
        "\n",
        "        #we want to order the top and bottom depending on the distance\n",
        "        if DISTANCE == 0:\n",
        "          sorted_indices = np.argsort(top5dist)[::-1]\n",
        "        else:\n",
        "          sorted_indices = np.argsort(top5dist)\n",
        "\n",
        "        #si utilitzam la distància cosin ens interessa que la distància més gran sigui la primera\n",
        "\n",
        "        top5dist = top5dist[sorted_indices]\n",
        "        top5labels = top5labels[sorted_indices]\n",
        "        top5paths = top5paths[sorted_indices]\n",
        "        top5names = top5names[sorted_indices]\n",
        "\n",
        "        if DISTANCE == 0:\n",
        "          sorted_indices = np.argsort(bottom5dist)[::-1]\n",
        "        else:\n",
        "          sorted_indices = np.argsort(bottom5dist)\n",
        "\n",
        "        bottom5dist = bottom5dist[sorted_indices]\n",
        "        bottom5labels = bottom5labels[sorted_indices]\n",
        "        bottom5paths = bottom5paths[sorted_indices]\n",
        "        bottom5names = bottom5names[sorted_indices]\n",
        "\n",
        "        #corregir actual label\n",
        "        data_row = [test_img_name.split('.')[0],test_img_label,test_img_label,[round(num,6) for num in top5dist.astype(float).tolist()],top5labels,top5names.astype(str).tolist(),[round(num,6) for num in bottom5dist.astype(float).tolist()],bottom5labels,bottom5names.astype(str).tolist()]\n",
        "\n",
        "        #guardarem els data_row disn un fitxer de txt i crearem les carpetes top i bottom\n",
        "\n",
        "        #ens interessa ara el nom de la enfermetat\n",
        "        test_img_label = dict_illnesses[int(test_img_label)]\n",
        "\n",
        "        os.makedirs(DIST_FOLDER+'/'+test_img_name.split('.')[0]+'('+test_img_label+')'+'/Top/',exist_ok=True)\n",
        "        os.makedirs(DIST_FOLDER+'/'+test_img_name.split('.')[0]+'('+test_img_label+')'+'/Bottom/',exist_ok=True)\n",
        "\n",
        "        #guardam les imatges més properes\n",
        "        for l in range(len(top5paths)):\n",
        "          shutil.copy(top5paths[l], DIST_FOLDER+'/'+test_img_name.split('.')[0]+'('+test_img_label+')/Top/'+str(l)+'_'+top5labels[l]+'.jpg')\n",
        "\n",
        "        #guardam la nostra imatge de test\n",
        "        shutil.copy(test_img_path ,DIST_FOLDER+'/'+test_img_name.split('.')[0]+'('+test_img_label+')/'+test_img_label+'_imatge_test_'+test_img_name)\n",
        "\n",
        "        #guardam les imatges més llunyanes\n",
        "\n",
        "        for m in range(len(bottom5paths)):\n",
        "          shutil.copy(bottom5paths[m], DIST_FOLDER+'/'+test_img_name.split('.')[0]+'('+test_img_label+')/Bottom/'+str(m)+'_'+bottom5labels[m]+'.jpg')\n",
        "\n",
        "        #guardam les distàncies dins un fitxer txt\n",
        "        with open(fi, mode=\"a\", newline=\"\") as file:\n",
        "          writer = csv.writer(file, delimiter=';')\n",
        "          writer.writerow(data_row)  # Write row immediately\n",
        "\n",
        "        print(number) #per fer un seguiment\n",
        "\n",
        "        #Nombre de distàncies que volem guardar\n",
        "        if number == 250:\n",
        "          break\n",
        "\n",
        "  print(\"CSV file written successfully.\")"
      ],
      "metadata": {
        "id": "aU21okj094I0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p ~/.kaggle\n",
        "# !mv /content/kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "bVQDISVu8ttG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genera_dists()"
      ],
      "metadata": {
        "id": "H7hKqkm4HM3d",
        "outputId": "fd789b25-3384-4e78-b11e-9b86c8e17d16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "CSV file written successfully.\n"
          ]
        }
      ]
    }
  ]
}